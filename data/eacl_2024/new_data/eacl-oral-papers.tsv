Session	Date	Time CET (Local Time)	Room	Track	Pres. Order	Session Name 	Paper ID	Paper Title	Author	Length	Category	Presentation Preference	New Presentation Mode	Chair	Chair email	Abstract
Session 2	2024-03-18	11:00	Carlson 	Efficient/Low-resource methods in NLP	1	Machine Learning for NLP	317	Extreme Fine-tuning: A Novel and Fast Fine-tuning Approach for Text Classification	Boonnithi Jiaramaneepinit, Thodsaporn Chay-intr, Kotaro Funakoshi, Manabu Okumura	Long 12/2.5/.5	Oral 	In Person		Dr. Bart Desmet	bart.desmet@gmail.com	Although fine-tuning a pre-trained model with a conventional approach has shown to be effective in various downstream tasks, previous work has used only backpropagation to fine-tune the model, which causes a massive amount of computational resources and time. We propose Extreme Fine-Tuning (EFT), a novel approach for fine-tuning a pre-trained model effectively and efficiently. EFT uses backpropagation for a brief fine-tuning and an iterative extreme learning machine for training a classifier. We applied EFT to four text classification datasets, MELD, IEMOCAP, IMDb, and AG News, and compared its performance with state-of-the-art (SOTA) approaches. The results indicate that EFT noticeably outperformed the other approaches in training-time measurement with comparable model performance. We will release our code at https://github.com/up-33/extreme-fine-tuning.
Session 2	2024-03-18	11:15	Carlson 	Machine Learning for NLP	2	Machine Learning for NLP	198	Plan-Grounded Large Language Models for Dual Goal Conversational Settings	Diogo Glória-Silva, Rafael Ferreira, Diogo Tavares, David Semedo, Joao Magalhaes	Long 12/2.5/.5	Oral 	In Person				Training Large Language Models (LLMs) to follow user instructions has shown to supply the LLM with ample capacity to converse fluently while being aligned with humans. Yet, it is not completely clear how an LLM can lead a plan-grounded conversation in mixed-initiative settings where instructions flow in both directions of the conversation, i.e. both the LLM and the user provide instructions to one another. In this paper, we tackle a dual goal mixed-initiative conversational setting where the LLM not only grounds the conversation on an arbitrary plan but also seeks to satisfy both a procedural plan and user instructions. The LLM is then responsible for guiding the user through the plan and, at the same time, adapting to new circumstances, answering questions, and activating safety guardrails when needed. We propose a novel LLM that grounds the dialogue on a procedural plan, can take the dialogue initiative, and enforces guardrails on the system's behavior, while also improving the LLM's responses to unexpected user behavior. Experiments in controlled settings and with real users show that the best-performing model, which we call PlanLLM, achieves a 2.1x improvement over a strong baseline. Moreover, experiments also show good generalization to unseen domains.
Session 2	2024-03-18	11:30	Carlson 	Machine Learning for NLP	3	Machine Learning for NLP	351	TESS: Text-to-Text Self-Conditioned Simplex Diffusion	Rabeeh Karimi mahabadi, Hamish Ivison, Jaesung Tae, James Henderson, Iz Beltagy, Matthew E Peters, Arman Cohan	Long 12/2.5/.5	Oral 	In Person				Diffusion models have emerged as a powerful paradigm for generation, obtaining strong performance in various continuous domains.   However, applying continuous diffusion models to natural language remains challenging due to its discrete nature and the need for a large number of diffusion steps to generate text, making diffusion-based generation expensive.  In this work, we propose Text-to-text Self-conditioned Simplex Diffusion (TESS), a text diffusion model that is fully non-autoregressive, employs a new form of self-conditioning, and applies the diffusion process on the logit simplex space rather than the learned embedding space.  Through extensive experiments on natural language understanding and generation tasks including summarization, text simplification, paraphrase generation, and question generation, we demonstrate that TESS outperforms state-of-the-art non-autoregressive models, requires fewer diffusion steps with minimal drop in performance, and is competitive with pretrained autoregressive sequence-to-sequence models.
Session 2	2024-03-18	11:45	Carlson 	Machine Learning for NLP	4	Machine Learning for NLP	446	Dynamic Masking Rate Schedules for MLM Pretraining	Zachary Ankner, Naomi Saphra, Davis Blalock, Jonathan Frankle, Matthew L Leavitt	Long 12/2.5/.5	Oral 	Unconfirmed				Most works on transformers trained with the Masked Language Modeling (MLM) objective use the original BERT model's fixed masking rate of 15%. We propose to instead dynamically schedule the masking rate throughout training. We find that linearly decreasing the masking rate over the course of pretraining improves average GLUE accuracy by up to 0.46% and 0.25% in BERT-base and BERT-large, respectively, compared to fixed rate baselines. These gains come from exposure to both high and low masking rate regimes, providing benefits from both settings. Our results demonstrate that masking rate scheduling is a simple way to improve the quality of masked language models, achieving up to a 1.89x speedup in pretraining for BERT-base as well as a Pareto improvement for BERT-large.
Session 2	2024-03-18	12:00	Carlson 	Machine Learning for NLP	5	Machine Learning for NLP	458	Gradient-Based Language Model Red Teaming	Nevan Wichers, Carson Denison, Ahmad Beirami	Long 12/2.5/.5	Oral 	In Person				Red teaming is a common strategy for identifying weaknesses in generative language models (LMs) by producing adversarial prompts that trigger models to generate unsafe responses. Red teaming is instrumental for both model alignment and evaluation, but is labor-intensive and difficult to scale when done by humans. In this paper, we present Gradient-Based Red Teaming (GBRT), a novel red teaming method for automatically generating diverse prompts that are likely to cause an LM to output unsafe responses. GBRT is a form of prompt learning, trained by scoring an LM response with a safety classifier and then backpropagating through the frozen safety classifier and LM to update the prompt. To improve the coherence of input prompts, we introduce two variants that add a realism loss and fine-tune a pretrained model to generate the prompts instead of learning the prompts directly. Our experiments show that GBRT is more effective at finding prompts that trigger an LM to generate unsafe responses than a strong reinforcement learning-based red teaming approach and works even when the LM has been fine-tuned to produce safer outputs.
Session 2	2024-03-18	12:15	Carlson 	NLP Applications	6	Machine Learning for NLP	107	A* shortest string decoding for non-idempotent semirings	Kyle Gorman, Cyril Allauzen	Long 12/2.5/.5	Oral 	In Person				Abstract: The single shortest path algorithm is undefined for weighted finite-state automata over non-idempotent semirings because such semirings do not guarantee the existence of a shortest path. However, in non-idempotent semirings admitting an order satisfying a monotonicity condition (such as the plus-times or log semirings), the shortest string is well-defined. We describe an algorithm which finds the shortest string for a weighted non-deterministic automaton over such semirings using the backwards shortest distance of an equivalent deterministic automaton (DFA) as a heuristic for A* search performed over a companion idempotent semiring, which is proven to return the shortest string. There may be exponentially more states in the DFA, but the proposed algorithm needs to visit only a small fraction of them if determinization is performed "on the fly".
Session 2	2024-03-18	11:00	Marie Louise 1 	Computational Social Science and Cultural Analytics	1	Factual Content in NLP	310	What Makes Medical Claims (Un)Verifiable? Analyzing Entity and Relation Properties for Fact Verification	Amelie Wuehrl, Yarik Menchaca Resendiz, Lara Grimminger, Roman Klinger	Long 12/2.5/.5	Oral 	In Person		Prof. Ion Androutsopoulos	ionandr@gmail.com	Verifying biomedical claims fails if no evidence can be discovered. In these cases, the fact-checking verdict remains unknown and the claim is unverifiable. To improve this situation, we have to understand if there are any claim properties that impact its verifiability. In this work we assume that entities and relations define the core variables in a biomedical claim's anatomy and analyze if their properties help us to differentiate verifiable from unverifiable claims. In a study with trained annotation experts we prompt them to find evidence for biomedical claims, and observe how they refine search queries for their evidence search. This leads to the first corpus for scientific fact verification annotated with subject--relation--object triplets, evidence documents, and fact-checking verdicts (the BEAR-FACT corpus). We find (1) that discovering evidence for negated claims (e.g., X--does-not-cause--Y) is particularly challenging. Further, we see that annotators process queries mostly by adding constraints to the search and by normalizing entities to canonical names. (2) We compare our in-house annotations with a small crowdsourcing setting where we employ both medical experts and laypeople. We find that domain expertise does not have a substantial effect on the reliability of annotations. Finally, (3), we demonstrate that it is possible to reliably estimate the success of evidence retrieval purely from the claim text (.82F$_1$), whereas identifying unverifiable claims proves more challenging (.27F$_1$)
Session 2	2024-03-18	11:15	Marie Louise 1 	Interpretability and Model Analysis in NLP	2	Factual Content in NLP	314	Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge	Xin Zhao, Naoki Yoshinaga, Daisuke Oba	Long 12/2.5/.5	Oral 	In Person				Acquiring factual knowledge for language models (LMs) in low-resource languages poses a serious challenge, thus resorting to cross-lingual transfer in multilingual LMs (ML-LMs). In this study, we ask how ML-LMs acquire and represent factual knowledge. Using the multilingual factual knowledge probing dataset, mLAMA, we first conducted a neuron investigation of ML-LMs (specifically, multilingual BERT). We then traced the roots of facts back to the knowledge source (Wikipedia) to identify the ways in which ML-LMs acquire specific facts. We finally identified three patterns of acquiring and representing facts in ML-LMs: language-independent, cross-lingual shared and transferred, and devised methods for differentiating them. Our findings highlight the challenge of maintaining consistent factual knowledge across languages, underscoring the need for better fact representation learning in ML-LMs.
Session 2	2024-03-18	11:30	Marie Louise 1 	Semantics: Sentence-level Semantics, Textual Inference and other areas	3	Factual Content in NLP	364	Rethinking Loss Functions for Fact Verification	Yuta Mukobara, Yutaro Shigeto, Masashi Shimbo	Long 12/2.5/.5	Oral 	In Person				We explore loss functions for fact verification in the FEVER shared task. While the cross-entropy loss is a standard objective for training verdict predictors, it fails to capture the heterogeneity among the FEVER verdict classes. In this paper, we develop two task-specific objectives tailored to FEVER. Experimental results confirm that the proposed objective functions outperform the standard cross-entropy. Performance is further improved when these objectives are combined with simple class weighting, which effectively overcomes the imbalance in the training data. The source code is available (https://github.com/yuta-mukobara/RLF-KGAT).
Session 2	2024-03-18	11:45	Marie Louise 1 	Semantics: Sentence-level Semantics, Textual Inference and other areas	4	Factual Content in NLP	428	Counterfactual Reasoning with Knowledge Graph Embeddings	Lena Zellinger, Andreas Stephan, Benjamin Roth	Long 12/2.5/.5	Oral 	In Person				Knowledge graph embeddings (KGEs) were originally developed to infer true but missing facts in incomplete knowledge repositories.  In this paper, we link knowledge graph completion and counterfactual reasoning via our new task CFKGR. We model the original world state as a knowledge graph, hypothetical scenarios as edges added to the graph, and plausible changes to the graph as inferences from logical rules. We create corresponding benchmark datasets, which contain diverse hypothetical scenarios with plausible changes to the original knowledge graph and facts that should be retained. We develop COULDD, a general method for adapting existing knowledge graph embeddings given a hypothetical premise, and evaluate it on our benchmark. Our results indicate that KGEs learn patterns in the graph without explicit training. We further observe that KGEs adapted with COULDD solidly detect plausible counterfactual changes to the graph that follow these patterns. An evaluation on human-annotated data reveals that KGEs adapted with COULDD are mostly unable to recognize changes to the graph that do not follow learned inference rules. In contrast, ChatGPT mostly outperforms KGEs in detecting plausible changes to the graph but has poor knowledge retention. In summary, CFKGR connects two previously distinct areas, namely KG completion and counterfactual reasoning.
Session 2	2024-03-18	12:00	Marie Louise 1 	Sentiment Analysis, Stylistic Analysis and Argument Mining	5	Factual Content in NLP	108	Multimodal Fallacy Classification in Political Debates	Eleonora Mancini, Federico Ruggeri, Paolo Torroni	Long 12/2.5/.5	Oral 	In Person				Recent advances in NLP suggest that some tasks, such as argument detection and relation classification, are better framed in a multimodal perspective. We propose multimodal argument mining for argumentative fallacy classification in political debates. To this end, we release the first corpus for multimodal fallacy classification. Our experiments show that the integration of the audio modality leads to superior classification performance. Our findings confirm that framing fallacy classification as a multimodal task is essential to capturing paralinguistic aspects of fallacious arguments.
Session 2	2024-03-18	12:15	Marie Louise 1 	Sentiment Analysis, Stylistic Analysis and Argument Mining	6	Factual Content in NLP	391	Leveraging fine-tuned Large Language Models with LoRA for Effective Claim, Claimer, and Claim Object Detection	Sotiris Kotitsas, Panagiotis Kounoudis, Eleni Koutli, Haris Papageorgiou	Long 12/2.5/.5	Oral 	In Person				Misinformation and disinformation phenomena existed long before the advent of digital technologies. The exponential use of social media platforms, whose information feeds have created the conditions for many to many communication and instant amplification of the news has accelerated the diffusion of inaccurate and misleading information. As a result, the identification of claims have emerged as a pivotal technology for combating the influence of misinformation and disinformation within news media. Most existing work has concentrated on claim analysis at the sentence level, neglecting the crucial exploration of supplementary attributes such as the claimer and the claim object of the claim or confining it by limiting its scope to a predefined list of topics. Furthermore, previous research has been mostly centered around political debates, Wikipedia articles, and COVID-19 related content. By leveraging the advanced capabilities of Large Language Models (LLMs) in Natural Language Understanding (NLU) and text generation, we propose a novel architecture utilizing LLMs finetuned with LoRA to transform the claim, claimer and claim object detection task into a Question Answering (QA) setting. We evaluate our approach in a dataset of 867 scientific news articles of 3 domains (Health, Climate Change, Nutrition) (HCN), which are human annotated with the major claim, the claimer and the object of the major claim. We also evaluate our proposed model in the benchmark dataset of NEWSCLAIMS. Experimental and qualitative results showcase the effectiveness of the proposed approach. We make our dataset publicly available to encourage further research.
Session 2	2024-03-18	11:00	Marie Louise 2  	Dialogue and Interactive Systems	1	Dialogue and Interactive Systems	26	A Comparative Multidimensional Analysis of Empathetic Systems	Andrew Lee, Jonathan K. Kummerfeld, Larry Ann, Rada Mihalcea	Long 12/2.5/.5	Oral 	In Person		Ondrej Dusek	odusek@ufal.mff.cuni.cz	Recently, empathetic dialogue systems have received significant attention.  While some researchers have noted limitations, e.g., that these systems tend to generate generic utterances, no study has systematically verified these issues. We survey 21 systems, asking what progress has been made on the task. We observe multiple limitations of current evaluation procedures. Most critically, studies tend to rely on a single non-reproducible empathy score, which inadequately reflects the multidimensional nature of empathy. To better understand the differences between systems, we comprehensively analyze each system with automated methods that are grounded in a variety of aspects of empathy. We find that recent systems lack three important aspects of empathy: specificity, reflection levels, and diversity. Based on our results, we discuss problematic behaviors that may have gone undetected in prior evaluations, and offer guidance for developing future systems.\footnote{Our experiments can be found at [Anonymous URL]}
Session 2	2024-03-18	11:15	Marie Louise 2  	Dialogue and Interactive Systems	2	Dialogue and Interactive Systems	34	Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions	Alberto Testoni, Raquel Fernández	Long 12/2.5/.5	Oral 	In Person				Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty---an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction.
Session 2	2024-03-18	11:30	Marie Louise 2  	Dialogue and Interactive Systems	3	Dialogue and Interactive Systems	56	Leveraging Implicit Feedback from Deployment Data in Dialogue	Richard Yuanzhe Pang, Stephen Roller, Kyunghyun Cho, He He, Jason E Weston	Long 12/2.5/.5	Oral 	In Person				We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.
Session 2	2024-03-18	11:45	Marie Louise 2  	Dialogue and Interactive Systems	4	Dialogue and Interactive Systems	74	Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement	Hana Kim, Kai Tzu-iunn Ong, Seoyeon Kim, Dongha Lee, Jinyoung Yeo	Long 12/2.5/.5	Oral 	Virtual				Memorizing and utilizing speakers' personas is a common practice for response generation in long-term conversations. Yet, human-authored datasets often provide uninformative persona sentences that hinder response quality. This paper presents a novel framework that leverages commonsense-based persona expansion to address such issues in long-term conversation.  While prior work focuses on not producing personas that contradict others, we focus on transforming contradictory personas into sentences that contain rich speaker information, by refining them based on their contextual backgrounds with designed strategies. As the pioneer of persona expansion in multi-session settings, our framework facilitates better response generation via human-like persona refinement. The supplementary video of our work is available at https://caffeine-15bbf.web.app/.
Session 2	2024-03-18	12:00	Marie Louise 2  	Dialogue and Interactive Systems	5	Dialogue and Interactive Systems	175	HumBEL: A Human-in-the-Loop Approach for Evaluating Demographic Factors of Language Models in Human-Machine Conversations	Anthony Sicilia, Jennifer C. Gates, Malihe Alikhani	Long 12/2.5/.5	Oral 	In Person				While demographic factors like age and gender change the way people talk, and in particular, the way people talk to machines, there is little investigation into how large pre-trained language models (LMs) can adapt to these changes. To remedy this gap, we consider how demographic factors in LM language skills can be measured to determine compatibility with a target demographic. We suggest clinical techniques from Speech Language Pathology, which has norms for acquisition of language skills in humans. We conduct evaluation with a domain expert (i.e., a clinically licensed speech language pathologist), and also propose automated techniques to complement clinical evaluation at scale. Empirically, we focus on age, finding LM capability varies widely depending on task: GPT-3.5 mimics the ability of humans ranging from age 6-15 at tasks requiring inference, and simultaneously, outperforms a typical 21 year old at memorization. GPT-3.5 also has trouble with social language use, exhibiting less than 50% of the tested pragmatic skills. Findings affirm the importance of considering demographic alignment and conversational goals when using LMs as public-facing tools. Code, data, and a package will be available.
Session 2	2024-03-18	12:15	Marie Louise 2  	Dialogue and Interactive Systems	6	Dialogue and Interactive Systems	290	SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State Tracking	Atharva Kulkarni, Bo-Hsiang Tseng, Joel Ruben Antony Moniz, Dhivya Piraviperumal, Hong Yu, Shruti Bhargava	Long 12/2.5/.5	Oral 	In Person				In-context learning with Large Language Models (LLMs) has emerged as a promising avenue of research in Dialog State Tracking (DST). However, the best-performing in-context learning methods involve retrieving and adding similar examples to the prompt, requiring access to labeled training data. Procuring such training data for a wide range of domains and applications is time-consuming, expensive, and, at times, infeasible. While zero-shot learning requires no training data, it significantly lags behind the few-shot setup. Thus, `\textit{Can we efficiently generate synthetic data for any dialogue schema to enable few-shot prompting?}' Addressing this question, we propose \method, a data generation framework tailored for DST, utilizing LLMs. Our approach only requires the dialogue schema and a few hand-crafted dialogue templates to synthesize natural, coherent, and free-flowing dialogues with DST annotations. Few-shot learning using data from {\method} results in $4-5\%$ improvement in Joint Goal Accuracy over the zero-shot baseline on MultiWOZ 2.1 and 2.4. Remarkably, our few-shot learning approach recovers nearly $98\%$ of the performance compared to the few-shot setup using human-annotated training data\footnote{Our synthetic data and code can be accessed at \\ \url{ https://github.com/apple/ml-synthdst}.}.
Session 3	2024-03-18	14:00	Carlson 	Efficient/Low-resource methods in NLP	1	Efficient/Low-resource methods in NLP	71	Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion	Aly M. Kassem, Sherif Saad	Long 12/2.5/.5	Oral 	Virtual		Yufang Hou	bnuxiaofang@gmail.com	Adversarial attacks against Language models (LMs) are a significant concern. In particular, adversarial samples exploit the model's sensitivity to small input changes. While these changes appear insignificant on the semantics of the input sample, they result in significant decay in model performance. In this paper, we propose Targeted Paraphrasing via RL (TPRL), an approach to automatically learn a policy to generate challenging samples that improve the model’s performance. TPRL leverages FLAN-T5, a language model, as a generator and employs a self-learned policy using a proximal policy optimization to generate the adversarial examples automatically. TPRL's reward is based on the confusion induced in the classifier, preserving the original text meaning through a Mutual Implication score. We demonstrate \& evaluate TPRL's effectiveness in discovering natural adversarial attacks and improving model performance through extensive experiments on four diverse NLP classification tasks via Automatic \& Human evaluation. TPRL outperforms strong baselines, exhibits generalizability across classifiers and datasets, and combines the strengths of language modeling and reinforcement learning to generate diverse and influential adversarial examples.
Session 3	2024-03-18	14:15	Carlson 	Efficient/Low-resource methods in NLP	2	Efficient/Low-resource methods in NLP	73	FAIR: Filtering of Automatically Induced Rules	Divya Jyoti Bajpai, Ayush Maheshwari, Manjesh Kumar Hanawal, Ganesh Ramakrishnan	Long 12/2.5/.5	Oral 	In Person				Availability of large annotated data can be a critical bottleneck in training machine learning algorithms successfully, especially when applied to diverse domains. Weak supervision offers a promising alternative by accelerating the creation of labeled training data using domain-specific rules. However, it requires users to write a diverse set of high-quality rules to assign labels to the unlabeled data (eg., Snorkel~\cite{bach2019snorkel}). Automatic Rule Induction (ARI) approaches such as Snuba \cite{snuba} circumvent this problem by automatically creating rules from features on a small labeled set and filtering a final set of rules from them. In the ARI approach, the crucial step is to filter out a set of a high-quality useful subset of rules from the large set of automatically created rules. In this paper, we propose an algorithm FAIR (Filtering of Automatically Induced Rules) to filter rules from a large number of automatically induced rules using submodular objective functions that account for the collective precision, coverage, and conflicts of the rule set. We experiment with three ARI approaches and five text classification datasets to validate the superior performance of our algorithm with respect to several semi-supervised label aggregation approaches. We show that our approach achieves statistically significant results in comparison to existing rule-filtering approaches. The anonymized source code is available at \url{https://anonymous.4open.science/r/FAIR-LF-Induction-9B60}.
Session 3	2024-03-18	14:30	Carlson 	Efficient/Low-resource methods in NLP	3	Efficient/Low-resource methods in NLP	130	Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora	Surangika Ranathunga, Nisansa de Silva, Velayuthan Menan, Aloka Fernando, Charitha S.M. Rathnayake	Long 12/2.5/.5	Oral 	Virtual				We conducted a detailed analysis on the quality of web-mined corpora for two low-resource languages (making three language pairs, English-Sinhala, English-Tamil and Sinhala-Tamil). We ranked each corpus according to a similarity measure and carried out an intrinsic and extrinsic evaluation on different portions of this ranked corpus. We show that there are significant quality differences between different portions of web-mined corpora and that the quality varies across languages and datasets. We also show that, for some web-mined datasets, Neural Machine Translation (NMT) models trained with their highest-ranked 25k portion can be on par with human-curated datasets.
Session 3	2024-03-18	14:45	Carlson 	Efficient/Low-resource methods in NLP	4	Efficient/Low-resource methods in NLP	148	LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions	Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji	Long 12/2.5/.5	Oral 	Unconfirmed				Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. While other similar works have been done, they are often conducted on a limited set of (usually still large) models and are not accompanied by proper evaluations. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. We also assess the model for hallucination and toxicity, and for the former, we introduce a new benchmark dataset for hallucination-inducing QA. The results demonstrate that our proposed LaMini-LM models are comparable to strong baselines while being much smaller in size.
Session 3	2024-03-18	15:00	Carlson 	Efficient/Low-resource methods in NLP	5	Efficient/Low-resource methods in NLP	222	Anchor Points: Benchmarking Models with Much Fewer Examples	Rajan Pathe Vivek, Kawin Ethayarajh, Diyi Yang, Douwe Kiela	Long 12/2.5/.5	Oral 	In Person				Modern language models often exhibit powerful but brittle behavior, leading to the development of larger and more diverse benchmarks to reliably assess their behavior. Here, we suggest that model performance can be benchmarked and elucidated with much smaller evaluation sets. We first show that in six popular language classification benchmarks, model confidence in the correct class on many pairs of points is strongly correlated across models. We build upon this phenomenon to propose Anchor Point Selection, a technique to select small subsets of datasets that capture model behavior across the entire dataset. Anchor points reliably rank models: across 87 diverse language model-prompt pairs, evaluating models using 1-30 anchor points outperforms uniform sampling and other baselines at accurately ranking models. Moreover, just a dozen anchor points can be used to estimate model per-class predictions on all other points in a dataset with low error, sufficient for gauging where the model is likely to fail. Lastly, we present Anchor Point Maps for visualizing these insights and facilitating comparisons of the performance of different models on various regions within the dataset distribution.
Session 3	2024-03-18	15:15	Carlson 	Efficient/Low-resource methods in NLP	6	Efficient/Low-resource methods in NLP	260	Aligning Large and Small Language Models via Chain-of-Thought Reasoning	Leonardo Ranaldi, Andre Freitas	Long 12/2.5/.5	Oral 	In Person				Chain-of-Thought (CoT) prompting empowers  the reasoning abilities of Large Language Models (LLMs), eliciting them to solve complex  reasoning tasks in a step-wise manner. However, these capabilities appear only in models with billions of parameters, which represent an entry barrier for many users who are constrained to operate on a smaller model scale, i.e., Small Language Models (SLMs). Although many companies are releasing LLMs of the same family with fewer parameters, these models tend not to preserve all the reasoning capabilities of the original models, including CoT reasoning.      In this paper, we propose a method for aligning and transferring reasoning abilities between larger to smaller Language Models. By using an Instruction-tuning-CoT method, that is, an Instruction-tuning designed around CoT-Demonstrations, we enable the SLMs to generate multi-step controlled reasoned answers when they are elicited with the CoT mechanism. Hence, we instruct a smaller Language Model using outputs generated by more robust models belonging to the same family or not, evaluating the impact across different types of models. Results obtained on question-answering and mathematical reasoning benchmarks show that LMs instructed via the Instruction-tuning CoT method produced by LLMs outperform baselines within both in-domain and out-domain scenarios.
Session 3	2024-03-18	14:00	Marie Louise 1 	Discourse and Pragmatics	1	Discourse and Syntactic Parsing	211	Unleashing the Power of Discourse-Enhanced Transformers for Propaganda Detection	Alexander Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov	Long 12/2.5/.5	Oral 	In Person		Dr Lorella Viola	l.viola@vu.nl	The prevalence of information manipulation online has created a need for propaganda detection systems. Such systems have typically focused on the surface words, ignoring the linguistic structure. Here we aim to bridge this gap. In particular, we present the first attempt at using discourse analysis for the task. We consider both paragraph-level and token-level classification and we propose a discourse-aware Transformer architecture. Our experiments on English and Russian demonstrate sizeable performance gains compared to a number of baselines. Moreover, our ablation study emphasizes the importance of specific types of discourse features, and our in-depth analysis reveals a strong correlation between propaganda instances and discourse spans.
Session 3	2024-03-18	14:15	Marie Louise 1 	Discourse and Pragmatics	2	Discourse and Syntactic Parsing	438	Can we obtain significant success in RST discourse parsing by using Large Language Models?	Aru Maekawa, Tsutomu Hirao, Hidetaka Kamigaito, Manabu Okumura	Long 12/2.5/.5	Oral 	In Person				Recently, decoder-only pre-trained large language models (LLMs), with several tens of billion parameters, have significantly impacted a wide range of natural language processing (NLP) tasks. While encoder-only or encoder-decoder pre-trained language models have already proved to be effective in discourse parsing, the extent to which LLMs can perform this task remains an open research question. Therefore, this paper explores how beneficial such LLMs are for Rhetorical Structure Theory (RST) discourse parsing. Here, the parsing process for both fundamental top-down and bottom-up strategies is converted into prompts, which LLMs can work with. We employ Llama 2 and fine-tune it with QLoRA, which has fewer parameters that can be tuned. Experimental results on three benchmark datasets, RST-DT, Instr-DT, and the GUM corpus, demonstrate that Llama 2 with 70 billion parameters in the bottom-up strategy obtained state-of-the-art (SOTA) results with significant differences. Furthermore, our parsers demonstrated generalizability when evaluated on RST-DT, showing that, in spite of being trained with the GUM corpus, it obtained similar performances to those of existing parsers trained with RST-DT.
Session 3	2024-03-18	14:30	Marie Louise 1 	Semantics: Sentence-level Semantics, Textual Inference and other areas	3	Discourse and Syntactic Parsing	182	Improving Generalization in Semantic Parsing by Increasing Natural Language Variation	Irina Saparina, Mirella Lapata	Long 12/2.5/.5	Oral 	In Person				Text-to-SQL semantic parsing has made significant progress in recent years, with various models demonstrating impressive performance on the challenging Spider benchmark. However, it has also been shown that these models often struggle to generalize even when faced with small perturbations of previously (accurately) parsed expressions. This is mainly due to the linguistic form of questions in Spider which are overly specific, unnatural, and display limited variation. In this work, we use data augmentation to enhance the robustness of text-to-SQL parsers against natural language variations. Existing approaches generate question reformulations either via models trained on Spider or only introduce local changes. In contrast, we leverage the capabilities of large language models to generate more realistic and diverse questions. Using only a few prompts, we achieve a two-fold increase in the number of questions in Spider. Training on this augmented    dataset yields substantial improvements on a range of evaluation sets, including robustness benchmarks and out-of-domain data.
Session 3	2024-03-18	14:45	Marie Louise 1 	Syntax: Tagging, Chunking and Parsing	4	Discourse and Syntactic Parsing	159	From Partial to Strictly Incremental Constituent Parsing	Ana Ezquerro, Carlos Gómez-Rodríguez, David Vilares	Long 12/2.5/.5	Oral 	In Person				We study incremental constituent parsers to assess their capacity to output trees based on prefix representations alone. Guided by strictly left-to-right generative language models and tree-decoding modules, we build parsers that adhere to a strong definition of incrementality across languages. This builds upon work that asserted incrementality, but that mostly only enforced it on either the encoder or the decoder. Finally, we conduct an analysis against non-incremental and partially incremental models.
Session 3	2024-03-18	15:00	Marie Louise 1 	Syntax: Tagging, Chunking and Parsing	5	Discourse and Syntactic Parsing	207	A Truly Joint Neural Architecture for Segmentation and Parsing	Danit Yshaayahu Levi, Reut Tsarfaty	Long 12/2.5/.5	Oral 	In Person				Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the {\em joint morpho-syntactic hypothesis}, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline.   In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.
Session 3	2024-03-18	15:15	Marie Louise 1 	Syntax: Tagging, Chunking and Parsing	6	Discourse and Syntactic Parsing	Journal paper: CL1	Generation and Polynomial Parsing of Graph Languages with Non-Structural Reentrancies	Johanna Björklund, Frank Drewes, Anna Jonsson	Long 12/2.5/.5	Oral 	In Person				#N/A
Session 3	2024-03-18	14:00	Marie Louise 2  	Multimodality and Language Grounding to Vision, Robotics and Beyond	1	Multimodality	170	The Role of Data Curation in Image Captioning	Wenyan Li, Jonas F. Lotz, Chen Qiu, Desmond Elliott	Long 12/2.5/.5	Oral 	In Person		Prof. Petr Sojka	sojka@fi.muni.cz	Image captioning models are typically trained by treating all samples equally, neglecting to account for mismatched or otherwise difficult data points. In contrast, recent work has shown the effectiveness of training models by scheduling the data using curriculum learning strategies. This paper contributes to this direction by actively curating difficult samples in datasets without increasing the total number of samples. We explore the effect of using three data curation methods within the training process: complete removal of an sample, caption replacement, or image replacement via a text-to-image generation model. Experiments on the Flickr30K and COCO datasets with the BLIP and BEiT-3 models demonstrate that these curation methods do indeed yield improved image captioning models, underscoring their efficacy.
Session 3	2024-03-18	14:15	Marie Louise 2  	Multimodality and Language Grounding to Vision, Robotics and Beyond	2	Multimodality	233	VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection	Arushi Rai, Adriana Kovashka	Long 12/2.5/.5	Oral 	In Person				The use of large-scale vision-language datasets is limited for object detection due to the negative impact of label noise on localization. Prior methods have shown how such large-scale datasets can be used for pretraining, which can provide initial signal for localization, but is insufficient without clean bounding-box data for at least some categories. We propose a technique to "vet" labels extracted from noisy captions, and use them for weakly-supervised object detection (WSOD), without any bounding boxes. We analyze and annotate the types of label noise in captions in our Caption Label Noise dataset, and train a classifier that predicts if an extracted label is actually present in the image or not. Our classifier generalizes across dataset boundaries and across categories. We compare the classifier to nine baselines on five datasets, and demonstrate that it can improve WSOD without label vetting by 30\% (31.2 to 40.5 mAP when evaluated on PASCAL VOC). See dataset at: https://github.com/arushirai1/CLaNDataset.
Session 3	2024-03-18	14:30	Marie Louise 2  	Multimodality and Language Grounding to Vision, Robotics and Beyond	3	Multimodality	476	Text-Guided Image Clustering	Andreas Stephan, Lukas Miklautz, Kevin Sidak, Jan Philip Wahle, Bela Gipp, Claudia Plant, Benjamin Roth	Long 12/2.5/.5	Oral 	In Person				Image clustering divides a collection of images into meaningful groups, typically interpreted post-hoc via human-given annotations. Those are usually in the form of text, begging the question of using text as an abstraction for image clustering. Current image clustering methods, however, neglect the use of generated textual descriptions. We, therefore, propose \textit{Text-Guided Image Clustering}, i.e., generating text using image captioning and visual question-answering (VQA) models and subsequently clustering the generated text. Further, we introduce a novel approach to inject task- or domain knowledge for clustering by prompting VQA models. Across eight diverse image clustering datasets, our results show that the obtained text representations often outperform image features. Additionally, we propose a counting-based cluster explainability method. Our evaluations show that the derived keyword-based explanations describe clusters better than the respective cluster accuracy suggests. Overall, this research challenges traditional approaches and paves the way for a paradigm shift in image clustering, using generated text.
Session 3	2024-03-18	14:45	Marie Louise 2  	Speech recognition, text-to-speech and spoken language understanding	4	Multimodality	70	Towards Hierarchical Spoken Language Disfluency Modeling	Jiachen Lian, Gopala Anumanchipalli	Long 12/2.5/.5	Oral 	In Person				Speech dysfluency modeling is the bottleneck for both speech therapy and language learning. However, there is no AI solution to systematically tackle this problem. We first propose to define the concept of dysfluent speech and dysfluent speech modeling. We then present Hierarchical Unconstrained Dysfluency Modeling (H-UDM) approach that addresses both dysfluency transcription and detection to eliminate the need for extensive manual annotation. Furthermore, we introduce a simulated dysfluent dataset called VCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our experimental results demonstrate the effectiveness and robustness of our proposed methods in both transcription and detection tasks.
Session 3	2024-03-18	15:00	Marie Louise 2  	Speech recognition, text-to-speech and spoken language understanding	5	Multimodality	282	Improving Acoustic Word Embeddings through Correspondence Training of Self-supervised Speech Representations	Amit Meghanani, Thomas Hain	Long 12/2.5/.5	Oral 	Virtual 				Acoustic word embeddings (AWEs) are vector representations of spoken words. An effective method for obtaining AWEs is the Correspondence Auto-Encoder (CAE). In the past, the CAE method has been associated with traditional MFCC features. Representations obtained from self-supervised learning (SSL)-based speech models such as HuBERT, Wav2vec2, etc., are outperforming MFCC in many downstream tasks. However, they have not been well studied in the context of learning AWEs. This work explores the effectiveness of CAE with SSL-based speech representations to obtain improved AWEs. Additionally, the capabilities of SSL-based speech models are explored in cross-lingual scenarios for obtaining AWEs. Experiments are conducted on five languages: Polish, Portuguese, Spanish, French, and English. HuBERT-based CAE model achieves the best results for word discrimination in all languages, despite HuBERT being pre-trained on English only. Also, the HuBERT-based CAE model works well in cross-lingual settings. It outperforms MFCC-based CAE models trained on the target languages when trained on one source language and tested on target languages.
Session 3	2024-03-18	15:15	Marie Louise 2  	Speech recognition, text-to-speech and spoken language understanding	6	Multimodality	362	STORiCo: Storytelling TTS for Hindi with Character Voice Modulation	Pavan Kalyan Tankala, Preethi Jyothi, Preeti Rao, Pushpak Bhattacharyya	Long 12/2.5/.5	Oral 	In Person				We present a new Hindi text-to-speech (TTS) dataset and demonstrate its utility for the expressive synthesis of children's audio stories. The dataset comprises narration by a single female speaker who modifies her voice to produce different story characters. Annotation for dialogue identification, character labelling, and character attribution are provided, all of which are expected to facilitate the learning of character voice and speaking styles. Experiments are conducted using different versions of the annotated dataset that enable training a multi-speaker TTS model on the single-speaker data. Subjective tests show that the multi-speaker model improves expressiveness and character voice consistency compared to the baseline single-speaker TTS. With the multi-speaker model, objective evaluations show comparable word error rates, better speaker voice consistency, and higher correlations with ground-truth emotion attributes. We release a new 16.8 hours storytelling speech dataset in Hindi and propose effective solutions for expressive TTS with narrator voice modulation and character voice consistency.
Session 4	2024-03-18	16:00	Carlson 	Information Extraction	1	Information Extraction	25	OpenPI2.0: An Improved Dataset for Entity Tracking in Texts	Li Zhang, Hainiu Xu, Abhinav Kommula, Chris Callison-Burch, Niket Tandon	Long 12/2.5/.5	Oral 	In Person		Lilja Øvrelid	liljao@ifi.uio.no	Much texts describe a changing world (e.g., procedures, stories, newswires), and understanding them requires tracking how entities change. An earlier dataset, OpenPI, provided crowdsourced annotations of entity state changes in text. However, a major limitation was that those annotations were free-form and did not identify salient changes, hampering model evaluation. To overcome these limitations, we present an improved dataset, OpenPI2.0, where entities and attributes are fully canonicalized and additional entity salience annotations are added. On our fairer evaluation setting, we find that current state-of-the-art language models are far from competent. We also show that using state changes of salient entities as a chain-of-thought prompt, downstream performance is improved on tasks such as question answering and classical planning, outperforming the setting involving all related entities indiscriminately. We offer OpenPI2.0 for the continued development of models that can understand the dynamics of entities in text.
Session 4	2024-03-18	16:15	Carlson 	Information Extraction	2	Information Extraction	43	MultiMUC: Multilingual Template Filling on MUC-4	William Gantt, Shabnam Behzad, Hannah YoungEun An, Yunmo Chen, Aaron Steven White, Benjamin Van Durme, Mahsa Yarmohammadi	Long 12/2.5/.5	Oral 	In Person				We introduce MultiMUC, the first multilingual parallel corpus for template filling, comprising translations of the classic MUC-4 template filling benchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. We obtain automatic translations from a strong multilingual machine translation system and manually project the original English annotations into each target language. For all languages, we also provide human translations for key portions of the dev and test splits. Finally, we present baselines on MultiMUC both with state-of-the-art template filling models for MUC-4 and with ChatGPT. We release MUC-4 and the supervised baselines to facilitate further work on document-level information extraction in multilingual settings.
Session 4	2024-03-18	16:30	Carlson 	Information Extraction	3	Information Extraction	217	3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding	Yihua Zhu, Hidetoshi Shimodaira	Long 12/2.5/.5	Oral 	In Person				The main objective of Knowledge Graph (KG) embeddings is to learn low-dimensional representations of entities and relations, enabling the prediction of missing facts. A significant challenge in achieving better KG embeddings lies in capturing relation patterns, including symmetry, antisymmetry, inversion, commutative composition, non-commutative composition, hierarchy, and multiplicity. This study introduces a novel model called 3H-TH (3D Rotation and Translation in Hyperbolic space) that captures these relation patterns simultaneously. In contrast, previous attempts have not achieved satisfactory performance across all the mentioned properties at the same time. The experimental results demonstrate that the new model outperforms existing state-of-the-art models in terms of accuracy, hierarchy property, and other relation patterns in low-dimensional space, meanwhile performing similarly in high-dimensional space.
Session 4	2024-03-18	16:45	Carlson 	Information Extraction	4	Information Extraction	440	Ameli: Enhancing Multimodal Entity Linking with Fine-Grained Attributes	Barry Menglong Yao, Sijia Wang, Yu Chen, Qifan Wang, Minqian Liu, Zhiyang Xu, Licheng Yu, Lifu Huang	Long 12/2.5/.5	Oral 	In Person				We propose attribute-aware multimodal entity linking, where the input consists of a mention described with a text paragraph and images, and the goal is to predict the corresponding target entity from a multimodal knowledge base (KB) where each entity is also accompanied by a text description, visual images, and a collection of attributes that present the meta-information of the entity in a structured format.   To facilitate this research endeavor, we construct Ameli, encompassing a new multimodal entity linking benchmark dataset that contains 16,735 mentions described in text and associated with 30,472 images, and a multimodal knowledge base that covers 34,690 entities along with 177,873 entity images and 798,216 attributes. To establish baseline performance on Ameli, we experiment with several state-of-the-art architectures for multimodal entity linking and further propose a new approach that incorporates attributes of entities into disambiguation. Experimental results and extensive qualitative analysis demonstrate that extracting and understanding the attributes of mentions from their text descriptions and visual images play a vital role in multimodal entity linking. To the best of our knowledge, we are the first to integrate attributes in the multimodal entity linking task. The programs, model checkpoints, and the dataset are publicly available at https://github.com/VT-NLP/Ameli.
Session 4	2024-03-18	17:00	Carlson 	Information Extraction	5	Information Extraction	470	Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition	Jonas Golde, Felix Hamborg, Alan Akbik	Long 12/2.5/.5	Oral 	In Person				Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples. One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.'' In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types. In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type. In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning. To this end, we leverage an entity linking benchmark to create a dataset with orders of magnitude of more distinct entity types and descriptions as currently used datasets. We find that this increased signal yields strong results in zero- and few-shot NER in in-domain, cross-domain, and even cross-lingual settings. Our findings indicate significant potential for improving few-shot NER through heuristical data-based optimization.
Session 4	2024-03-18	17:15	Carlson 	Semantics: Sentence-level Semantics, Textual Inference and other areas	6	Information Extraction	240	Chaining Event Spans for Temporal Relation Grounding	Jongho Kim, Dohyeon Lee, Minsoo Kim, seung-won hwang	Long 12/2.5/.5	Oral 	In Person				Accurately understanding temporal relations between events is a critical building block of diverse tasks, such as temporal reading comprehension (TRC) and relation extraction (TRE). For example in TRC, we need to understand the temporal semantic differences between the following two questions that are lexically near-identical: “What finished right before the decision?” or “What finished right after the decision?”. To discern the two questions, existing solutions have relied on answer overlaps as a proxy label to contrast similar and dissimilar questions. However, we claim that answer overlap can lead to unreliable results, due to spurious overlaps of two dissimilar questions with coincidentally identical answers. To address the issue, we propose a novel approach that elicits proper reasoning behaviors through a module for predicting time spans of events. We introduce the Timeline Reasoning Network (TRN) operating in a two-step inductive reasoning process: In the first step model initially answers each question with semantic and syntactic information. The next step chains multiple questions on the same event to predict a timeline, which is then used to ground the answers. Results on the TORQUE and TB-dense, TRC, and TRE tasks respectively, demonstrate that TRN outperforms previous methods by effectively resolving the spurious overlaps using the predicted timeline.
Session 4	2024-03-18	16:00	Marie Louise 1 	Discourse and Pragmatics	1	Linguistic Theory and Insights	433	Syntactic Preposing and Discourse Relations	Yunfang Dong, Xixian Liao, Bonnie L. Webber	Long 12/2.5/.5	Oral 	In Person		Dr. Daisy Rosenblum	daisy.rosenblum@ubc.ca	Over 15 years ago, Ward & Birner (2006) suggested that non-canonical constructions in English can serve both to mark information status and to structure the information flow of discourse. One such construction is preposing, where a phrasal constituent appears to the left of its canonical position, typically sentence-initially. But computational work on discourse has, to date, ignored non-canonical syntax. We take account of non-canonical syntax by providing quantitative evidence relating NP/PP preposing to discourse relations. The evidence comes from an LLM mask-filling task that compares the predictions when a mask is inserted between the arguments of an implicit inter-sentential discourse relation --- first, when the right-hand argument (Arg2) starts with a preposed constituent, and again, when that constituent is in canonical (post-verbal) position. Results show that (1) the top-ranked mask-fillers in the preposed case agree more often with "gold" annotations in the Penn Discourse TreeBank than they do in the latter case, and (2) preposing in Arg2 can affect the distribution of discourse-relational senses.
Session 4	2024-03-18	16:15	Marie Louise 1 	Linguistic Theories, Cognitive Modeling and Psycholinguistics	2	Linguistic Theory and Insights	171	Large-Scale Bitext Corpora Provide New Evidence for Cognitive Representations of Spatial Terms	Peter Viechnicki, Kevin Duh, Anthony Kostacos, Barbara Landau	Long 12/2.5/.5	Oral 	In Person				Recent evidence from cognitive science suggests that there exist two classes of cognitive representations within the spatial terms of a language, one represented geometrically (e.g., above, below) and the other functionally (e.g., on, in). It has been hypothesized that geometric terms are more constrained and are mastered relatively early in language learning, whereas functional terms are less constrained and are mastered over longer time periods (Landau, 2016). One consequence of this hypothesis is that these two classes should exhibit different cross-linguistic variability, which is supported by human elicitation studies.      In this work we present to our knowledge the first corpus-based empirical test of this hypothesis. We develop a pipeline for extracting, isolating, and aligning spatial terms in basic locative constructions from parallel text. Using Shannon entropy to measure the variability of spatial term use across eight languages, we find supporting evidence that variability in functional terms differs significantly from that of geometric terms. We also perform latent variable modeling and find support for the division of spatial terms into geometric and functional classes.
Session 4	2024-03-18	16:30	Marie Louise 1 	Linguistic Theories, Cognitive Modeling and Psycholinguistics	3	Linguistic Theory and Insights	335	Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models	Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz	Long 12/2.5/.5	Oral 	In Person				The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine "intelligence." Recently, many anecdotal examples were used to suggest that newer Large Language Models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation of 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.
Session 4	2024-03-18	16:45	Marie Louise 1 	Linguistic Theories, Cognitive Modeling and Psycholinguistics	4	Linguistic Theory and Insights	405	Frequency Explains the Inverse Correlation of Large Language Models' Size, Training Data Amount, and Surprisal's Fit to Reading Times	Byung-Doh Oh, Shisen Yue, William Schuler	Long 12/2.5/.5	Oral 	In Person				Recent studies have shown that as Transformer-based language models become larger and are trained on very large amounts of data, the fit of their surprisal estimates to naturalistic human reading times degrades. The current work presents a series of analyses showing that word frequency is a key explanatory factor underlying these two trends. First, residual errors from four language model families on four corpora show that the inverse correlation between model size and fit to reading times is the strongest on the subset of least frequent words, which is driven by excessively accurate predictions of larger model variants. Additionally, training dynamics reveal that during later training steps, all model variants learn to predict rare words and that larger model variants do so more accurately, which explains the detrimental effect of both training data amount and model size on fit to reading times. Finally, a feature attribution analysis demonstrates that larger model variants are able to accurately predict rare words based on both an effectively longer context window size as well as stronger local associations compared to smaller model variants. Taken together, these results indicate that Transformer-based language models' surprisal estimates diverge from human-like expectations due to the superhumanly complex associations they learn for predicting rare words.
Session 4	2024-03-18	17:00	Marie Louise 1 	Phonology, Morphology, and Word Segmentation	5	Linguistic Theory and Insights	149	Automated Cognate Detection as a Supervised Link Prediction Task with Cognate Transformer	V.S.D.S.Mahesh Akavarapu, Arnab Bhattacharya	Long 12/2.5/.5	Oral 	In Person				Identification of cognates across related languages is one of the primary problems in historical linguistics. Automated cognate identification is helpful for several downstream tasks including identifying sound correspondences, proto-language reconstruction, phylogenetic classification, etc. Previous state-of-the-art methods are mostly based on distributions of phonemes computed across multilingual wordlists and make little use of the cognacy labels that define links among cognate clusters. In this paper, we present a transformer-based architecture inspired by computational biology for the task of automated cognate detection. Beyond a certain amount of supervision, this method performs better than the existing methods, and shows steady improvement with further increase in supervision proving the efficacy of utilizing the labeled information. We also demonstrate that accepting multiple sequence alignments as input and having an end-to-end architecture with link prediction head saves much computation time while simultaneously yielding superior performance.
Session 4	2024-03-18	17:15	Marie Louise 1 	Semantics: Sentence-level Semantics, Textual Inference and other areas	6	Linguistic Theory and Insights	51	Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models	Erik Arakelyan, Zhaoqi Liu, Isabelle Augenstein	Long 12/2.5/.5	Oral 	Unconfirmed				Recent studies of the emergent capabilities of transformer-based Natural Language Understanding (NLU) models have indicated that they have an understanding of lexical and compositional semantics. We provide evidence that suggests these claims should be taken with a grain of salt: we find that state-of-the-art Natural Language Inference (NLI) models are sensitive towards minor semantics preserving surface-form variations, which lead to sizable inconsistent model decisions during inference. Notably, this behaviour differs from valid and in-depth comprehension of compositional semantics, however does neither emerge when evaluating model accuracy on standard benchmarks nor when probing for syntactic, monotonic, and logically robust reasoning. We propose a novel framework to measure the extent of semantic sensitivity. To this end, we evaluate NLI models on adversarially generated examples containing minor semantics-preserving surface-form input noise. This is achieved using conditional text generation, with the explicit condition that the NLI model predicts the relationship between the original and adversarial inputs as a symmetric equivalence entailment. We systematically study the effects of the phenomenon across NLI models for $\text{\emph{in-}}$ and $\text{\emph{out-of-}}$ domain settings. Our experiments show that semantic sensitivity causes performance degradations of $12.92\%$ and $23.71\%$ average over $\text{\emph{in-}}$ and $\text{\emph{out-of-}}$ domain settings, respectively. We further perform ablation studies, analysing this phenomenon across models, datasets, and variations in inference and show that semantic sensitivity can lead to major inconsistency within model predictions.
Session 4	2024-03-18	16:00	Marie Louise 2  	Dialogue and Interactive Systems	1	Opinion, Sentiment and Emotion	325	Improving Contrastive Learning in Emotion Recognition in Conversation via Data Augmentation and Decoupled Neutral Emotion	Yujin Kang, Yoon-Sik Cho	Long 12/2.5/.5	Oral 	In Person		Gabriella Lapesa?	gabriella.lapesa@gesis.org	Emotion recognition in conversation (ERC) has attracted much attention due to its wide applications. While consistent improvement is being made in this area, inevitable challenge comes from the dataset. The ERC dataset exhibits significantly imbalanced emotion distribution. While the utterances with neutral emotion predominate the data, this emotion label is always treated the same as other emotion labels in current approaches. To address the problem caused by the dataset, we propose a supervised contrastive learning specifically oriented for ERC task. We employ a novel data augmentation method emulating the emotion dynamics in a conversation and formulate supervised contrastive learning method tailored for ERC addressing the predominance and the ambiguity of neutral emotion. Experimental results on four benchmark datasets demonstrate the effectiveness of our approach.
Session 4	2024-03-18	16:15	Marie Louise 2  	NLP Applications	2	Opinion, Sentiment and Emotion	213	Predicting Client Emotions and Therapist Interventions in Psychotherapy Dialogues	Tobias Mayer, Neha Warikoo, Amir Eliassaf, Dana Atzil-Slonim, Iryna Gurevych	Long 12/2.5/.5	Oral 	Unconfirmed				Natural Language Processing (NLP) can advance psychotherapy research by scaling up therapy dialogue analysis as well as by allowing researchers to examine client-therapist interactions in detail. Previous studies have mainly either explored the clients' behavior or the therapists' intervention in dialogues. Yet, modelling conversations from both dialogue participants is crucial to understanding the therapeutic interaction. This study explores speaker contribution-based dialogue acts at the utterance-level; i.e, the therapist - Intervention Prediction (IP) and the client - Emotion Recognition (ER) in psychotherapy using a pan-theoretical schema. We perform experiments with fine-tuned language models and light-weight adapter solutions on a Hebrew dataset. We deploy the results from our ER model predictions in investigating the coherence between client self-reports on emotion and the utterance-level emotions. Our best adapters achieved on-par performance with fully fine-tuned models, at 0.64 and 0.66 micro F1 for IP and ER, respectively. In addition, our analysis identifies ambiguities within categorical clinical coding, which can be used to fine-tune the coding schema. Finally, our results indicate a positive correlation between client self-reports and utterance-level emotions.
Session 4	2024-03-18	16:30	Marie Louise 2  	Sentiment Analysis, Stylistic Analysis and Argument Mining	3	Opinion, Sentiment and Emotion	199	“Define Your Terms” : Enhancing Efficient Offensive Speech Classification with Definition	Huy Nghiem, Umang Gupta, Fred Morstatter	Long 12/2.5/.5	Oral 	Virtual				The propagation of offensive content through social media channels has garnered attention of the research community. Multiple works have proposed various semantically related yet subtle distinct categories of offensive speech. In this work, we explore meta-learning approaches to leverage the diversity of offensive speech corpora to enhance their reliable and efficient detection. We propose a joint embedding architecture that incorporates the input's label and definition for classification via Prototypical Network. Our model achieves at least 75% of the maximal F1-score while using less than 10% of the available training data across 4 datasets. Our experimental findings also provide a case study of training strategies valuable to combat resource scarcity.
Session 4	2024-03-18	16:45	Marie Louise 2  	Sentiment Analysis, Stylistic Analysis and Argument Mining	4	Opinion, Sentiment and Emotion	257	Unsupervised stance detection for social media discussions: A generic baseline	Maia Sutter, Antoine Gourru, Amine Trabelsi, Christine Largeron	Long 12/2.5/.5	Oral 	In Person				With the ever-growing use of social media to express opinions on the national and international stage, unsupervised methods of stance detection are increasingly important to handle the task without costly annotation of data. The current unsupervised state-of-the-art models are designed for specific network types, either homophilic or heterophilic, and they fail to generalize to both. In this paper, we first analyze the generalization ability of recent baselines to these two very different network types. Then, we conduct extensive experiments with a baseline model based on text embeddings propagated with a graph neural network that generalizes well to heterophilic and homophilic networks. We show that it outperforms, on average, other state-of-the-art methods across the two network types. Additionally, we show that combining textual and network information outperforms using text only, and that the language model size has only a limited impact on the model performance.
Session 4	2024-03-18	17:00	Marie Louise 2  	Sentiment Analysis, Stylistic Analysis and Argument Mining	5	Opinion, Sentiment and Emotion	259	Putting Context in Context: the Impact of Discussion Structure on Text Classification	Nicolò Penzo, Antonio Longa, Bruno Lepri, Sara Tonelli, Marco Guerini	Long 12/2.5/.5	Oral 	In Person				Current text classification approaches usually focus on the content to be classified. Contextual aspects (both linguistic and extra-linguistic) are usually neglected, even in tasks based on online discussions. Still in many cases the multi-party and multi-turn nature of the context from which these elements are selected can be fruitfully exploited. In this work, we propose a series of experiments on a large dataset for stance detection in English, in which we evaluate the contribution of different types of contextual information, i.e. linguistic, structural and temporal, by feeding them as natural language input into a transformer-based model. We also experiment with different amounts of training data and analyse the topology of local discussion networks in a privacy-compliant way. Results show that structural information can be highly beneficial to text classification but only under certain circumstances (e.g. depending on the amount of training data and on discussion chain complexity). Indeed, we show that contextual information on smaller datasets from other classification tasks does not yield significant improvements. Our framework, based on local discussion networks, allows the integration of structural information while minimising user profiling, thus preserving their privacy.
Session 4	2024-03-18	17:15	Marie Louise 2  	Sentiment Analysis, Stylistic Analysis and Argument Mining	6	Opinion, Sentiment and Emotion	427	A Weak Supervision Approach for Few-Shot Aspect Based Sentiment Analysis	Robert Vacareanu, Siddharth Varia, Kishaloy Halder, Shuai Wang, Giovanni Paolini, Neha Anna John, Miguel Ballesteros, Smaranda Muresan	Long 12/2.5/.5	Oral 	In Person				We explore how weak supervision on abundant unlabeled data can be leveraged to improve few-shot performance in aspect-based sentiment analysis (ABSA) tasks. We propose a pipeline approach to construct a noisy ABSA dataset, and we use it to adapt a pre-trained sequence-to-sequence model to the ABSA tasks. We test the resulting model on three widely used ABSA datasets, before and after fine-tuning. Our proposed method preserves the full fine-tuning performance while showing significant improvements (15.84 absolute F1) in the few-shot learning scenario for the harder tasks. In zero-shot (i.e., without fine-tuning), our method outperforms the previous state of the art on the aspect extraction sentiment classification (AESC) task and is, additionally, capable of performing the harder aspect sentiment triplet extraction (ASTE) task.
Session 6	2024-03-19	10:30	Carlson 	Question Answering	1	Sentence-level Semantics	Journal paper: TACL1	Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap	Raphael Schumann, Michael Staniek, Maike Züfle, Stefan Riezler	Long 12/2.5/.5	Oral 	In Person		Dr. Eleni Metheniti	lenakmeth@gmail.com	#N/A
Session 6	2024-03-19	10:45	Carlson 	Semantics: Sentence-level Semantics, Textual Inference and other areas	2	Sentence-level Semantics	47	UNSEE: Unsupervised Non-contrastive Sentence Embeddings	Ömer Veysel Çağatan	Long 12/2.5/.5	Oral 	In Person				In this paper, we introduce UNSEE, which stands for Unsupervised Non-Contrastive Sentence Embeddings. UNSEE demonstrates better performance compared to SimCSE in the Massive Text Embedding (MTEB) benchmark. We begin by highlighting the issue of representation collapse that occurs with the replacement of contrastive objectives with non-contrastive objectives in SimCSE. Subsequently, we introduce a straightforward solution called the target network to mitigate this problem. This approach enables us to harness non-contrastive objectives while ensuring training stability and achieving performance improvements similar to those seen with contrastive objectives. We have reached peak performance in non-contrastive sentence embeddings through extensive fine-tuning and optimization. These efforts have resulted in superior sentence representation models, emphasizing the importance of careful tuning and optimization for non-contrastive objectives.
Session 6	2024-03-19	11:00	Carlson 	Semantics: Sentence-level Semantics, Textual Inference and other areas	3	Sentence-level Semantics	112	Lost in Translationese? Reducing Translation Effect Using Abstract Meaning Representation	Shira Wein, Nathan Schneider	Long 12/2.5/.5	Oral 	In Person				Translated texts bear several hallmarks distinct from texts originating in the language (“translationese”). Though individual translated texts are often fluent and preserve meaning, at a large scale, translated texts have statistical tendencies which distinguish them from text originally written in the language and can affect model performance. We frame the novel task of translationese reduction and hypothesize that Abstract Meaning Representation (AMR), a graph-based semantic representation which abstracts away from the surface form, can be used as an interlingua to reduce the amount of translationese in translated texts. By parsing English translations into an AMR and then generating text from that AMR, the result more closely resembles originally English text across three quantitative macro-level measures, without severely compromising fluency or adequacy. We compare our AMR-based approach against three other techniques based on machine translation or paraphrase generation. This work represents the first approach to reducing translationese in text and highlights the promise of AMR, given that our AMR-based approach outperforms more computationally intensive methods.
Session 6	2024-03-19	11:15	Carlson 	Semantics: Sentence-level Semantics, Textual Inference and other areas	4	Sentence-level Semantics	174	REFINER: Reasoning Feedback on Intermediate Representations	Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, Boi Faltings	Long 12/2.5/.5	Oral 	In Person				Language models (LMs) have recently shown remarkable performance on reasoning tasks by explicitly generating intermediate inferences,  e.g., chain-of-thought prompting. However, these intermediate inference steps may be inappropriate deductions from the initial context  and lead to incorrect final predictions. Here we introduce REFINER, a framework for finetuning LMs to explicitly generate intermediate reasoning steps while interacting with a critic model that provides automated feedback on the reasoning. Specifically, the critic provides structured feedback that the reasoning LM uses to iteratively improve its intermediate arguments. Empirical evaluations of REFINER on three diverse reasoning tasks show significant improvements over baseline LMs of comparable scale. Furthermore, when using GPT-3.5 or ChatGPT as the reasoner, the trained critic significantly improves reasoning without finetuning the reasoner. Finally, our critic model is trained without expensive human-in-the-loop data but can be substituted with humans at inference time.
Session 6	2024-03-19	11:30	Carlson 	Semantics: Sentence-level Semantics, Textual Inference and other areas	5	Sentence-level Semantics	326	Neuralign: A Context-Aware, Cross-Lingual and Fully-Neural Sentence Alignment System for Long Texts	Francesco Maria Molfese, Andrei Stefan Bejgu, Simone Tedeschi, Simone Conia, Roberto Navigli	Long 12/2.5/.5	Oral 	In Person				Sentence alignment -- establishing links between corresponding sentences in two related documents -- is an important NLP task with several downstream applications, such as machine translation (MT).  Despite the fact that existing sentence alignment systems have achieved promising results, their effectiveness is based on auxiliary information such as document metadata or machine-generated translations, as well as hyperparameter-sensitive techniques. Moreover, these systems often overlook the crucial role that context plays in the alignment process.  In this paper, we address the aforementioned issues and propose Neuralign: the first context-aware, end-to-end and fully-neural architecture for sentence alignment. Our system maps source and target sentences in long documents by contextualizing their sentence embeddings with respect to the other sentences in the document. We extensively evaluate Neuralign on a multilingual dataset consisting of 20 language pairs derived from the Opus project, and demonstrate that our model achieves state-of-the-art performance. To ensure reproducibility, we release our code and model checkpoints at https://github.com/Babelscape/Neuralign.
Session 6	2024-03-19	11:45	Carlson 	Semantics: Sentence-level Semantics, Textual Inference and other areas	6	Sentence-level Semantics	350	Sentence Representations via Gaussian Embedding	Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda	Long 12/2.5/.5	Oral 	In Person				Recent progress in sentence embedding, which represents a sentence's meaning as a point in a vector space, has achieved high performance on several tasks such as the semantic textual similarity (STS) task.  However, a sentence representation cannot adequately express the diverse information that sentences contain: for example, such representations cannot naturally handle asymmetric relationships between sentences.  This paper proposes GaussCSE, a Gaussian-distribution-based contrastive learning framework for sentence embedding that can handle asymmetric inter-sentential relations, as well as a similarity measure for identifying entailment relations.  Our experiments show that GaussCSE achieves performance comparable to that of previous methods on natural language inference (NLI) tasks, and that it can estimate the direction of entailment relations, which is difficult with point representations.
Session 6	2024-03-19	10:30	Marie Louise 1 	Ethics and NLP	1	Multilingual Issues	125	Centering the Speech Community	Steven Bird, Dean Yibarbuk	Long 12/2.5/.5	Oral 	Unconfirmed		Antonios Anastasopoulos	antonis@gmu.edu	How can NLP/AI practitioners engage with oral societies and develop locally appropriate language technologies? We report on our experience of working together over five years in a remote community in the far north of Australia, and how we prototyped simple language technologies to support our collaboration. We navigated different understandings of language, the functional differentiation of oral vs institutional languages, and the distinct technology opportunities for each. Our collaboration unsettled the first author's western framing of language as data for exploitation by machines, and we devised a design pattern that seems better aligned with local interests and aspirations. We call for new collaborations on the design of locally appropriate technologies for languages with primary orality.
Session 6	2024-03-19	10:45	Marie Louise 1 	Ethics and NLP	2	Multilingual Issues	147	'It's how you do things that matters'': Attending to Process to Better Serve Indigenous Communities with Language Technologies	Ned Cooper, Courtney Heldreth, Ben Hutchinson	Long 12/2.5/.5	Oral 	In Person				Indigenous languages are historically under-served by Natural Language Processing (NLP) technologies, but this is changing for some languages with the recent scaling of large multilingual models and an increased focus by the NLP community on endangered languages. This position paper explores ethical considerations in building NLP technologies for Indigenous languages, based on the premise that such projects should primarily serve Indigenous communities. We report on interviews with 17 researchers working in or with Aboriginal and/or Torres Strait Islander communities on language technology projects in Australia. Drawing on insights from the interviews, we recommend practices for NLP researchers to increase attention to the process of engagements with Indigenous communities, rather than focusing only on decontextualised artefacts.
Session 6	2024-03-19	11:00	Marie Louise 1 	Ethics and NLP	3	Multilingual Issues	462	Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test	Aditi Khandelwal, Utkarsh Agarwal, Kumar Tanmay, Monojit Choudhury	Long 12/2.5/.5	Oral 	In Person				This paper explores the moral judgment and moral reasoning abilities exhibited by Large Language Models (LLMs) across languages through the Defining Issues Test. It is a well known fact that moral judgment depends on the language in which the question is asked. We extend the work of beyond English, to 5 new languages (Chinese, Hindi, Russian, Spanish and Swahili), and probe three LLMs -- ChatGPT, GPT-4 and Llama2Chat-70B -- that shows substantial multilingual text processing and generation abilities. Our study shows that the moral reasoning ability for all models, as indicated by the post-conventional score, is substantially inferior for Hindi and Swahili, compared to Spanish, Russian, Chinese and English, while there is no clear trend for the performance of the latter four languages. The moral judgments too vary considerably by the language.
Session 6	2024-03-19	11:15	Marie Louise 1 	Semantics: Lexical	4	Multilingual Issues	42	Injecting Wiktionary to improve token-level contextual representations using contrastive learning	Anna Mosolova, Marie Candito, Carlos Ramisch	Long 12/2.5/.5	Oral 	In Person				While static word embeddings are blind to context, for lexical semantics tasks context is rather too present in contextual word embeddings, vectors of same-meaning occurrences being too different (Ethayarajh, 2019). Fine-tuning pre-trained language models (PLMs) using contrastive learning was proposed, leveraging automatically self-augmented examples (Liu et al., 2021b). In this paper, we investigate how to inject a lexicon as an alternative source of supervision, using the English Wiktionary. We also test how dimensionality reduction impacts the resulting contextual word embeddings. We evaluate our approach on the Word-In-Context (WiC) task, in the unsupervised setting (not using the training set). We achieve new SoTA result on the original WiC test set. We also propose two new WiC test sets for which we show that our fine-tuning method achieves substantial improvements. We also observe improvements, although modest, for the semantic frame induction task. Although we experimented on English to allow comparison with related work, our method is adaptable to the many languages for which large Wiktionaries exist.
Session 6	2024-03-19	11:30	Marie Louise 1 	Semantics: Lexical	5	Multilingual Issues	220	Graph-based Clustering for Detecting Semantic Change Across Time and Languages	Xianghe Ma, Michael Strube, Wei Zhao	Long 12/2.5/.5	Oral 	In Person				Despite the predominance of contextualized embeddings in NLP, approaches to detect semantic change relying on these embeddings and clustering methods underperform simpler counterparts based on static word embeddings. This stems from the poor quality of the clustering methods to produce sense clusters---which struggle to capture word senses, especially those with low frequency. This issue hinders the next step in examining how changes in word senses in one language influence another. To address this issue, we propose a graph-based clustering approach to capture nuanced changes in both high- and low-frequency word senses across time and languages, including the acquisition and loss of these senses over time. Our experimental results show that our approach substantially surpasses previous approaches in the SemEval2020 binary classification task across four languages. Moreover, we showcase the ability of our approach as a versatile visualization tool to detect semantic changes in both intra-language and inter-language setups. We make our code and data publicly available.
Session 6	2024-03-19	11:45	Marie Louise 1 	Semantics: Lexical	6	Multilingual Issues	221	Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models	Haoqiang Kang, Terra Blevins, Luke Zettlemoyer	Long 12/2.5/.5	Oral 	In Person				Pretrained Language Models (PLMs) learn rich cross-lingual knowledge and perform well on diverse tasks such as translation and multilingual word sense disambiguation (WSD) when finetuned. However, they often struggle at disambiguating word sense in a zero-shot setting. To better understand this contrast, we present a new study investigating how well PLMs capture cross-lingual word sense with Contextual Word-Level Translation (C-WLT), an extension of word-level translation that prompts the model to translate a given word in context. We find that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. Building on C-WLT, we introduce a zero-shot prompting approach for WSD, tested on 18 languages from the XL-WSD dataset. Our method outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning. This study presents a first step towards understanding how to best leverage the cross-lingual knowledge inside PLMs for robust zero-shot reasoning in any language.
Session 6	2024-03-19	10:30	Marie Louise 2  	NLP Applications	1	NLP Applications	80	NNOSE: Nearest Neighbor Occupational Skill Extraction	Mike Zhang, Rob van der Goot, Min-Yen Kan, Barbara Plank	Long 12/2.5/.5	Oral 	In Person		Prof. Thomas Francois	thomas.francois@uclouvain.be	The labor market is changing rapidly, prompting increased interest in the automatic extraction of occupational skills from text. With the advent of English benchmark job description datasets, there is a need for systems that handle their diversity well. We tackle the complexity in occupational skill datasets tasks---combining and leveraging multiple datasets for skill extraction, to identify rarely observed skills within a dataset, and overcoming the scarcity of skills across datasets. In particular, we investigate the retrieval-augmentation of language models, employing an external datastore for retrieving similar skills in a dataset-unifying manner. Our proposed method, \textbf{N}earest \textbf{N}eighbor \textbf{O}ccupational \textbf{S}kill \textbf{E}xtraction (NNOSE) effectively leverages multiple datasets by retrieving neighboring skills from other datasets in the datastore. This improves skill extraction \emph{without} additional fine-tuning. Crucially, we observe a performance gain in predicting infrequent patterns, with substantial gains of up to 30\% span-F1 in cross-dataset settings.
Session 6	2024-03-19	10:45	Marie Louise 2  	NLP Applications	2	NLP Applications	191	Generation, Distillation and Evaluation of Motivational Interviewing-Style Reflections with a Foundational Language Model	Andrew Brown, Jiading Zhu, Mohamed Abdelwahab, Alec Dong, Cindy Wang, Jonathan Rose	Long 12/2.5/.5	Oral 	In Person				Large Foundational Language Models are capable of performing many tasks at a high level but are difficult to deploy in many applications because of their size and proprietary ownership. Many will be motivated to distill specific capabilities of foundational models into smaller models that can be owned and controlled. In the development of a therapeutic chatbot, we wish to distill a capability known as reflective listening, in which a therapist produces reflections of client speech. These reflections either restate what a client has said, or connect what was said to a relevant observation, idea or guess that encourages and guides the client to continue contemplation. In this paper, we present a method for distilling the generation of reflections from a Foundational Language Model (GPT-4) into smaller models. We first show that GPT-4, using zero-shot prompting, can generate reflections at near 100% success rate, superior to all previous methods. Using reflections generated by GPT-4, we fine-tune different sizes of the GPT-2 family. The GPT-2-small model achieves 83% success on a hold-out test set and the GPT-2 XL achieves 90% success. We also show that GPT-4 can help in the labor-intensive task of evaluating the quality of the distilled models, using it as a zero-shot classifier. Using triple-human review as a guide, the classifier achieves a Cohen-Kappa of 0.66, a substantial inter-rater reliability figure.
Session 6	2024-03-19	11:00	Marie Louise 2  	NLP Applications	3	NLP Applications	308	Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical Study	Zhaoyue Sun, Gabriele Pergola, Byron C Wallace, Yulan He	Long 12/2.5/.5	Oral 	In Person				With the advent of large language models (LLMs), there has been growing interest in exploring their potential for medical applications. This research aims to investigate the ability of LLMs, specifically ChatGPT, in the context of pharmacovigilance event extraction, of which the main goal is to identify and extract adverse events or potential therapeutic events from textual medical sources. We conduct extensive experiments to assess the performance of ChatGPT in the pharmacovigilance event extraction task, employing various prompts and demonstration selection strategies. The findings demonstrate that while ChatGPT demonstrates reasonable performance with appropriate demonstration selection strategies, it still falls short compared to fully fine-tuned small models. Additionally, we explore the potential of leveraging ChatGPT for data augmentation. However, our investigation reveals that the inclusion of synthesized data into fine-tuning may lead to a decrease in performance, possibly attributed to noise in the ChatGPT-generated labels. To mitigate this, we explore different filtering strategies and find that, with the proper approach, more stable performance can be achieved, although constant improvement remains elusive.
Session 6	2024-03-19	11:15	Marie Louise 2  	NLP Applications	4	NLP Applications	320	LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text	Dor Bernsohn, Gil Semo, Yaron Vazana, Gila Hayat, Ben Hagag, Joel Niklaus, Rohit Saha, Kyryl Truskovskyi	Long 12/2.5/.5	Oral 	In Person				In this study, we focus on two main tasks, the first for detecting legal violations within unstructured textual data, and the second for associating these violations with potentially affected individuals. We constructed two datasets using Large Language Models (LLMs) which were subsequently validated by domain expert annotators. Both tasks were designed specifically for the context of class-action cases. The experimental design incorporated fine-tuning models from the BERT family and open-source LLMs, and conducting few-shot experiments using closed-source LLMs. Our results, with an F1-score of 62.69% (violation identification) and 81.02% (associating victims), show that our datasets and setups can be used for both tasks. Finally, we publicly release the datasets and the code used for the experiments in order to advance further research in the area of legal natural language processing (NLP).
Session 6	2024-03-19	11:30	Marie Louise 2  	NLP Applications	5	NLP Applications	345	Accurate and Well-Calibrated ICD Code Assignment Through Attention Over Diverse Label Embeddings	Goncalo Emanuel Cavaco Gomes, Isabel Pereira Coutinho, Bruno Martins	Long 12/2.5/.5	Oral 	In Person				Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches. This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work. We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently. The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms. Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance. Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification.
Session 6	2024-03-19	11:45	Marie Louise 2  	NLP Applications	6	NLP Applications	411	Presentations by the Humans and For the Humans: Harnessing LLMs for Generating Persona-Aware Slides from Documents	Ishani Mondal, Shwetha S, Anandhavelu Natarajan, Aparna Garimella, Sambaran Bandyopadhyay, Jordan Lee Boyd-Graber	Long 12/2.5/.5	Oral 	Virtual				Scientific papers and slides are two different representations of the same underlying information, but both require substantial work to prepare. While there had been prior efforts on automating document-to-slides generation, there is still a pressing need of customizing the presentation of content aligning with the persona of target audience or duration of presentation. This paper first introduces the concept of end-user specification-aware document to slides conversion that incorporates end-user specifications into the conversion process. For this, we initially introduce a new dataset reuse the existing SciDuet dataset consisting of pairs of papers and corresponding slides decks from recent years’ *ACL conferences to create four persona-aware configurations. Secondly, we present Persona-Aware-D2S, a novel approach by finetuning LLMs using target audience feedback to create persona-aware slides from scientific documents. Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of target audience.
Session 7	2024-03-19	14:00	Carlson 	Question Answering	1	Question Answering	28	Few-Shot Data Synthesis for Open Domain Multi-Hop Question Answering	Mingda Chen, Xilun Chen, Wen-tau Yih	Long 12/2.5/.5	Oral 	In Person		Mr. Mohammad Aliannejadi	m.aliannejadi@uva.nl	Few-shot learning for open domain multi-hop question answering typically relies on the in-context learning capability of large language models (LLMs). While powerful, these LLMs usually contain tens or hundreds of billions of parameters, making them rather inefficient at inference time. To improve performance of smaller language models, we propose a data synthesis framework for multi-hop question answering that requires less than 10 human-annotated question answer pairs. Our framework depends only on rich, naturally-occurring relationships among documents and is built upon the data generation functions parameterized by LLMs and prompts. We synthesize millions of multi-hop questions and claims to finetune language models, evaluated on popular benchmarks for multi-hop question answering and fact verification. Empirically, our approach improves model performance significantly, allowing the finetuned models to be competitive with GPT-3.5 based approaches while being almost one-third the size in parameter count.
Session 7	2024-03-19	14:15	Carlson 	Question Answering	2	Question Answering	269	CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration	Rachneet Singh Sachdeva, Martin Tutek, Iryna Gurevych	Long 12/2.5/.5	Oral 	In Person				In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of smaller language models (SLMs) with automatically generated counterfactual (CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain (OOD) performance of SLMs in the extractive question answering (QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise explanations.
Session 7	2024-03-19	14:30	Carlson 	Question Answering	3	Question Answering	323	Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models	Lukáš Mikula, Michal Štefánik, Marek Petrovič, Petr Sojka	Long 12/2.5/.5	Oral 	In Person				While the Large Language Models (LLMs) dominate a majority of language understanding tasks, previous work shows that some of these results are supported by modelling spurious correlations of training datasets. Authors commonly assess model robustness by evaluating their models on out-of-distribution (OOD) datasets of the same task, but these datasets might share the bias of the training dataset. We propose a simple method for measuring a scale of models' reliance on any identified spurious feature and assess the robustness towards a large set of known and newly found prediction biases for various pre-trained models and debiasing methods in Question Answering (QA). We find that the reported OOD gains of debiasing methods can not be explained by mitigated reliance on biased features, suggesting that biases are shared among different QA datasets. We further evidence this by measuring that performance of OOD models depends on bias features comparably to the ID model. Our findings motivate future work to refine the reports of LLMs' robustness to a level of known spurious features.
Session 7	2024-03-19	14:45	Carlson 	Question Answering	4	Question Answering	343	Defending Against Disinformation Attacks in Open-Domain Question Answering	Orion Weller, Aleem Khan, Nathaniel Weir, Dawn Lawrie, Benjamin Van Durme	Long 12/2.5/.5	Oral 	In Person				Recent work in open-domain question answering (ODQA) has shown that adversarial poisoning of the search collection can cause large drops in accuracy for production systems. However, little to no work has proposed methods to defend against these attacks. To do so, we rely on the intuition that redundant information often exists in large corpora. To find it, we introduce a method that uses query augmentation to search for a diverse set of passages that could answer the original question but are less likely to have been poisoned. We integrate these new passages into the model through the design of a novel confidence method, comparing the predicted answer to its appearance in the retrieved contexts (what we call Confidence from Answer Redundancy, i.e. CAR). Together these methods allow for a simple but effective way to defend against poisoning attacks that provides gains of nearly 20% exact match across varying levels of data poisoning/knowledge conflicts.
Session 7	2024-03-19	15:00	Carlson 	Question Answering	5	Question Answering	388	Graph Guided Question Answer Generation for Procedural Question-Answering	Hai X. Pham, Isma Hadji, Xinnuo Xu, Ziedune Degutyte, Jay Rainey, Evangelos Kazakos, Afsaneh Fazly, Georgios Tzimiropoulos, Brais Martinez	Long 12/2.5/.5	Oral 	In Person				In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller. 2) semantic coverage is the key indicator for downstream QA performance. Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model. In contrast, the higher semantic coverage provided by our method is critical for QA performance.
Session 7	2024-03-19	15:15	Carlson 	Question Answering	6	Question Answering	432	Pre-Training Methods for Question Reranking	Stefano Campese, Ivano Lauriola, Alessandro Moschitti	Long 12/2.5/.5	Oral 	In Person				One interesting approach to Question Answering (QA) is to search for semantically similar questions, which have been answered before. This task is different from answer retrieval as it focuses on questions rather than only on the answers, therefore it requires different model training on different data.  In this work, we introduce a novel unsupervised pre-training method specialized for retrieving and ranking questions. This leverages (i) knowledge distillation from a basic question retrieval model, and (ii) new pre-training task and objective for learning to rank questions in terms of their relevance with the query. Our experiments show that (i) the proposed technique achieves state-of-the-art performance on QRC and Quora-match datasets, and (ii) the benefit of combining re-ranking and retrieval models.
Session 7	2024-03-19	14:00	Marie Louise 1 	Multilinguality and Language Diversity 1	1	Multilinguality and Language Diversity 1	44	Multilingual Gradient Word-Order Typology from Universal Dependencies	Emi Baylor, Esther Ploeger, Johannes Bjerva	Long 12/2.5/.5	Oral 	In Person		Sara Stymne	sara.stymne@lingfil.uu.se	While information from the field of linguistic typology has the potential to improve performance on NLP tasks, reliable typological data is a prerequisite. Existing typological databases, including WALS and Grambank, suffer from inconsistencies primarily caused by their categorical format. Furthermore, typological categorisations by definition differ significantly from the continuous nature of phenomena, as found in natural language corpora. In this paper, we introduce a new seed dataset made up of continuous-valued data, rather than categorical data, that can better reflect the variability of language. While this initial dataset focuses on word-order typology, we also present the methodology used to create the dataset, which can be easily adapted to generate data for a broader set of features and languages.
Session 7	2024-03-19	14:15	Marie Louise 1 	Resources and Evaluation	2	Multilinguality and Language Diversity 1	31	SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects	David Ifeoluwa Adelani, Hannah Liu, Xiaoyu Shen, Nikita Vassilyev, Jesujoba Oluwadara Alabi, Yanke Mao, Haonan Gao, En-Shiun Annie Lee	Long 12/2.5/.5	Oral 	In Person				Despite the progress in building multilingual language models, evaluation is often limited to a few languages with available datasets which excludes a large number of low-resource languages.   In this paper, we create SIB-200---a large-scale open-sourced benchmark dataset for topic classification in 205 languages and dialects to address the lack of evaluation dataset for Natural Language Understanding (NLU). For many of the languages covered in SIB-200, this is the first publicly available evaluation dataset for NLU. The dataset is based on Flores-200 machine translation corpus. We annotated the English portion of the dataset and extended the sentence-level annotation to the remaining 204 languages covered in the corpus. Despite the simplicity of this task, our evaluation in full-supervised setting, cross-lingual transfer setting and prompting of large language model setting show that there is still a large gap between the performance of high-resource and low-resource languages when multilingual evaluation is scaled to numerous world languages. We found that languages unseen during the pre-training of multilingual language models, languages from under-represented families (like Nilotic and Altantic-Congo), and languages from the regions of Africa, Americas, Oceania and South East Asia, often have the lowest performance on our topic classification dataset. We hope our dataset %will   encourages a more inclusive evaluation of multilingual language models on a more diverse set of languages.
Session 7	2024-03-19	14:30	Marie Louise 1 	Resources and Evaluation	3	Multilinguality and Language Diversity 1	146	Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations	Prince Jha, Krishanu Maity, Raghav Jain, Apoorv Verma, Sriparna Saha, Pushpak Bhattacharyya	Long 12/2.5/.5	Oral 	Virtual 				Internet memes have gained significant influence in communicating political, psychological, and sociocultural ideas. While meme are often humorous, there has been a rise in the use of memes for trolling and cyberbullying. Although a wide variety of effective deep learning-based models have been developed for detecting offensive multimodal memes, only a few works have been done on explainability aspect. Recent laws like "right to explanations" of General Data Protection Regulation, have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we introduce MultiBully-Ex, the first benchmark dataset for multimodal explanation from code-mixed cyberbullying memes. Here, both visual and textual modalities are highlighted to explain why a given meme is cyberbullying. A Contrastive Language-Image Pretraining (CLIP) projection based multimodal shared-private multitask approach has been proposed for visual and textual explanation of a meme. Experimental results demonstrate that training with multimodal explanations improves performance in generating textual justifications and more accurately identifying the visual evidence supporting a decision with reliable performance improvements.
Session 7	2024-03-19	14:45	Marie Louise 1 	Resources and Evaluation	4	Multilinguality and Language Diversity 1	206	M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection	Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Chenxi Whitehouse, OSAMA MOHAMMED AFZAL, Tarek Mahmoud, Toru Sasaki, Thomas Arnold, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov	Long 12/2.5/.5	Oral 	In Person				Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark M4, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4
Session 7	2024-03-19	15:00	Marie Louise 1 	Resources and Evaluation	5	Multilinguality and Language Diversity 1	236	Kardeş-NLU: Transfer to Low-Resource Languages with Big Brother's Help -- A Benchmark and Evaluation for Turkic Languages	Lütfi Kerem Senel, Benedikt Ebing, Konul Baghirova, Hinrich Schuetze, Goran Glavaš	Long 12/2.5/.5	Oral 	Unconfirmed				Cross-lingual transfer (XLT) driven by massively multilingual language models (mmLMs) has been shown largely ineffective for low-resource (LR) target languages with little (or no) representation in mmLM's pretraining, especially if they are linguistically distant from the high-resource (HR) source language. Much of the recent focus in XLT research has been dedicated to \textit{LR language families}, i.e., families without any HR languages (e.g., families of African languages or indigenous languages of the Americas). In this work, in contrast, we investigate a configuration that is arguably of practical relevance for more of the world's languages: XLT to LR languages that do have a close HR relative. To explore the extent to which a HR language can facilitate transfer to its LR relatives, we (1) introduce Karde\c{s}-NLU, an evaluation benchmark with language understanding datasets in five LR Turkic languages: Azerbaijani, Kazakh, Kyrgyz, Uzbek, and Uyghur; and (2) investigate (a) intermediate training and (b) fine-tuning strategies that leverage Turkish in XLT to these target languages. Our experimental results show that both - integrating Turkish in intermediate training and in downstream fine-tuning - yield substantial improvements in XLT to LR Turkic languages. Finally, we benchmark cutting-edge instruction-tuned large language models on Karde\c{s}-NLU, showing that their performance is highly task- and language-dependent.
Session 7	2024-03-19	15:15	Marie Louise 1 	Resources and Evaluation	6	Multilinguality and Language Diversity 1	292	Translation Errors Significantly Impact Low-Resource Languages in Cross-Lingual Learning	Ashish Sunil Agrawal, Barah Fazili, Preethi Jyothi	Long 12/2.5/.5	Oral 	In Person				Popular benchmarks (e.g., XNLI) used to evaluate cross-lingual language understanding consist of parallel versions of English evaluation sets in multiple target languages created with the help of professional translators. When creating such parallel data, it is critical to ensure high-quality translations for all target languages for an accurate characterization of cross-lingual transfer. In this work, we find that translation inconsistencies \emph{do exist} and interestingly they \emph{disproportionally impact low-resource languages} in XNLI. To identify such inconsistencies, we propose measuring the gap in performance between zero-shot evaluations on the human-translated and machine-translated target text across multiple target languages; relatively large gaps are indicative of translation errors. We also corroborate that translation errors exist for two target languages, namely Hindi and Urdu, by doing a manual reannotation of human-translated test instances in these two languages and finding poor agreement with the original English labels these instances were supposed to inherit.
Session 7	2024-03-19	14:00	Marie Louise 2  	Generation	1	Generation	201	CEV-LM: Controlled Edit Vector Language Model for Shaping Natural Language Generations	Samraj Moorjani, ADIT KRISHNAN, Hari Sundaram	Long 12/2.5/.5	Oral 	Virtual		Naoki Yoshinaga	ynaga@iis.u-tokyo.ac.jp	As large-scale language models become the standard for text generation, there is a greater need to tailor the generations to be more or less concise, targeted, and informative, depending on the audience/application. Existing control approaches primarily adjust the semantic (e.g., emotion, topics), structural (e.g., syntax tree, parts-of-speech), and lexical (e.g., keyword/phrase inclusion) properties of text, but are insufficient to accomplish complex objectives such as pacing which control the complexity and readability of the text. In this paper, we introduce CEV-LM - a lightweight, semi-autoregressive language model that utilizes constrained edit vectors to control three complementary metrics (speed, volume, and circuitousness) that quantify the shape of text (e.g., pacing of content). We study an extensive set of state-of-the-art CTG models and find that CEV-LM provides significantly more targeted and precise control of these three metrics while preserving semantic content, using less training data, and containing fewer parameters.
Session 7	2024-03-19	14:15	Marie Louise 2  	Generation	2	Generation	210	Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation	Kun Zhou, Yifan Li, Xin Zhao, Ji-Rong Wen	Long 12/2.5/.5	Oral 	Unconfirmed				Recently, continuous diffusion models (CDM) have been introduced into non-autoregressive (NAR) text-to-text generation.   However, the discrete nature of text increases the difficulty of CDM to generate coherent and fluent texts, and also causes the incompatibility problem between CDM and advanced NLP techniques, especially the popular pre-trained language models~(PLMs).  To solve it, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM) into NAR text-to-text generation and integrates BART to improve the performance.  By revising the decoding process of BART and the typical settings of DDM, we unify the inference process of BART and the denoising process of DDM into the same NAR masked tokens recovering task.  In this way, DDM can rely on BART to perform denoising, which can benefit from both the rich pre-learned knowledge of BART and the iterative refining paradigm of DDM.  Besides, we also propose the iterative self-prompting strategy to further improve the generation quality.  Experimental results on 7 datasets show that our approach can outperform competitive NAR methods, and even surpass autoregressive methods.  Our code and data are released at \url{https://github.com/RUCAIBox/DiffusionNAT}.
Session 7	2024-03-19	14:30	Marie Louise 2  	Generation	3	Generation	312	A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation	Phillip Schneider, Manuel Klettner, Elena Simperl, Florian Matthes	Long 12/2.5/.5	Oral 	In Person				Generating natural language text from graph-structured data is essential for conversational information seeking. Semantic triples derived from knowledge graphs can serve as a valuable source for grounding responses from conversational agents by providing a factual basis for the information they communicate. This is especially relevant in the context of large language models, which offer great potential for conversational interaction but are prone to hallucinating, omitting, or producing conflicting information. In this study, we conduct an empirical analysis of conversational large language models in generating natural language text from semantic triples. We compare four large language models of varying sizes with different prompting techniques. Through a series of benchmark experiments on the WebNLG dataset, we analyze the models' performance and identify the most common issues in the generated predictions. Our findings show that the capabilities of large language models in triple verbalization can be significantly improved through few-shot prompting, post-processing, and efficient fine-tuning techniques, particularly for smaller models that exhibit lower zero-shot performance.
Session 7	2024-03-19	14:45	Marie Louise 2  	Generation	4	Generation	322	Exploring Data Augmentation in Neural DRS-to-Text Generation	Muhammad Saad Amin, Luca Anselma, Alessandro Mazzei	Long 12/2.5/.5	Oral 	Unconfirmed				Neural networks are notoriously data-hungry. This represents an issue in cases where data are scarce such as in low-resource languages. Data augmentation is a technique commonly used in computer vision to provide neural networks with more data and increase their generalization power. When dealing with data augmentation for natural language, however, simple data augmentation techniques similar to the ones used in computer vision such as rotation and cropping cannot be employed because they would generate ungrammatical texts.   Thus, data augmentation needs a specific design in the case of neural logic-to-text systems, especially for a structurally rich input format such as the ones used for meaning representation. This is the case of the neural natural language generation for Discourse Representation Structures (DRS-to-Text), where the logical nature of DRS needs a specific design of data augmentation. In this paper, we adopt a novel approach in DRS-to-Text to selectively augment a training set with new data by adding and varying two specific lexical categories, i.e. proper and common nouns. In particular, we propose using WordNet supersenses to produce new training sentences using both in-and-out-of-context nouns. We present a number of experiments for evaluating the role played by augmented lexical information. The experimental results prove the effectiveness of our approach for data augmentation in DRS-to-Text generation.
Session 7	2024-03-19	15:00	Marie Louise 2  	Generation	5	Generation	417	Small Language Models Improve Giants by Rewriting Their Outputs	Giorgos Vernikos, Arthur Brazinskas, Jakub Adamek, Jonathan Mallinson, Aliaksei Severyn, Eric Malmi	Long 12/2.5/.5	Oral 	In Person				Despite the impressive performance of large language models (LLMs), they  often lag behind specialized models in various tasks. LLMs only use a fraction  of the existing training data for in-context learning, while task-specific  models harness the full dataset for fine-tuning. In this work, we tackle the  problem of leveraging training data to improve the performance of LLMs without  fine-tuning. Our approach directly targets LLM predictions without requiring  access to their weights. We create a pool of candidates from the LLM through  few-shot prompting and we employ a compact model, the LM-corrector (LMCor),  specifically trained to merge these candidates to produce an enhanced output.  Our experiments on four natural language generation tasks demonstrate that even  a small LMCor model (250M) substantially improves the few-shot performance of  LLMs (62B), matching and even outperforming standard fine-tuning. Furthermore,  we illustrate the robustness of LMCor against different prompts, thereby  minimizing the need for extensive prompt engineering. Finally, we show that  LMCor can be seamlessly integrated with different LLMs at inference, serving as  a plug-and-play module to improve their performance.
Session 7	2024-03-19	15:15	Marie Louise 2  	NLP Applications	6	Generation	183	Text-to-Code Generation with Modality-relative Pre-training	Fenia Christopoulou, Guchun Zhang, Gerasimos Lampouras	Long 12/2.5/.5	Oral 	In Person				Large pre-trained language models have recently been expanded and applied to programming language tasks with great success, often through further pre-training of a strictly-natural language model--where training sequences typically contain both natural and (linearised) programming language. Such approaches effectively map both modalities of the sequence into the same embedding space. However, programming language keywords (e.g. ``while'') often have very strictly defined semantics. As such, transfer learning from their natural language usage may not necessarily be beneficial to their code application and vise versa. Assuming an already pre-trained language model, in this work we investigate how sequence tokens can be adapted and represented differently, depending on which modality they belong to, and to the ultimate benefit of the downstream task. We experiment with separating embedding spaces between modalities during further model pre-training with modality-relative training objectives. We focus on text-to-code generation and observe consistent improvements across two backbone models and two test sets, measuring pass@$k$ and a novel incremental variation.
Session 8	2024-03-19	16:00	Carlson 	Information Retrieval and Text Mining	1	Information Retrieval and Text Mining	50	Fréchet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels	Negar Arabzadeh, Charles L. A. Clarke	Long 12/2.5/.5	Oral 	In Person		Prof. Dr. David E Losada	david.losada@usc.es	The rapid advancement of natural language processing, information retrieval (IR), computer vision, and other technologies has presented significant challenges in evaluating the performance of these systems. One of the main challenges is the scarcity of human-labeled data, which hinders the fair and accurate assessment of these systems. In this work, we specifically focus on evaluating IR systems with sparse labels, borrowing from recent research on evaluating computer vision tasks.  taking inspiration from the success of using Fréchet Inception Distance (FID) in assessing text-to-image generation systems. We propose leveraging the Fréchet Distance to measure the distance between the distributions of relevant judged items and retrieved results. Our experimental results on MS MARCO V1 dataset and TREC Deep Learning Tracks query sets demonstrate the effectiveness of the Fréchet Distance as a metric for evaluating IR systems,   particularly in settings where a few labels are available.  This approach contributes to the advancement of evaluation methodologies in real-world scenarios such as the assessment of generative IR systems.
Session 8	2024-03-19	16:15	Carlson 	Information Retrieval and Text Mining	2	Information Retrieval and Text Mining	203	HiGen: Hierarchy-Aware Sequence Generation for Hierarchical Text Classification	Vidit Jain, Mukund Rungta, Yuchen Zhuang, Yue Yu, Zeyu Wang, Mu Gao, Jeffrey Skolnick, Chao Zhang	Long 12/2.5/.5	Oral 	In Person				Hierarchical text classification (HTC) is a complex subtask under multi-label text classification, characterized by a hierarchical label taxonomy and data imbalance. The best-performing models aim to learn a static representation by combining document and hierarchical label information. However, the relevance of document sections can vary based on the hierarchy level, necessitating a dynamic document representation. To address this, we propose HiGen, a text-generation-based framework utilizing language models to encode dynamic text representations. We introduce a level-guided loss function to capture the relationship between text and label name semantics. Our approach incorporates a task-specific pretraining strategy, adapting the language model to in-domain knowledge and significantly enhancing performance for classes with limited examples. Furthermore, we present a new and valuable dataset called ENZYME, designed for HTC, which comprises articles from PubMed with the goal of predicting Enzyme Commission (EC) numbers. Through extensive experiments on the ENZYME dataset and the widely recognized WOS and NYT datasets, our methodology demonstrates superior performance, surpassing existing approaches while efficiently handling data and mitigating class imbalance. We release our code and dataset here: https://github.com/viditjain99/HiGen.
Session 8	2024-03-19	16:30	Carlson 	Information Retrieval and Text Mining	3	Information Retrieval and Text Mining	218	Geo-Encoder: A Chunk-Argument Bi-Encoder Framework for Chinese Geographic Re-Ranking	Yong Cao, Ruixue Ding, Boli Chen, Xianzhi Li, Min Chen, Daniel Hershcovich, Pengjun Xie, Fei Huang	Long 12/2.5/.5	Oral 	In Person				Chinese geographic re-ranking task aims to find the most relevant addresses among retrieved candidates, which is crucial for location-related services such as navigation maps. Unlike the general sentences, Chinese geographic contexts are closely intertwined with geographical concepts, from general spans (e.g., province) to specific spans (e.g., road). Given this feature, we propose an innovative framework, namely Geo-Encoder, to more effectively integrate Chinese geographical semantics into re-ranking pipelines. Our methodology begins by employing off-the-shelf tools to associate text with geographical spans, treating them as chunking units. Then, we present a multi-task learning module to simultaneously acquire an effective attention matrix that determines chunk contributions to geographic representations. Furthermore, we put forth an asynchronous update mechanism for the proposed task, aiming to guide the model to focus on specific chunks. Experiments on two Chinese benchmark datasets, show that the Geo-Encoder achieves significant improvements when compared to state-of-the-art baselines. Notably, it leads to a substantial improvement in the Hit@1 score of MGEO-BERT, increasing it by 6.22% from 62.76 to 68.98 on the GeoTES dataset.
Session 8	2024-03-19	16:45	Carlson 	Information Retrieval and Text Mining	4	Information Retrieval and Text Mining	252	A Comprehensive Survey of Sentence Representations: From the BERT Epoch to the CHATGPT Era and Beyond	Abhinav Ramesh Kashyap, Thanh-Tung Nguyen, Viktor Schlegel, Stefan Winkler, See-Kiong Ng, Soujanya Poria	Long 12/2.5/.5	Oral 	In Person				Sentence representations are a critical component in NLP applications such as retrieval, question answering, and text classification. They capture the meaning of a sentence, enabling machines to understand and reason over human language. In recent years, significant progress has been made in developing methods for learning sentence representations, including unsupervised, supervised, and transfer learning approaches. However there is no literature review on sentence representations till now. In this paper, we provide an overview of the different methods for sentence representation learning, focusing mostly on deep learning models. We provide a systematic organization of the literature, highlighting the key contributions and challenges in this area. Overall, our review highlights the importance of this area in natural language processing, the progress made in sentence representation learning, and the challenges that remain. We conclude with directions for future research, suggesting potential avenues for improving the quality and efficiency of sentence representations.
Session 8	2024-03-19	17:00	Carlson 	Information Retrieval and Text Mining	5	Information Retrieval and Text Mining	342	NevIR: Negation in Neural Information Retrieval	Orion Weller, Dawn Lawrie, Benjamin Van Durme	Long 12/2.5/.5	Oral 	In Person				Negation is a common everyday phenomena and has been a consistent area of weakness for language models (LMs). Although the Information Retrieval (IR) community has adopted LMs as the backbone of modern IR architectures, there has been little to no research in understanding how negation impacts neural IR. We therefore construct a straightforward benchmark on this theme: asking IR models to rank two documents that differ only by negation. We show that the results vary widely according to the type of IR architecture: cross-encoders perform best, followed by late-interaction models, and in last place are bi-encoder and sparse neural architectures. We find that most current information retrieval models do not consider negation, performing similarly or worse than randomly ranking. We show that although the obvious approach of continued fine-tuning on a dataset of contrastive documents containing negations increases performance (as does model size), there is still a large gap between machine and human performance.
Session 8	2024-03-19	17:15	Carlson 	Information Retrieval and Text Mining	6	Information Retrieval and Text Mining	444	Generative Dense Retrieval: Memory Can Be a Burden	Peiwen Yuan, Xinglin Wang, Shaoxiong Feng, Boyuan Pan, Yiwei Li, Heda Wang, Xupeng Miao, Kan Li	Long 12/2.5/.5	Oral 	Unconfirmed				Generative Retrieval (GR), autoregressively decoding relevant document identifiers given a query, has been shown to perform well under the setting of small-scale corpora. By memorizing the document corpus with model parameters, GR implicitly achieves deep interaction between query and document. However, such a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for fine-grained features of documents; (2) Memory confusion gets worse as the corpus size increases; (3) Huge memory update costs for new documents. To alleviate these problems, we propose the Generative Dense Retrieval (GDR) paradigm. Specifically, GDR first uses the limited memory volume to achieve inter-cluster matching from query to relevant document clusters. Memorizing-free matching mechanism from Dense Retrieval (DR) is then introduced to conduct fine-grained intra-cluster matching from clusters to relevant documents. The coarse-to-fine process maximizes the advantages of GR's deep interaction and DR's scalability. Besides, we design a cluster identifier constructing strategy to facilitate corpus memory and a cluster-adaptive negative sampling strategy to enhance the intra-cluster mapping ability. Empirical results show that GDR obtains an average of 3.0 R@100 improvement on NQ dataset under multiple settings and has better scalability.
Session 8	2024-03-19	16:00	Marie Louise 1 	Multilinguality and Language Diversity 2	1	Multilinguality and Language Diversity 2	94	Code-Switched Language Identification is Harder Than You Think	Laurie Burchell, Alexandra Birch, Robert Peter Thompson, Kenneth Heafield	Long 12/2.5/.5	Oral 	In Person		Mrs. Marie Candito	marie.candito@gmail.com	Code switching (CS) is a very common phenomenon in written and spoken communication, but is handled poorly by many NLP applications. Looking to the application of building CS corpora, we explore CS language identification for corpus building. We make the task more realistic by scaling it to more languages and considering models with simpler architectures for faster inference. We also reformulate the task as a sentence-level multi-label tagging problem to make it more tractable. Having defined the task, we investigate three reasonable architectures for this task and define metrics which better reflect desired performance. We present empirical evidence that no current approach is adequate, and finally provide recommendations for future work in this area.
Session 8	2024-03-19	16:15	Marie Louise 1 	Multilinguality and Language Diversity	2	Multilinguality and Language Diversity 2	184	No Error Left Behind: Multilingual Grammatical Error Correction with Pre-trained Translation Models	Agnes Luhtaru, Elizaveta Korotkova, Mark Fishel	Long 12/2.5/.5	Oral 	In Person				Grammatical Error Correction (GEC) enhances language proficiency and promotes effective communication, but research has primarily centered around English. We propose a simple approach to multilingual and low-resource GEC by exploring the potential of multilingual machine translation (MT) models for error correction. We show that MT models are not only capable of error correction out-of-the-box, but that they can also be fine-tuned to even better correction quality. Results show the effectiveness of this approach, with our multilingual model outperforming similar-sized mT5-based models and even competing favourably with larger models.
Session 8	2024-03-19	16:30	Marie Louise 1 	Multilinguality and Language Diversity	3	Multilinguality and Language Diversity 2	413	ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks	Bolei Ma, Ercong Nie, Shuzhou Yuan, Helmut Schmid, Michael Färber, Frauke Kreuter, Hinrich Schuetze	Long 12/2.5/.5	Oral 	In Person				Prompt-based methods have been successfully applied to multilingual pretrained language models for zero-shot cross-lingual understanding. However, most previous studies primarily focused on sentence-level classification tasks, and only a few considered token-level labeling tasks such as Named Entity Recognition (NER) and Part-of-Speech (POS) tagging. In this paper, we propose Token-Level Prompt Decomposition (ToPro), which facilitates the prompt-based method for token-level sequence labeling tasks. The ToPro method decomposes an input sentence into single tokens and applies one prompt template to each token. Our experiments on multilingual NER and POS tagging datasets demonstrate that ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuning in zero-shot cross-lingual transfer, especially for languages that are typologically different from the source language English. Our method also attains state-of-the-art performance when employed with the mT5 model. Besides, our exploratory study in multilingual large language models shows that ToPro performs much better than the current in-context learning method. Overall, the performance improvements show that ToPro could potentially serve as a novel and simple benchmarking method for sequence labeling tasks.
Session 8	2024-03-19	16:45	Marie Louise 1 	Multilinguality and Language Diversity	4	Multilinguality and Language Diversity 2	468	Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in Multilingual Language Models	Sara Rajaee, Christof Monz	Long 12/2.5/.5	Oral 	In Person				Recent advances in training multilingual language models on large datasets seem to have shown promising results in knowledge transfer across languages and achieve high performance on downstream tasks. However, we question to what extent the current evaluation benchmarks and setups accurately measure zero-shot cross-lingual knowledge transfer. In this work, we challenge the assumption that high zero-shot performance on target tasks reflects high cross-lingual ability by introducing more challenging setups involving instances with multiple languages. Through extensive experiments and analysis, we show that the observed high performance of multilingual models can be largely attributed to factors not requiring the transfer of actual linguistic knowledge, such as task- and surface-level knowledge. More specifically, we observe what has been transferred across languages is mostly data artifacts and biases, especially for low-resource languages. Our findings highlight the overlooked drawbacks of existing cross-lingual test data and evaluation setups, calling for a more nuanced understanding of the cross-lingual capabilities of multilingual models.
Session 8	2024-03-19	17:00	Marie Louise 1 	Phonology, Morphology, and Word Segmentation	5	Multilinguality and Language Diversity 2	102	Quantifying the Hyperparameter Sensitivity of Neural Networks for Character-level Sequence-to-Sequence Tasks	Adam Wiemerslage, Kyle Gorman, Katharina von der Wense	Long 12/2.5/.5	Oral 	In Person				Hyperparameter tuning, the process of searching for suitable hyperparameters, becomes more difficult as the computing resources required to train neural networks continue to grow. This topic continues to receive little attention and discussion---much of it hearsay---despite its obvious importance. We attempt to formalize hyperparameter sensitivity using two metrics: similarity-based sensitivity and performance-based sensitivity. We then use these metrics to quantify two such claims: (1) transformers are more sensitive to hyperparameter choices than LSTMs and (2) transformers are particularly sensitive to batch size. We conduct experiments on two different character-level sequence-to-sequence tasks and find that, indeed, the transformer is slightly more sensitive to hyperparameters according to both of our metrics. However, we do not find that it is more sensitive to batch size in particular.
Session 8	2024-03-19	17:15	Marie Louise 1 	Speech recognition, text-to-speech and spoken language understanding	6	Multilinguality and Language Diversity 2	27	Multi-Level Attention Aggregation for Language-Agnostic Speaker Replication	Yejin Jeon, Gary Lee	Long 12/2.5/.5	Oral 	In Person				This paper explores the task of language-agnostic speaker replication, a novel endeavor that seeks to replicate a speaker's voice irrespective of the language they are speaking. Towards this end, we introduce a multi-level attention aggregation approach that systematically probes and amplifies various speaker-specific attributes in a hierarchical manner. Through rigorous evaluations across a wide range of scenarios including seen and unseen speakers conversing in seen and unseen lingua, we establish that our proposed model is able to achieve substantial speaker similarity, and is able to generalize to out-of-domain (OOD) cases.
Session 8	2024-03-19	16:00	Marie Louise 2  	Efficient/Low-resource methods in NLP	1	Summarization	176	LOCOST: State-Space Models for Long Document Abstractive Summarization	Florian Le Bronnec, Song Duong, Mathieu Ravaut, Alexandre Allauzen, Nancy F. Chen, Vincent Guigue, Alberto Lumbreras, Laure Soulier, patrick gallinari	Long 12/2.5/.5	Oral 	In Person		Dr Gabriele Pergola	gabriele.pergola.1@warwick.ac.uk	State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies. We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs. With a computational complexity of $\mathcal{O}(L \log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns. We evaluate our model on a series of long document abstractive summarization tasks. The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference. Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing.
Session 8	2024-03-19	16:15	Marie Louise 2  	NLP Applications	2	Summarization	57	Characterizing the Confidence of Large Language Model-Based Automatic Evaluation Metrics	Rickard Stureborg, Dimitris Alikaniotis, Yoshi Suhara	Long 12/2.5/.5	Oral 	In Person				There has recently been a growing interest in using Large Language Models (LLMs) to evaluate NLP tasks automatically. Considerable research effort has been put into improving such systems towards achieving high correlations with human judgement. However, it is still unclear what level of correlation is good enough for practical applications of LLM-based automatic evaluation systems. This paper characterizes these LLM evaluators' confidence in ranking candidate NLP models and develops a configurable Monte Carlo simulation method. We show that even automatic metrics with low correlation with human judgement can reach high-confidence rankings of candidate models with reasonable evaluation set sizes (100s of examples). Further, we describe tradeoff curves between the LLM evaluator performance (i.e., correlation with humans) and evaluation set size; loss in correlation can be compensated with modest increases in the evaluation set size. We validate our results on RoSE, a text summarization dataset, and find our estimates of confidence align with empirical observations.    Code available at https://github.com/rickardstureborg/llm-eval-confidence
Session 8	2024-03-19	16:30	Marie Louise 2  	Sentiment Analysis, Stylistic Analysis and Argument Mining	3	Summarization	309	An Empirical Analysis of Diversity in Argument Summarization	Michiel van der Meer, Piek Vossen, Catholijn M Jonker, Pradeep Kumar Murukannaiah	Long 12/2.5/.5	Oral 	In Person				Presenting high-level arguments is a crucial task for fostering participation in online societal discussions. Current argument summarization approaches miss an important facet of this task---capturing \emph{diversity}---which is important for accommodating multiple perspectives. We introduce three aspects of diversity: those of opinions, annotators, and sources.   We evaluate approaches to a popular argument summarization task called Key Point Analysis, which shows how these approaches struggle to (1) represent arguments shared by few people, (2) deal with data from various sources, and (3) align with subjectivity in human-provided annotations. We find that both general-purpose LLMs and dedicated KPA models exhibit this behavior, but have complementary strengths. Further, we observe that diversification of training data may ameliorate generalization in zero-shot cases. Addressing diversity in argument summarization requires a mix of strategies to deal with subjectivity.
Session 8	2024-03-19	16:45	Marie Louise 2  	Summarization	4	Summarization	82	On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization	Lorenzo Jaime Yu Flores, Arman Cohan	Long 12/2.5/.5	Oral 	Unconfirmed				Text summarization and simplification are among the most widely used applications of AI. However, such models are often prone to hallucination, which can result from training models on unaligned data. One efficient approach to address this issue is Loss Truncation (Kang and Hashimoto, 2020), an approach to modify the standard log loss to adaptively remove noisy examples during training. However, we find that LT alone yields a considerable number of hallucinated entities on various datasets. We study the behavior of the underlying losses between factual and non-factual examples, to understand and refine the performance of LT. We demonstrate that LT's performance is limited when the underlying assumption that noisy targets have higher NLL loss is not satisfied, and find that word-level NLL among entities provides better signal for distinguishing factuality. We then leverage this to propose a fine-grained NLL loss and fine-grained data cleaning strategies, and observe improvements in hallucination reduction across some datasets. Our work is available at https://github.com/yale-nlp/Simplification-Projects.
Session 8	2024-03-19	17:00	Marie Louise 2  	Summarization	5	Summarization	246	Fine-Grained Natural Language Inference Based Faithfulness Evaluation for Diverse Summarisation Tasks	Huajian Zhang, Yumo Xu, Laura Perez-Beltrachini	Long 12/2.5/.5	Oral 	Unconfirmed				We study existing approaches to leverage off-the-shelf Natural Language Inference (NLI) models for the evaluation of summary faithfulness and argue that these are sub-optimal due to the granularity level considered for premises and hypotheses. That is, the smaller content unit considered as hypothesis is a sentence and premises are made up of a fixed number of document sentences. We propose a novel approach, namely INFUSE, that uses a variable premise size and simplifies summary sentences into shorter hypotheses. Departing from previous studies which focus on single short document summarisation, we analyse NLI based faithfulness evaluation for diverse summarisation tasks. We introduce DiverSumm, a new benchmark comprising long form summarisation (long documents and summaries) and diverse summarisation tasks (e.g., meeting and multi-document summarisation). In experiments, INFUSE obtains superior performance across the different summarisation tasks.
Session 8	2024-03-19	17:15	Marie Louise 2  	Summarization	6	Summarization	303	Less is More for Long Document Summary Evaluation by LLMs	Yunshu Wu, Hayate Iso, Pouya Pezeshkpour, Nikita Bhutani, Estevam Hruschka	Long 12/2.5/.5	Oral 	In Person				Large Language Models (LLMs) have shown promising performance in summary evaluation tasks, yet they face challenges such as high computational costs and the \textit{Lost-in-the-Middle} problem where important information in the middle of long documents is often overlooked. To address these issues, this paper introduces a novel approach, Extract-then-Evaluate, which involves extracting key sentences from a long source document and then evaluating the summary by prompting LLMs. The results reveal that the proposed method not only significantly reduces evaluation costs but also exhibits a higher correlation with human evaluations. Furthermore, we provide practical recommendations for optimal document length and sentence extraction methods, contributing to the development of cost-effective yet more accurate methods for LLM-based text generation evaluation.
Session 9	2024-03-20	9:00	Carlson 	Ethics and NLP	1	Ethics and NLP	2	Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement	Xin Quan, Marco Valentino, Louise A. Dennis, Andre Freitas	Long 12/2.5/.5	Oral 	In Person		Prof. Monojit Choudhury	monojit.choudhury@mbzuai.ac.ae	An increasing amount of research in Natural Language Inference (NLI) focuses on the application and evaluation of Large Language Models (LLMs) and their reasoning capabilities. Despite their success, however, LLMs are still prone to factual errors and inconsistencies in their explanations, offering limited control and interpretability for inference in complex domains.   In this paper, we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques can enhance the logical validity and alignment of ethical explanations produced by LLMs. Specifically, we present an abductive-deductive framework named Logic-Explainer, which integrates LLMs with an external backward-chaining solver to refine step-wise natural language explanations and jointly verify their correctness, reduce incompleteness and minimise redundancy. An extensive empirical analysis demonstrates that Logic-Explainer can improve explanations generated via in-context learning methods and Chain-of-Thought (CoT) on challenging ethical NLI tasks, while, at the same time, producing formal proofs describing and supporting models' reasoning. As ethical NLI requires commonsense reasoning to identify underlying moral violations, our results suggest the effectiveness of neuro-symbolic methods for multi-step NLI more broadly, opening new opportunities to enhance the logical consistency, reliability, and alignment of LLMs.
Session 9	2024-03-20	9:15	Carlson 	Ethics and NLP	2	Ethics and NLP	87	MAFIA: Multi-Adapter Fused Inclusive Language Models	Prachi Jain, Ashutosh Sathe, Varun Gumma, Kabir Ahuja, Sunayana Sitaram	Long 12/2.5/.5	Oral 	In Person				Pretrained Language Models (PLMs) are widely used in NLP for various tasks. Recent studies have identified various biases that such models exhibit and have proposed methods to correct these biases. However, most of the works address a limited set of bias dimensions independently such as gender, race, or religion. Moreover, the methods typically involve finetuning the full model in order to maintain the performance on the downstream task. In this work, we aim to modularly debias a pre-trained language model across multiple dimensions. Previous works extensively explored debiasing PLMs by using limited US-centric counterfactual data augmentation (CDA). We use structured knowledge and a large generative model to build a diverse CDA across multiple bias dimensions in a semi-automated way. We highlight how existing debiasing methods do not consider interactions between multiple societal biases and propose a debiasing model that exploits the synergy amongst various societal biases and enables multi-bias debiasing simultaneously. An extensive evaluation on multiple tasks and languages demonstrates the efficacy of the approach.
Session 9	2024-03-20	9:30	Carlson 	Ethics and NLP	3	Ethics and NLP	103	Examining Gender and Racial Bias in Large Vision--Language Models Using a Novel Dataset of Parallel Images	Kathleen C. Fraser, Svetlana Kiritchenko	Long 12/2.5/.5	Oral 	In Person				Following on recent advances in large language models (LLMs) and subsequent chat models, a new wave of large vision--language models (LVLMs) has emerged. Such models can incorporate images as input in addition to text, and perform tasks such as visual question answering, image captioning, story generation, etc. Here, we examine potential gender and racial biases in such systems, based on the perceived characteristics of the people in the input images. To accomplish this, we present a new dataset PAIRS (PArallel Images for eveRyday Scenarios). The PAIRS dataset contains sets of AI-generated images of people, such that the images are highly similar in terms of background and visual content, but differ along the dimensions of gender (man, woman) and race (Black, white). By querying the LVLMs with such images, we observe significant differences in the responses according to the perceived gender or race of the person depicted.
Session 9	2024-03-20	9:45	Carlson 	Ethics and NLP	4	Ethics and NLP	165	Bias in Opinion Summarisation from Pre-training to Adaptation: A Case Study in Political Bias	Nannan Huang, Haytham M. Fayek, Xiuzhen Zhang	Long 12/2.5/.5	Oral 	In Person				Opinion summarisation aims to summarise the salient information and opinions presented in documents such as product reviews, discussion forums, and social media texts into short summaries that enable users to effectively understand the opinions therein.  Generating biased summaries has the risk of potentially swaying public opinion. Previous studies focused on studying bias in opinion summarisation using extractive models, but limited research has paid attention to abstractive summarisation models. In this study, using political bias as a case study, we first establish a methodology to quantify bias in abstractive models, then trace it from the pre-trained models to the task of summarising social media opinions using different models and adaptation methods. We find that most models exhibit intrinsic bias. Using a social media text summarisation dataset and contrasting various adaptation methods, we find that tuning a smaller number of parameters is less biased compared to standard fine-tuning; however, the diversity of topics in training data used for fine-tuning is critical.
Session 9	2024-03-20	10:00	Carlson 	Ethics and NLP	5	Ethics and NLP	180	A Prompt Response to the Demand for Automatic Gender-Neutral Translation	Beatrice Savoldi, Andrea Piergentili, Dennis Fucci, Matteo Negri, Luisa Bentivogli	Long 12/2.5/.5	Oral 	Unconfirmed				Gender-neutral translation (GNT) that avoids biased and undue binary assumptions is a pivotal challenge for the creation of more inclusive translation technologies. Advancements for this task in Machine Translation (MT), however, are hindered by the lack of dedicated parallel data, which are necessary to adapt MT systems to satisfy neutral constraints. For such a scenario, large language models offer hitherto unforeseen possibilities, as they come with the distinct advantage of being versatile in various (sub)tasks when provided with explicit instructions. In this paper, we explore this potential to automate GNT by comparing MT with the popular GPT-4 model. Through extensive manual analyses, our study empirically reveals the inherent limitations of current MT systems in generating GNTs and provides valuable insights into the potential and challenges associated with prompting for neutrality.
Session 9	2024-03-20	10:15	Carlson 	Ethics and NLP	6	Ethics and NLP	263	Uncovering Stereotypes in Large Language Models: A Task Complexity-based Approach	Hari Shrawgi, Prasanjit Rath, Tushar Singhal, Sandipan Dandapat	Long 12/2.5/.5	Oral 	In Person				Recent Large Language Models (LLMs) have unlocked unprecedented applications of AI. As these models continue to transform human life, there are growing socio-ethical concerns around their inherent stereotypes that can lead to bias in their applications. There is an urgent need for holistic bias evaluation of these LLMs. Few such benchmarks exist today and evaluation techniques that do exist are either non-holistic or may provide a false sense of security as LLMs become better at hiding their biases on simpler tasks. We address these issues with an extensible benchmark - LLM Stereotype Index (LSI). LSI is grounded on Social Progress Index, a holistic social benchmark. We also test the breadth and depth of bias protection provided by LLMs via a variety of tasks with varying complexities. Our findings show that both ChatGPT and GPT-4 have strong inherent prejudice with respect to nationality, gender, race, and religion. The exhibition of such issues becomes increasingly apparent as we increase task complexity. Furthermore, GPT-4 is better at hiding the biases, but when displayed it is more significant. Our findings highlight the harms and divide that these LLMs can bring to society if we do not take very diligent care in their use.
Session 9	2024-03-20	9:00	Marie Louise 1 	Machine Translation	1	Machine Translation	33	Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding	Rico Sennrich, Jannis Vamvas, Alireza Mohammadshahi	Long 12/2.5/.5	Oral 	In Person		Hermann Ney	ney@cs.rwth-aachen.de	Hallucinations and off-target translation remain unsolved problems in MT, especially for low-resource languages and massively multilingual models. In this paper, we introduce two related methods to mitigate these failure cases with a modified decoding objective, without either requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. Experiments on the massively multilingual models M2M-100 (418M) and SMaLL-100 show that these methods suppress hallucinations and off-target translations, reducing the number of translations with segment-level chrF2 below 10 by 67-83% on average across 57 tested translation directions. In a proof of concept on out-of-English translation, we also show that we can suppress off-target translations with large language models. We release code upon acceptance.
Session 9	2024-03-20	9:15	Marie Louise 1 	Machine Translation	2	Machine Translation	40	How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?	Danni Liu, Jan Niehues	Long 12/2.5/.5	Oral 	In Person				Customizing machine translation models to comply with desired attributes (e.g., formality or grammatical gender) is a well-studied topic. However, most current approaches rely on (semi-)supervised data with attribute annotations. This data scarcity bottlenecks democratizing such customization possibilities to a wider range of languages, particularly lower-resource ones. This gap is out of sync with recent progress in pretrained massively multilingual translation models. In response, we transfer the attribute controlling capabilities to languages without attribute-annotated data with an NLLB-200 model as a foundation. Inspired by techniques from controllable generation, we employ a gradient-based inference-time controller to steer the pretrained model. The controller transfers well to zero-shot conditions, as it is operates on pretrained multilingual representations and is attribute- rather than language-specific. With a comprehensive comparison to finetuning-based control, we demonstrate that, despite finetuning’s clear dominance in supervised settings, the gap to inference-time control closes when moving to zero-shot conditions, especially with new and distant target languages. The latter also shows stronger domain robustness. We further show that our inference-time control complements finetuning. Moreover, a human evaluation on a real low-resource language, Bengali, confirms our findings. Our code is in the supplementary material.
Session 9	2024-03-20	9:30	Marie Louise 1 	Machine Translation	3	Machine Translation	262	Disentangling the Roles of Target-side Transfer and Regularization in Multilingual Machine Translation	Yan Meng, Christof Monz	Long 12/2.5/.5	Oral 	In Person				Multilingual Machine Translation (MMT) benefits from knowledge transfer across different language pairs. However, improvements in one-to-many translation compared to many-to-one translation are only marginal and sometimes even negligible. This performance discrepancy raises the question of to what extent positive transfer plays a role on the target-side for one-to-many MT. In this paper, we conduct a large-scale study that varies the auxiliary target-side languages along two dimensions, i.e., linguistic similarity and corpus size, to show the dynamic impact of knowledge transfer on the main language pairs. We show that linguistically similar auxiliary target languages exhibit strong ability to transfer positive knowledge. With an increasing size of similar target languages, the positive transfer is further enhanced to benefit the main language pairs. Meanwhile, we find distant auxiliary target languages can also unexpectedly benefit main language pairs, even with minimal positive transfer ability. Apart from transfer, we show distant auxiliary target languages can act as a regularizer to benefit translation performance by enhancing the generalization and model inference calibration.
Session 9	2024-03-20	9:45	Marie Louise 1 	Machine Translation	4	Machine Translation	389	Contrastive Decoding Reduces Hallucinations in Large Multilingual Machine Translation Models	Jonas Waldendorf, Barry Haddow, Alexandra Birch	Long 12/2.5/.5	Oral 	In Person				In Neural Machine Translation (NMT), models will sometimes generate repetitive or fluent output that is not grounded in the source sentence. This phenomenon is known as hallucination and is a problem even in large-scale multilingual translation models. We propose to use Contrastive Decoding, an algorithm developed to improve generation from unconditional language models, to mitigate hallucinations in NMT. Specifically, we maximise the log-likelihood difference between a model and the same model with reduced contribution from the encoder outputs. Additionally, we propose an alternative implementation of Contrastive Decoding that dynamically weights the difference based on the maximum probability in the output distribution to reduce the effect of CD when the model is confident of its prediction. We evaluate our methods using the Small (418M) and Medium (1.2B) M2M models across 21 low and medium-resource language pairs. Our results show a 14.6 ± 0.5 and 11.0 ± 0.6 maximal increase in the mean COMET scores for the Small and Medium models on those sentences for which the M2M models initially generate a hallucination., respectively.
Session 9	2024-03-20	10:00	Marie Louise 1 	Multilinguality and Language Diversity	5	Machine Translation	157	Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching	Kurt Micallef, Nizar Habash, Claudia Borg, Fadhl Eryani, Houda Bouamor	Long 12/2.5/.5	Oral 	In Person				Although multilingual language models exhibit impressive cross-lingual transfer capabilities on unseen languages, the performance on downstream tasks is impacted when there is a script disparity with the languages used in the multilingual model's pre-training data. Using transliteration offers a straightforward yet effective means to align the script of a resource-rich language with a target language thereby enhancing cross-lingual transfer capabilities. However, for mixed languages, this approach is suboptimal, since only a subset of the language benefits from the cross-lingual transfer while the remainder is impeded. In this work, we focus on Maltese, a Semitic language, with substantial influences from Arabic, Italian, and English, and notably written in Latin script. We present a novel dataset annotated with word-level etymology. We use this dataset to train a classifier that enables us to make informed decisions regarding the appropriate processing of each token in the Maltese language. We contrast indiscriminate transliteration or translation to mixing processing pipelines that only transliterate words of Arabic origin, thereby resulting in text with a mixture of scripts. We fine-tune the processed data on four downstream tasks and show that conditional transliteration based on word etymology yields the best results, surpassing fine-tuning with raw Maltese or Maltese processed with non-selective pipelines.
Session 9	2024-03-20	10:15	Marie Louise 1 	Multilinguality and Language Diversity	6	Machine Translation	242	Robust Neural Machine Translation for Abugidas by Glyph Perturbation	Hour Kaing, Chenchen Ding, Hideki Tanaka, Masao Utiyama	Long 12/2.5/.5	Oral 	In Person				Neural machine translation (NMT) systems are vulnerable when trained on limited data. This is a common scenario in low-resource tasks in the real world. To increase robustness, a solution is to intently add realistic noise in the training phase. Noise simulation using text perturbation has been proven to be efficient in writing systems that use Latin letters. In this study, we further explore perturbation techniques on more complex abugida writing systems, for which the visual similarity of complex glyphs is considered to capture the essential nature of these writing systems. Besides the generated noise, we propose a training strategy to improve robustness. We conducted experiments on six languages: Bengali, Hindi, Myanmar, Khmer, Lao, and Thai. By overcoming the introduced noise, we obtained non-degenerate NMT systems with improved robustness for low-resource tasks for abugida glyphs.
Session 9	2024-03-20	9:00	Marie Louise 2  	Interpretability and Model Analysis in NLP	1	Semantics and Applications	121	Scaling up Discovery of Latent Concepts in Deep NLP Models	Majd Hawasly, Fahim Dalvi, Nadir Durrani	Long 12/2.5/.5	Oral 	In Person		Dr. Sandro Pezzelle	s.pezzelle@uva.nl	Despite the revolution caused by deep NLP models, they remain black boxes, necessitating research to understand their decision-making processes. A recent work by Dalvi et al. (2022) carried out representation analysis through the lens of clustering latent spaces within pre-trained models (PLMs), but that approach is limited to small scale due to the high cost of running Agglomerative hierarchical clustering. This paper studies clustering algorithms in order to scale the discovery of encoded concepts in PLM representations to larger datasets and models. We propose metrics for assessing the quality of discovered latent concepts and use them to compare the studied clustering algorithms. We found that K-Means-based concept discovery significantly enhances efficiency while maintaining the quality of the obtained concepts. Furthermore, we demonstrate the practicality of this newfound efficiency by scaling latent concept discovery to LLMs and phrasal concepts.
Session 9	2024-03-20	9:15	Marie Louise 2  	Interpretability and Model Analysis in NLP	2	Semantics and Applications	168	Document Structure in Long Document Transformers	Jan Buchmann, Max Eichler, Jan-Micha Bodensohn, Ilia Kuznetsov, Iryna Gurevych	Long 12/2.5/.5	Oral 	In Person				Long documents often exhibit structure with hierarchically organized elements of different functions, such as section headers and paragraphs. Despite the omnipresence of document structure, its role in natural language processing (NLP) remains opaque. Do long-document Transformer models acquire an internal representation of document structure during pre-training? How can structural information be communicated to a model after pre-training, and how does it influence downstream performance? To answer these questions, we develop a novel suite of probing tasks to assess structure-awareness of long-document Transformers, propose general-purpose structure infusion methods, and evaluate the effects of structure infusion on QASPER and Evidence Inference, two challenging long-document NLP tasks. Results on LED and LongT5 suggest that they acquire implicit understanding of document structure during pre-training, which can be further enhanced by structure infusion, leading to improved end-task performance. To foster research on the role of document structure in NLP modeling, we make our data and code publicly available.
Session 9	2024-03-20	9:30	Marie Louise 2  	NLP Applications	3	Semantics and Applications	110	The Parrot Dilemma: Human-Labeled vs. LLM-augmented Data in Classification Tasks	Anders Giovanni Møller, Arianna Pera, Jacob Aarup Dalsgaard, Luca Maria Aiello	Long 12/2.5/.5	Oral 	In Person				In the realm of Computational Social Science (CSS), practitioners often navigate complex, low-resource domains and face the costly and time-intensive challenges of acquiring and annotating data. We aim to establish a set of guidelines to address such challenges, comparing the use of human-labeled data with synthetically generated data from GPT-4 and Llama-2 in ten distinct CSS classification tasks of varying complexity. Additionally, we examine the impact of training data sizes on performance. Our findings reveal that models trained on human-labeled data consistently exhibit superior or comparable performance compared to their synthetically augmented counterparts. Nevertheless, synthetic augmentation proves beneficial, particularly in improving performance on rare classes within multi-class tasks. Furthermore, we leverage GPT-4 and Llama-2 for zero-shot classification and find that, while they generally display strong performance, they often fall short when compared to specialized classifiers trained on moderately sized training sets.
Session 9	2024-03-20	9:45	Marie Louise 2  	NLP Applications	4	Semantics and Applications	473	MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks	lei Zhang, Yuge Zhang, Kan Ren, Dongsheng Li, Yuqing Yang	Long 12/2.5/.5	Oral 	Unconfirmed				The field of machine learning (ML) has gained widespread adoption, leading to significant demand for adapting ML to specific scenarios, which is yet expensive and non-trivial. The predominant approaches towards the automation of solving ML tasks (e.g., AutoML) are often time-consuming and hard to understand for human developers. In contrast, though human engineers have the incredible ability to understand tasks and reason about solutions, their experience and knowledge are often sparse and difficult to utilize by quantitative approaches. In this paper, we aim to bridge the gap between machine intelligence and human knowledge by introducing a novel framework MLCopilot, which leverages the state-of-the-art large language models to develop ML solutions for novel tasks. We showcase the possibility of extending the capability of LLMs to comprehend structured inputs and perform thorough reasoning for solving novel ML tasks. And we find that, after some dedicated design, the LLM can (i) observe from the existing experiences of ML tasks and (ii) reason effectively to deliver promising results for new tasks. The solution generated can be used directly to achieve high levels of competitiveness.
Session 9	2024-03-20	10:00	Marie Louise 2  	Semantics: Sentence-level Semantics, Textual Inference and other areas	5	Semantics and Applications	45	Align and Augment: Generative Data Augmentation for Compositional Generalization	Francesco Cazzaro, Davide Locatelli, Ariadna Quattoni	Long 12/2.5/.5	Oral 	In Person				Recent work on semantic parsing has shown that seq2seq models find compositional generalization challenging. Several strategies have been proposed to mitigate this challenge. One such strategy is to improve compositional generalization via data augmentation techniques. In this paper we follow this line of work and propose Archer, a data-augmentation strategy that exploits alignment annotations between sentences and their corresponding meaning representations. More precisely, we use alignments to train a two step generative model that combines monotonic lexical generation with reordering. Our experiments show that Archer leads to significant improvements in compositional generalization performance.
Session 9	2024-03-20	10:15	Marie Louise 2  	Semantics: Sentence-level Semantics, Textual Inference and other areas	6	Semantics and Applications	66	SentenceLDA: Discriminative and Robust Document Representation with Sentence Level Topic Model	Taehun Cha, Donghun Lee	Long 12/2.5/.5	Oral 	In Person				A subtle difference in context results in totally different nuances even for lexically identical words. On the other hand, two words can convey similar meanings given a homogeneous context. As a result, considering only word spelling information is not sufficient to obtain quality text representation. We propose SentenceLDA, a sentence-level topic model. We combine modern SentenceBERT and classical LDA to extend the semantic unit from word to sentence. By extending the semantic unit, we verify that SentenceLDA returns more discriminative document representation than other topic models, while maintaining LDA's elegant probabilistic interpretability. We also verify the robustness of SentenceLDA by comparing the inference results on original and paraphrased texts. Additionally, we implement one possible application of SentenceLDA on corpus-level key opinion mining by applying SentenceLDA on an argumentative corpus, DebateSum.
Session 10	2024-03-20	11:00	Carlson 	Interpretability and Model Analysis in NLP	1	Interpretability and Model Analysis in NLP	88	Over-Reasoning and Redundant Calculation of Large Language Models	Cheng-Han Chiang, Hung-yi Lee	Long 12/2.5/.5	Oral 	In Person		Prof. Preslav Nakov	preslav.nakov@mbzuai.ac.ae	Large language models (LLMs) can solve problems step-by-step.  While this chain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if LLMs know when to use CoT and whether those CoT are always necessary to answer the question.   This paper shows that LLMs tend to generate redundant calculations and reasoning on a manually constructed math QA dataset, GSM8K-Zero.  GSM8K-Zero is constructed such that the questions can be answered without any calculations, but LLMs, including Llama-2 models and Claude-2, tend to generate lengthy and unnecessary calculations to answer the questions.  We also conduct experiments to explain why LLMs generate redundant calculations and reasonings.
Session 10	2024-03-20	11:15	Carlson 	Interpretability and Model Analysis in NLP	2	Interpretability and Model Analysis in NLP	126	Improving the TENOR of Labeling: Re-evaluating Topic Models for Content Analysis	Zongxia Li, Andrew Mao, Daniel Kofi Stephens, Pranav Goel, Emily Walpole, Alden Dima, Juan Francisco Fung, Jordan Lee Boyd-Graber	Long 12/2.5/.5	Oral 	In Person				Topic models are a popular tool for understanding text collections, but their evaluation has been a point of contention. Automated evaluation metrics such as coherence are often used, however, their validity has been questioned for neural topic models (NTMs) and can overlook a model's benefits in real-world applications. To this end, we conduct the first evaluation of neural, supervised and classical topic models in an interactive task-based setting. We combine topic models with a classifier and test their ability to help humans   conduct content analysis and document annotation. From simulated, real user and expert pilot studies, the Contextual Neural Topic Model does the best on cluster evaluation metrics and human evaluations; however, LDA is competitive with two other NTMs under our simulated experiment and user study results, contrary to what coherence scores suggest. We show that current automated metrics do not provide a complete picture of topic modeling capabilities, but the right choice of NTMs can be better than classical models on practical tasks.
Session 10	2024-03-20	11:30	Carlson 	Interpretability and Model Analysis in NLP	3	Interpretability and Model Analysis in NLP	137	Unsupervised Contrast-Consistent Ranking with Language Models	Niklas Stoehr, Pengxiang Cheng, Jing Wang, Daniel Preotiuc-Pietro, Rajarshi Bhowmik	Long 12/2.5/.5	Oral 	In Person				Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank product reviews by sentiment. We compare pairwise, pointwise and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probe guided by a logical constraint: a language model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent, pairwise or listwise comparisons. To this end, we extend the binary CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking methods such as the Max-Margin Loss, Triplet Loss and an Ordinal Regression objective. Across different models and datasets, our results confirm that CCR probing performs better or, at least, on a par with prompting.
Session 10	2024-03-20	11:45	Carlson 	Interpretability and Model Analysis in NLP	4	Interpretability and Model Analysis in NLP	280	It is not True that Transformers are Inductive Learners: Probing NLI Models with External Negation	Michael Sullivan	Long 12/2.5/.5	Oral 	In Person				NLI tasks necessitate a substantial degree of logical reasoning; as such, the remarkable performance of SoTA transformers on these tasks may lead us to believe that those models have learned to reason logically. The results presented in this paper demonstrate that (i) models fine-tuned on NLI datasets learn to treat external negation as a distractor, effectively ignoring its presence in hypothesis sentences; (ii) several near-SoTA encoder and encoder-decoder transformer models fail to inductively learn the law of the excluded middle for a single external negation prefix with respect to NLI tasks, despite extensive fine-tuning; (iii) those models which are are able to learn the law of the excluded middle for a single prefix are unable to generalize this pattern to similar prefixes. Given the critical role of negation in logical reasoning, we may conclude from these findings that transformers do not learn to reason logically when fine-tuned for NLI tasks. Furthermore, these results suggest that transformers may not be able to inductively learn the role of negation with respect to NLI tasks, calling into question their capacity to fully acquire logical reasoning abilities.
Session 10	2024-03-20	12:00	Carlson 	Interpretability and Model Analysis in NLP	5	Interpretability and Model Analysis in NLP	327	Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features	Eliana Pastor, Alkis Koudounas, Giuseppe Attanasio, Dirk Hovy, Elena Baralis	Long 12/2.5/.5	Oral 	In Person				Predictive models make mistakes and have biases. To combat both, we need to understand their predictions.  Explainable AI (XAI) provides insights into models for vision, language, and tabular data. However, only a few approaches exist for speech classification models. Previous works focus on a selection of spoken language understanding (SLU) tasks, and most users find their explanations challenging to interpret.  We propose a novel approach to explain speech classification models. It provides two types of insights. (i) Word-level. We measure the impact of each audio segment aligned with a word on the outcome. (ii) Paralinguistic. We evaluate how non-linguistic features (e.g., prosody and background noise) affect the outcome if perturbed.  We validate our approach by explaining two state-of-the-art SLU models on two tasks in English and Italian. We test their plausibility with human subject ratings. Our results show that the explanations correctly represent the model's inner workings and are plausible to humans.
Session 10	2024-03-20	12:15	Carlson 	Interpretability and Model Analysis in NLP	6	Interpretability and Model Analysis in NLP	400	Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting	Tilman Beck, Hendrik Schuff, Anne Lauscher, Iryna Gurevych	Long 12/2.5/.5	Oral 	In Person				Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as toxic language detection.   Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique — it remains unclear for which tasks and scenarios it can help, and the role of the individual factors in sociodemographic prompting is still unexplored. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. We use it to analyze its influence on model sensitivity, performance and robustness across seven datasets and six instruction-tuned model families. We show that sociodemographic information affects model predictions and can be beneficial for improving zero-shot learning in subjective NLP tasks.  However, its outcomes largely vary for different model types, sizes, and datasets, and are subject to large variance with regards to prompt formulations. Most importantly, our results show that sociodemographic prompting should be used with care when used for data annotation or studying LLM alignment.
Session 10	2024-03-20	11:00	Marie Louise 1 	Resources and Evaluation	1	Resources and Evaluation	14	Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs	Simone Balloccu, Patrícia Schmidtová, Mateusz Lango, Ondrej Dusek	Long 12/2.5/.5	Oral 	In Person		Prof. Nizar Habash	nizar.habash@nyu.edu	Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of indirect data leaking, where models  are iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI’s GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI’s data usage policy, we extensively document the amount of data leaked to these models during the first year after the model’s release. We report that these models have been globally exposed to ∼4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts.
Session 10	2024-03-20	11:15	Marie Louise 1 	Resources and Evaluation	2	Resources and Evaluation	19	Archer: A Human-Labeled Text-to-SQL Dataset with Arithmetic, Commonsense and Hypothetical Reasoning	Danna Zheng, Mirella Lapata, Jeff Z. Pan	Long 12/2.5/.5	Oral 	In Person				We present Archer, a challenging bilingual text-to-SQL dataset specific to complex reasoning, including arithmetic, commonsense and hypothetical reasoning. It contains 1,042 English questions and 1,042 Chinese questions, along with 521 unique SQL queries, covering 20 English databases across 20 domains. Notably, this dataset demonstrates a significantly higher level of complexity compared to existing publicly available datasets. Our evaluation shows that Archer challenges the capabilities of current state-of-the-art models, with a high-ranked model on the Spider leaderboard achieving only 6.73% execution accuracy on Archer test set. Thus, Archer presents a significant challenge for future research in this field.
Session 10	2024-03-20	11:30	Marie Louise 1 	Resources and Evaluation	3	Resources and Evaluation	49	From Text Segmentation to Smart Chaptering: A Novel Benchmark for Structuring Video Transcriptions	Fabian Retkowski, Alexander Waibel	Long 12/2.5/.5	Oral 	In Person				Text segmentation is a fundamental task in natural language processing, where documents are split into contiguous sections. However, prior research in this area has been constrained by limited datasets, which are either small in scale, synthesized, or only contain well-structured documents. In this paper, we address these limitations by introducing a novel benchmark YTSeg focusing on spoken content that is inherently more unstructured and both topically and structurally diverse. As part of this work, we introduce an efficient hierarchical segmentation model MiniSeg, that outperforms state-of-the-art baselines. Lastly, we expand the notion of text segmentation to a more practical "smart chaptering" task that involves the segmentation of unstructured content, the generation of meaningful segment titles, and a potential real-time application of the models.
Session 10	2024-03-20	11:45	Marie Louise 1 	Resources and Evaluation	4	Resources and Evaluation	162	Predict the Next Word: <Humans exhibit uncertainty in this task and language models _____>	Evgenia Ilia, Wilker Aziz	Long 12/2.5/.5	Oral 	In Person				Language models (LMs) are statistical models trained to assign probability to human-generated text. As such, it is reasonable to question whether they approximate linguistic variability exhibited by humans well. This form of statistical assessment is difficult to perform at the passage level, for it requires acceptability judgments (i.e., human evaluation) or a robust automated proxy (which is non-trivial). At the word level, however, given some context, samples from an LM can be assessed via exact matching against a prerecorded dataset of alternative single-word continuations of the available context. We exploit this fact and evaluate the LM’s ability to reproduce variability that humans (in particular, a population of English speakers) exhibit in the ‘next word prediction’ task. This can be seen as assessing a form of calibration, which, in the context of text classification, Baan et al. (2022) termed calibration to human uncertainty. We assess GPT2, BLOOM and ChatGPT and find that they exhibit fairly low calibration to human uncertainty. We also verify the failure of expected calibration error (ECE) to reflect this, and as such, advise the community against relying on it in this setting.
Session 10	2024-03-20	12:00	Marie Louise 1 	Resources and Evaluation	5	Resources and Evaluation	234	WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts	Pardis Sadat Zahraei, Ali Emami	Long 12/2.5/.5	Oral 	Virtual				The Winograd Schema Challenge (WSC) serves as a prominent benchmark for evaluating machine understanding. While Large Language Models (LLMs) excel at answering WSC questions, their ability to generate such questions remains less explored. In this work, we propose Tree-of-Experts (ToE), a novel prompting method which enhances the generation of WSC instances (50% valid cases vs. 10% in recent methods). Using this approach, we introduce WSC+, a novel dataset comprising 3,026 LLM-generated sentences. Notably, we extend the WSC framework by incorporating new 'ambiguous' and 'offensive' categories, providing a deeper insight into model overconfidence and bias. Our analysis reveals nuances in generation-evaluation consistency, suggesting that LLMs may not always outperform in evaluating their own generated questions when compared to those crafted by other models. On WSC+, GPT-4, the top-performing LLM, achieves an accuracy of 68.7%, significantly below the human benchmark of 95.1%.
Session 10	2024-03-20	12:15	Marie Louise 1 	Resources and Evaluation	6	Resources and Evaluation	247	AnaDE1.0: A Novel Data Set for Benchmarking Analogy Detection and Extraction	Bhavya Bhavya, Shradha Sehgal, Jinjun Xiong, ChengXiang Zhai	Long 12/2.5/.5	Oral 	In Person				Textual analogies that make comparisons between two concepts are often used for explaining complex ideas, creative writing, and scientific discovery. In this paper, we propose and study a new task, called Analogy Detection and Extraction (AnaDE), which includes three synergistic sub-tasks: 1) detecting documents containing analogies, 2) extracting text segments that make up the analogy, and 3) identifying the (source and target) concepts being compared. To facilitate the study of this new task, we create a benchmark dataset by scraping Metamia.com and investigate the performances of state-of-the-art models on all sub-tasks to establish the first-generation benchmark results for this new task. We find that the Longformer model achieves the best performance on all the three sub-tasks demonstrating its effectiveness for handling long texts. Moreover, smaller models fine-tuned on our dataset perform better than non-finetuned ChatGPT, suggesting high task difficulty. Overall, the models achieve a high performance on documents detection suggesting that it could be used to develop applications like analogy search engines. Further, there is a large room for improvement on the segment and concept extraction tasks.
Session 10	2024-03-20	11:00	Marie Louise 2  	Computational Social Science and Cultural Analytics	1	Computational Social Science and Cultural Analytics	123	AnthroScore: A Computational Linguistic Measure of Anthropomorphism	Myra Cheng, Kristina Gligoric, Tiziano Piccardi, Dan Jurafsky	Long 12/2.5/.5	Oral 	In Person		Philip Resnik	resnik@umd.edu	Anthropomorphism, or the attribution of human-like characteristics to non-human entities, has shaped conversations about the impacts and possibilities of technology. We present AnthroScore, an automatic metric of implicit anthropomorphism in language. We use a masked language model to quantify how non-human entities are implicitly framed as human by the surrounding context. We show that AnthroScore corresponds with human judgments of anthropomorphism and dimensions of anthropomorphism described in social science literature. Motivated by concerns of misleading anthropomorphism in computer science discourse, we use AnthroScore to analyze 15 years of research papers and downstream news articles. In research papers, we find that anthropomorphism has steadily increased over time, and that papers related to language models have the most anthropomorphism. Within ACL papers, temporal increases in anthropomorphism are correlated with key neural advancements. Building upon concerns of scientific misinformation in mass media, we identify higher levels of anthropomorphism in news headlines compared to the research papers they cite. Since AnthroScore is lexicon-free, it can be directly applied to a wide range of text sources.
Session 10	2024-03-20	11:15	Marie Louise 2  	Computational Social Science and Cultural Analytics	2	Computational Social Science and Cultural Analytics	202	It's All Relative: Learning Interpretable Models for Scoring Subjective Bias in Documents from Pairwise Comparisons	Aswin Suresh, Wu Chi hsuan, Matthias Grossglauser	Long 12/2.5/.5	Oral 	In Person				We propose an interpretable model to score the subjective bias present in documents, based only on their textual content. Our model is trained on pairs of revisions of the same Wikipedia article, where one version is more biased than the other. Although prior approaches based on bias classification have struggled to obtain a high accuracy for the task, we are able to develop a useful model for scoring bias by learning to accurately perform pairwise comparisons. We show that we can interpret the parameters of the trained model to discover the words most indicative of bias. We also apply our model in three different settings by studying the temporal evolution of bias in Wikipedia articles, comparing news sources based on bias, and scoring bias in law amendments. In each case, we demonstrate that the outputs of the model can be explained and validated, even for the two domains that are outside the training-data domain. We also use the model to compare the general level of bias between domains, where we see that legal texts are the least biased and news media are the most biased, with Wikipedia articles in between.
Session 10	2024-03-20	11:30	Marie Louise 2  	Computational Social Science and Cultural Analytics	3	Computational Social Science and Cultural Analytics	404	Identifying Narrative Content in Podcast Transcripts	Yosra Abdessamed, Shadi Rezapour, Steven R. Wilson	Long 12/2.5/.5	Oral 	In Person				As one of the oldest forms of human communication, narratives appear across a variety of genres and media. Computational methods have been applied to study narrativity in novels, social media, and patient records, leading to new approaches and insights. However, other types of media are growing in popularity, like podcasts. Podcasts contain a multitude of spoken narratives that can provide a meaningful glimpse into how people share stories with one another.  In this paper, we outline and apply methods to process English-language podcast transcripts and extract narrative content from conversations within each episode. We provide an initial analysis of the types of narrative content that exists within a wide range of podcasts, and compare our results to other established narrative analysis tools.  Our annotations for narrativity and pretrained models can help to enable future research into narrativity within a large corpus of approximately 100,000 podcast episodes.
Session 10	2024-03-20	11:45	Marie Louise 2  	Computational Social Science and Cultural Analytics	4	Computational Social Science and Cultural Analytics	422	SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks	Gourab Dey, Adithya V Ganesan, Yash Kumar Lal, Manal Shah, Shreyashee Sinha, Matthew Matero, Salvatore Giorgi, Vivek Kulkarni, H. Schwartz	Long 12/2.5/.5	Oral 	In Person				Social science NLP tasks, such as emotion or humor detection, are required to capture the semantics along with the implicit pragmatics from text, often with limited amounts of training data. Instruction tuning has been shown to improve the many capabilities of large language models (LLMs) such as commonsense reasoning, reading comprehension, and computer programming. However, little is known about the effectiveness of instruction tuning on the social domain where implicit pragmatic cues are often needed to be captured. We explore the use of instruction tuning for social science NLP tasks and introduce Socialite-Llama &mdash; an open-source, instruction-tuned Llama. On a suite of 20 social science tasks, Socialite-Llama improves upon the performance of Llama as well as matches or improves upon the performance of a state-of-the-art, multi-task finetuned model on a majority of them. Further, Socialite-Llama also leads to improvement on 5 out of 6 related social tasks as compared to Llama, suggesting instruction tuning can lead to generalized social understanding. All resources including our code, model and dataset can be found through [bit.ly/socialitellama](https://bit.ly/socialitellama/).
Session 10	2024-03-20	12:00	Marie Louise 2  	Computational Social Science and Cultural Analytics	5	Computational Social Science and Cultural Analytics	425	Unintended Bias Detection and Mitigation in Misogynous Memes	Gitanjali Kumari, Anubhav Sinha, Asif Ekbal	Long 12/2.5/.5	Oral 	In Person				Online sexism has become a concerning issue in recent years, especially conveyed through memes. Although this alarming phenomenon has triggered many studies from computational linguistic and natural language processing points of view, less effort has been spent analyzing if those misogyny detection models are affected by an unintended bias. Such biases can lead models to incorrectly label non-misogynous memes misogynous due to specific identity terms, perpetuating harmful stereotypes and reinforcing negative attitudes.   This paper presents the first and most comprehensive approach to measure and mitigate unintentional bias in the misogynous memes detection model, aiming to develop effective strategies to counter their harmful impact. Our proposed model, the \textbf{C}on\textbf{t}e\textbf{x}tualized \textbf{S}cene \textbf{G}raph-based \textbf{M}ultimodal \textbf{Net}work (CTXSGMNet), is an integrated architecture that combines VisualBERT, a CLIP-LSTM-based memory network, and an unbiased scene graph module with supervised contrastive loss, achieves state-of-the-art performance in mitigating unintentional bias in misogynous memes.  Empirical evaluation, including both qualitative and quantitative analysis, demonstrates the effectiveness of our CTXSGMNet framework on the SemEval-2022 Task 5 (\textbf{MAMI} task) dataset, showcasing its promising performance in terms of Equity of Odds and F1 score. Additionally, we assess the generalizability of the proposed model by evaluating their performance on a few benchmark meme datasets, providing a comprehensive understanding of our approach's efficacy across diverse datasets.
Session 10	2024-03-20	12:15	Marie Louise 2  	Resources and Evaluation	6	Computational Social Science and Cultural Analytics	156	Moderation in the Wild: Investigating User-Driven Moderation in Online Discussions	Neele Falk, Eva Maria Vecchi, Iman Jundi, Gabriella Lapesa	Long 12/2.5/.5	Oral 	In Person				Effective content moderation is imperative for fostering healthy and productive discussions in online domains. Despite the substantial efforts of moderators, the overwhelming nature of discussion flow can limit their effectiveness. However, it is not only trained moderators who intervene in online discussions to improve their quality. “Ordinary” users also act as moderators, actively intervening to correct information of other users’ posts, enhance arguments, and steer discussions back on course.  This paper introduces the phenomenon of user moderation, documenting and releasing UMOD, the first dataset of comments in which  users act as moderators. UMOD contains 1000 comment-reply pairs from the subreddit r/changemyview with crowdsourced annotations from a large annotator pool and with a fine-grained annotation schema targeting the functions of moderation, stylistic properties  (aggressiveness, subjectivity, sentiment), constructiveness, as well as the individual perspectives of the annotators on the task. The release  of UMOD is complemented by two analyses which focus on the constitutive features of constructiveness in user moderation and on the  sources of annotator disagreements, given the high subjectivity of the task.