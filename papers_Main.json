[{"abstract":"","anthology_url":null,"authors":["Heejoon Koo"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)","session-9_-nlp-applications-(poster)"],"id":"10","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["EuiYul Song","Sangryul Kim","Haeju Lee","Joonkee Kim","James Thorne"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["business-meeting_-information-retrieval-and-text-mining-(poster)"],"id":"100","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Re3val: Reinforced and Reranked Generative Retrieval","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Hyperparameter tuning, the process of searching for suitable hyperparameters, becomes more difficult as the computing resources required to train neural networks continue to grow. This topic continues to receive little attention and discussion---much of it hearsay---despite its obvious importance. We attempt to formalize hyperparameter sensitivity using two metrics: similarity-based sensitivity and performance-based sensitivity. We then use these metrics to quantify two such claims: (1) transformers are more sensitive to hyperparameter choices than LSTMs and (2) transformers are particularly sensitive to batch size. We conduct experiments on two different character-level sequence-to-sequence tasks and find that, indeed, the transformer is slightly more sensitive to hyperparameters according to both of our metrics. However, we do not find that it is more sensitive to batch size in particular.","anthology_url":null,"authors":["Adam Wiemerslage","Kyle Gorman","Katharina von der Wense"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 2","event_ids":["session-8_-multilinguality-and-language-diversity-2-(oral)"],"id":"102-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Quantifying the Hyperparameter Sensitivity of Neural Networks for Character-level Sequence-to-Sequence Tasks","tldr":"","track":"Multilinguality and Language Diversity 2","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Following on recent advances in large language models (LLMs) and subsequent chat models, a new wave of large vision--language models (LVLMs) has emerged. Such models can incorporate images as input in addition to text, and perform tasks such as visual question answering, image captioning, story generation, etc. Here, we examine potential gender and racial biases in such systems, based on the perceived characteristics of the people in the input images. To accomplish this, we present a new dataset PAIRS (PArallel Images for eveRyday Scenarios). The PAIRS dataset contains sets of AI-generated images of people, such that the images are highly similar in terms of background and visual content, but differ along the dimensions of gender (man, woman) and race (Black, white). By querying the LVLMs with such images, we observe significant differences in the responses according to the perceived gender or race of the person depicted.","anthology_url":null,"authors":["Kathleen C. Fraser","Svetlana Kiritchenko"],"category":"Oral","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-9_-ethics-and-nlp-(oral)"],"id":"103-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Examining Gender and Racial Bias in Large Vision--Language Models Using a Novel Dataset of Parallel Images","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Quyet V. Do","Tianqing Fang","Shizhe Diao","Zhaowei Wang","Yangqiu Song"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["business-meeting_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"104","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Mike Zhang","Rob van der Goot","Barbara Plank"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"105","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Entity Linking in the Job Market Domain","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Abstract: The single shortest path algorithm is undefined for weighted finite-state automata over non-idempotent semirings because such semirings do not guarantee the existence of a shortest path. However, in non-idempotent semirings admitting an order satisfying a monotonicity condition (such as the plus-times or log semirings), the shortest string is well-defined. We describe an algorithm which finds the shortest string for a weighted non-deterministic automaton over such semirings using the backwards shortest distance of an equivalent deterministic automaton (DFA) as a heuristic for A* search performed over a companion idempotent semiring, which is proven to return the shortest string. There may be exponentially more states in the DFA, but the proposed algorithm needs to visit only a small fraction of them if determinization is performed \"on the fly\".","anthology_url":null,"authors":["Kyle Gorman","Cyril Allauzen"],"category":"Oral","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-2_-machine-learning-for-nlp-(oral)"],"id":"107-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A* shortest string decoding for non-idempotent semirings","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent advances in NLP suggest that some tasks, such as argument detection and relation classification, are better framed in a multimodal perspective. We propose multimodal argument mining for argumentative fallacy classification in political debates. To this end, we release the first corpus for multimodal fallacy classification. Our experiments show that the integration of the audio modality leads to superior classification performance. Our findings confirm that framing fallacy classification as a multimodal task is essential to capturing paralinguistic aspects of fallacious arguments.","anthology_url":null,"authors":["Eleonora Mancini","Federico Ruggeri","Paolo Torroni"],"category":"Oral","demo_url":null,"display_track":"Factual Content in NLP","event_ids":["session-2_-factual-content-in-nlp-(oral)"],"id":"108-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Multimodal Fallacy Classification in Political Debates","tldr":"","track":"Factual Content in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Dor Muhlgay","Ori Ram","Inbal Magar","Yoav Levine","Nir Ratner","Yonatan Belinkov","Omri Abend","Kevin Leyton-Brown","Amnon Shashua","Yoav Shoham"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-11_-resources-and-evaluation-(poster)"],"id":"11","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Generating Benchmarks for Factuality Evaluation of Language Models","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In the realm of Computational Social Science (CSS), practitioners often navigate complex, low-resource domains and face the costly and time-intensive challenges of acquiring and annotating data. We aim to establish a set of guidelines to address such challenges, comparing the use of human-labeled data with synthetically generated data from GPT-4 and Llama-2 in ten distinct CSS classification tasks of varying complexity. Additionally, we examine the impact of training data sizes on performance. Our findings reveal that models trained on human-labeled data consistently exhibit superior or comparable performance compared to their synthetically augmented counterparts. Nevertheless, synthetic augmentation proves beneficial, particularly in improving performance on rare classes within multi-class tasks. Furthermore, we leverage GPT-4 and Llama-2 for zero-shot classification and find that, while they generally display strong performance, they often fall short when compared to specialized classifiers trained on moderately sized training sets.","anthology_url":null,"authors":["Anders Giovanni M\u00f8ller","Arianna Pera","Jacob Aarup Dalsgaard","Luca Maria Aiello"],"category":"Oral","demo_url":null,"display_track":"Semantics and Applications","event_ids":["session-9_-semantics-and-applications-(oral)"],"id":"110-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"The Parrot Dilemma: Human-Labeled vs. LLM-augmented Data in Classification Tasks","tldr":"","track":"Semantics and Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Minghao Wu","Yufei Wang","George Foster","Lizhen Qu","Gholamreza Haffari"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-11_-machine-translation-(poster)"],"id":"111","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Importance-Aware Data Augmentation for Document-Level Neural Machine Translation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Translated texts bear several hallmarks distinct from texts originating in the language (\u201ctranslationese\u201d). Though individual translated texts are often fluent and preserve meaning, at a large scale, translated texts have statistical tendencies which distinguish them from text originally written in the language and can affect model performance. We frame the novel task of translationese reduction and hypothesize that Abstract Meaning Representation (AMR), a graph-based semantic representation which abstracts away from the surface form, can be used as an interlingua to reduce the amount of translationese in translated texts. By parsing English translations into an AMR and then generating text from that AMR, the result more closely resembles originally English text across three quantitative macro-level measures, without severely compromising fluency or adequacy. We compare our AMR-based approach against three other techniques based on machine translation or paraphrase generation. This work represents the first approach to reducing translationese in text and highlights the promise of AMR, given that our AMR-based approach outperforms more computationally intensive methods.","anthology_url":null,"authors":["Shira Wein","Nathan Schneider"],"category":"Oral","demo_url":null,"display_track":"Sentence-level Semantics","event_ids":["session-6_-sentence-level-semantics-(oral)"],"id":"112-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Lost in Translationese? Reducing Translation Effect Using Abstract Meaning Representation","tldr":"","track":"Sentence-level Semantics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sagi Shaier","Kevin Bennett","Lawrence Hunter","Katharina von der Wense"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"116","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Comparing Template-based and Template-free Language Model Probing","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sagi Shaier","Lawrence Hunter","Katharina von der Wense"],"category":"Poster","demo_url":null,"display_track":"Question Answering","event_ids":["session-3_-question-answering-(poster)"],"id":"117","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Desiderata For The Context Use Of Question Answering Systems","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Thilini Wijesiriwardene","Ruwan Wickramarachchi","Aishwarya Naresh Reganti","Vinija Jain","Aman Chadha","Amit P. Sheth","Amitava Das"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-11_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"119","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"On the Relationship between Sentence Analogy Identification and Sentence Structure Encoding in Large Language Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Dawei Li","Zhen Tan","Tianlong Chen","huan liu"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)"],"id":"120","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Contextualization Distillation from Large Language Model for Knowledge Graph Completion","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Despite the revolution caused by deep NLP models, they remain black boxes, necessitating research to understand their decision-making processes. A recent work by Dalvi et al. (2022) carried out representation analysis through the lens of clustering latent spaces within pre-trained models (PLMs), but that approach is limited to small scale due to the high cost of running Agglomerative hierarchical clustering. This paper studies clustering algorithms in order to scale the discovery of encoded concepts in PLM representations to larger datasets and models. We propose metrics for assessing the quality of discovered latent concepts and use them to compare the studied clustering algorithms. We found that K-Means-based concept discovery significantly enhances efficiency while maintaining the quality of the obtained concepts. Furthermore, we demonstrate the practicality of this newfound efficiency by scaling latent concept discovery to LLMs and phrasal concepts.","anthology_url":null,"authors":["Majd Hawasly","Fahim Dalvi","Nadir Durrani"],"category":"Oral","demo_url":null,"display_track":"Semantics and Applications","event_ids":["session-9_-semantics-and-applications-(oral)"],"id":"121-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Scaling up Discovery of Latent Concepts in Deep NLP Models","tldr":"","track":"Semantics and Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Myra Cheng","Kristina Gligoric","Tiziano Piccardi","Dan Jurafsky"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-8_-computational-social-science-and-cultural-analytics-(poster)"],"id":"123","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"AnthroScore: A Computational Linguistic Measure of Anthropomorphism","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Anthropomorphism, or the attribution of human-like characteristics to non-human entities, has shaped conversations about the impacts and possibilities of technology. We present AnthroScore, an automatic metric of implicit anthropomorphism in language. We use a masked language model to quantify how non-human entities are implicitly framed as human by the surrounding context. We show that AnthroScore corresponds with human judgments of anthropomorphism and dimensions of anthropomorphism described in social science literature. Motivated by concerns of misleading anthropomorphism in computer science discourse, we use AnthroScore to analyze 15 years of research papers and downstream news articles. In research papers, we find that anthropomorphism has steadily increased over time, and that papers related to language models have the most anthropomorphism. Within ACL papers, temporal increases in anthropomorphism are correlated with key neural advancements. Building upon concerns of scientific misinformation in mass media, we identify higher levels of anthropomorphism in news headlines compared to the research papers they cite. Since AnthroScore is lexicon-free, it can be directly applied to a wide range of text sources.","anthology_url":null,"authors":["Myra Cheng","Kristina Gligoric","Tiziano Piccardi","Dan Jurafsky"],"category":"Oral","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-10_-computational-social-science-and-cultural-analytics-(oral)"],"id":"123-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"AnthroScore: A Computational Linguistic Measure of Anthropomorphism","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Steven Bird","Dean Yibarbuk"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"125","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Centering the Speech Community","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"How can NLP/AI practitioners engage with oral societies and develop locally appropriate language technologies? We report on our experience of working together over five years in a remote community in the far north of Australia, and how we prototyped simple language technologies to support our collaboration. We navigated different understandings of language, the functional differentiation of oral vs institutional languages, and the distinct technology opportunities for each. Our collaboration unsettled the first author's western framing of language as data for exploitation by machines, and we devised a design pattern that seems better aligned with local interests and aspirations. We call for new collaborations on the design of locally appropriate technologies for languages with primary orality.","anthology_url":null,"authors":["Steven Bird","Dean Yibarbuk"],"category":"Oral","demo_url":null,"display_track":"Multilingual Issues","event_ids":["session-6_-multilingual-issues-(oral)"],"id":"125-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Centering the Speech Community","tldr":"","track":"Multilingual Issues","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Topic models are a popular tool for understanding text collections, but their evaluation has been a point of contention. Automated evaluation metrics such as coherence are often used, however, their validity has been questioned for neural topic models (NTMs) and can overlook a model's benefits in real-world applications. To this end, we conduct the first evaluation of neural, supervised and classical topic models in an interactive task-based setting. We combine topic models with a classifier and test their ability to help humans   conduct content analysis and document annotation. From simulated, real user and expert pilot studies, the Contextual Neural Topic Model does the best on cluster evaluation metrics and human evaluations; however, LDA is competitive with two other NTMs under our simulated experiment and user study results, contrary to what coherence scores suggest. We show that current automated metrics do not provide a complete picture of topic modeling capabilities, but the right choice of NTMs can be better than classical models on practical tasks.","anthology_url":null,"authors":["Zongxia Li","Andrew Mao","Daniel Kofi Stephens","Pranav Goel","Emily Walpole","Alden Dima","Juan Francisco Fung","Jordan Lee Boyd-Graber"],"category":"Oral","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-10_-interpretability-and-model-analysis-in-nlp-(oral)"],"id":"126-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving the TENOR of Labeling: Re-evaluating Topic Models for Content Analysis","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Chakib Fettal","lazhar labiod","Mohamed Nadif"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"13","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"More Discriminative Sentence Embeddings via Semantic Graph Smoothing","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We conducted a detailed analysis on the quality of web-mined corpora for two low-resource languages (making three language pairs, English-Sinhala, English-Tamil and Sinhala-Tamil). We ranked each corpus according to a similarity measure and carried out an intrinsic and extrinsic evaluation on different portions of this ranked corpus. We show that there are significant quality differences between different portions of web-mined corpora and that the quality varies across languages and datasets. We also show that, for some web-mined datasets, Neural Machine Translation (NMT) models trained with their highest-ranked 25k portion can be on par with human-curated datasets.","anthology_url":null,"authors":["Surangika Ranathunga","Nisansa de Silva","Velayuthan Menan","Aloka Fernando","Charitha S.M. Rathnayake"],"category":"Oral","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-3_-efficient-low-resource-methods-in-nlp-(oral)"],"id":"130-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yoo Hyun Jeong","Myeong soo Han","Dong-Kyu Chae"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"131","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Simple Temperature Cool-down in Contrastive Framework for Unsupervised Sentence Representation Learning","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yoo Hyun Jeong","Myeong soo Han","Dong-Kyu Chae"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"132","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Bootstrap Your Own PLM: Boosting Semantic Features of PLMs for Unsuperivsed Contrastive Learning","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Wen Xiao","Yujia Xie","Giuseppe Carenini","Pengcheng He"],"category":"Poster","demo_url":null,"display_track":"Summarization","event_ids":["business-meeting_-summarization-(poster)"],"id":"134","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Personalized Abstractive Summarization by Tri-agent Generation Pipeline","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Prawaal Sharma","Poonam Goyal","Vidisha Sharma","Navneet Goyal"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"135","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"VOLTAGE: A Versatile Contrastive Learning based OCR Methodology for ultra low-resource scripts through Auto Glyph Feature Extraction","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank product reviews by sentiment. We compare pairwise, pointwise and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probe guided by a logical constraint: a language model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent, pairwise or listwise comparisons. To this end, we extend the binary CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking methods such as the Max-Margin Loss, Triplet Loss and an Ordinal Regression objective. Across different models and datasets, our results confirm that CCR probing performs better or, at least, on a par with prompting.","anthology_url":null,"authors":["Niklas Stoehr","Pengxiang Cheng","Jing Wang","Daniel Preotiuc-Pietro","Rajarshi Bhowmik"],"category":"Oral","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-10_-interpretability-and-model-analysis-in-nlp-(oral)"],"id":"137-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Unsupervised Contrast-Consistent Ranking with Language Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Cunxiao Du","Hao Zhou","Zhaopeng Tu","Jing Jiang"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"139","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Revisiting the Markov Property for Machine Translation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Simone Balloccu","Patr\u00edcia Schmidtov\u00e1","Mateusz Lango","Ondrej Dusek"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"14","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of indirect data leaking, where models  are iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI\u2019s GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI\u2019s data usage policy, we extensively document the amount of data leaked to these models during the first year after the model\u2019s release. We report that these models have been globally exposed to \u223c4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts.","anthology_url":null,"authors":["Simone Balloccu","Patr\u00edcia Schmidtov\u00e1","Mateusz Lango","Ondrej Dusek"],"category":"Oral","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-10_-resources-and-evaluation-(oral)"],"id":"14-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jongyoon Song","Nohil Park","Bongkyu Hwang","Jaewoong Yun","Seongho Joe","Youngjune Gwon","Sungroh Yoon"],"category":"Poster","demo_url":null,"display_track":"Summarization","event_ids":["business-meeting_-summarization-(poster)"],"id":"141","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Entity-level Factual Adaptiveness of Fine-tuning based Abstractive Summarization Models","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Joshua Zingale","Jugal Kalita"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["business-meeting_-generation-(poster)"],"id":"142","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Minju Kim","Heuiyeen Yeen","Myoung-Wan Koo"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-11_-resources-and-evaluation-(poster)"],"id":"145","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Towards Context-Based Violence Detection: A Korean Crime Dialogue Dataset","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Internet memes have gained significant influence in communicating political, psychological, and sociocultural ideas. While meme are often humorous, there has been a rise in the use of memes for trolling and cyberbullying. Although a wide variety of effective deep learning-based models have been developed for detecting offensive multimodal memes, only a few works have been done on explainability aspect. Recent laws like \"right to explanations\" of General Data Protection Regulation, have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we introduce MultiBully-Ex, the first benchmark dataset for multimodal explanation from code-mixed cyberbullying memes. Here, both visual and textual modalities are highlighted to explain why a given meme is cyberbullying. A Contrastive Language-Image Pretraining (CLIP) projection based multimodal shared-private multitask approach has been proposed for visual and textual explanation of a meme. Experimental results demonstrate that training with multimodal explanations improves performance in generating textual justifications and more accurately identifying the visual evidence supporting a decision with reliable performance improvements.","anthology_url":null,"authors":["Prince Jha","Krishanu Maity","Raghav Jain","Apoorv Verma","Sriparna Saha","Pushpak Bhattacharyya"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 1","event_ids":["session-7_-multilinguality-and-language-diversity-1-(oral)"],"id":"146-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations","tldr":"","track":"Multilinguality and Language Diversity 1","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Indigenous languages are historically under-served by Natural Language Processing (NLP) technologies, but this is changing for some languages with the recent scaling of large multilingual models and an increased focus by the NLP community on endangered languages. This position paper explores ethical considerations in building NLP technologies for Indigenous languages, based on the premise that such projects should primarily serve Indigenous communities. We report on interviews with 17 researchers working in or with Aboriginal and/or Torres Strait Islander communities on language technology projects in Australia. Drawing on insights from the interviews, we recommend practices for NLP researchers to increase attention to the process of engagements with Indigenous communities, rather than focusing only on decontextualised artefacts.","anthology_url":null,"authors":["Ned Cooper","Courtney Heldreth","Ben Hutchinson"],"category":"Oral","demo_url":null,"display_track":"Multilingual Issues","event_ids":["session-6_-multilingual-issues-(oral)"],"id":"147-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"'It's how you do things that matters'': Attending to Process to Better Serve Indigenous Communities with Language Technologies","tldr":"","track":"Multilingual Issues","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. While other similar works have been done, they are often conducted on a limited set of (usually still large) models and are not accompanied by proper evaluations. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. We also assess the model for hallucination and toxicity, and for the former, we introduce a new benchmark dataset for hallucination-inducing QA. The results demonstrate that our proposed LaMini-LM models are comparable to strong baselines while being much smaller in size.","anthology_url":null,"authors":["Minghao Wu","Abdul Waheed","Chiyu Zhang","Muhammad Abdul-Mageed","Alham Fikri Aji"],"category":"Oral","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-3_-efficient-low-resource-methods-in-nlp-(oral)"],"id":"148-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["V.S.D.S.Mahesh Akavarapu","Arnab Bhattacharya"],"category":"Poster","demo_url":null,"display_track":"Phonology, Morphology, and Word Segmentation","event_ids":["session-8_-phonology,-morphology,-and-word-segmentation-(poster)"],"id":"149","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Automated Cognate Detection as a Supervised Link Prediction Task with Cognate Transformer","tldr":"","track":"Phonology, Morphology, and Word Segmentation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Identification of cognates across related languages is one of the primary problems in historical linguistics. Automated cognate identification is helpful for several downstream tasks including identifying sound correspondences, proto-language reconstruction, phylogenetic classification, etc. Previous state-of-the-art methods are mostly based on distributions of phonemes computed across multilingual wordlists and make little use of the cognacy labels that define links among cognate clusters. In this paper, we present a transformer-based architecture inspired by computational biology for the task of automated cognate detection. Beyond a certain amount of supervision, this method performs better than the existing methods, and shows steady improvement with further increase in supervision proving the efficacy of utilizing the labeled information. We also demonstrate that accepting multiple sequence alignments as input and having an end-to-end architecture with link prediction head saves much computation time while simultaneously yielding superior performance.","anthology_url":null,"authors":["V.S.D.S.Mahesh Akavarapu","Arnab Bhattacharya"],"category":"Oral","demo_url":null,"display_track":"Linguistic Theory and Insights","event_ids":["session-4_-linguistic-theory-and-insights-(oral)"],"id":"149-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Automated Cognate Detection as a Supervised Link Prediction Task with Cognate Transformer","tldr":"","track":"Linguistic Theory and Insights","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Na Min An","Sania Waheed","James Thorne"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["business-meeting_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"150","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Capturing the Relationship Between Sentence Triplets for LLM and Human-Generated Texts to Enhance Sentence Embeddings","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Shivani Kumar","Tanmoy Chakraborty"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["business-meeting_-dialogue-and-interactive-systems-(poster)"],"id":"151","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yoshi Suhara","Dimitris Alikaniotis"],"category":"Poster","demo_url":null,"display_track":"Summarization","event_ids":["business-meeting_-summarization-(poster)"],"id":"153","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Source Identification in Abstractive Summarization","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jeongwoo Park","Enrico Liscio","Pradeep Kumar Murukannaiah"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-8_-computational-social-science-and-cultural-analytics-(poster)"],"id":"154","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kaiyan Zhao","Qiyu Wu","Xin-Qiang Cai","Yoshimasa Tsuruoka"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["business-meeting_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"155","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leveraging Multi-lingual Positive Instances in Contrastive Learning to Improve Sentence Embedding","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Effective content moderation is imperative for fostering healthy and productive discussions in online domains. Despite the substantial efforts of moderators, the overwhelming nature of discussion flow can limit their effectiveness. However, it is not only trained moderators who intervene in online discussions to improve their quality. \u201cOrdinary\u201d users also act as moderators, actively intervening to correct information of other users\u2019 posts, enhance arguments, and steer discussions back on course.  This paper introduces the phenomenon of user moderation, documenting and releasing UMOD, the first dataset of comments in which  users act as moderators. UMOD contains 1000 comment-reply pairs from the subreddit r/changemyview with crowdsourced annotations from a large annotator pool and with a fine-grained annotation schema targeting the functions of moderation, stylistic properties  (aggressiveness, subjectivity, sentiment), constructiveness, as well as the individual perspectives of the annotators on the task. The release  of UMOD is complemented by two analyses which focus on the constitutive features of constructiveness in user moderation and on the  sources of annotator disagreements, given the high subjectivity of the task.","anthology_url":null,"authors":["Neele Falk","Eva Maria Vecchi","Iman Jundi","Gabriella Lapesa"],"category":"Oral","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-10_-computational-social-science-and-cultural-analytics-(oral)"],"id":"156-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Moderation in the Wild: Investigating User-Driven Moderation in Online Discussions","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kurt Micallef","Nizar Habash","Claudia Borg","Fadhl Eryani","Houda Bouamor"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"157","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Although multilingual language models exhibit impressive cross-lingual transfer capabilities on unseen languages, the performance on downstream tasks is impacted when there is a script disparity with the languages used in the multilingual model's pre-training data. Using transliteration offers a straightforward yet effective means to align the script of a resource-rich language with a target language thereby enhancing cross-lingual transfer capabilities. However, for mixed languages, this approach is suboptimal, since only a subset of the language benefits from the cross-lingual transfer while the remainder is impeded. In this work, we focus on Maltese, a Semitic language, with substantial influences from Arabic, Italian, and English, and notably written in Latin script. We present a novel dataset annotated with word-level etymology. We use this dataset to train a classifier that enables us to make informed decisions regarding the appropriate processing of each token in the Maltese language. We contrast indiscriminate transliteration or translation to mixing processing pipelines that only transliterate words of Arabic origin, thereby resulting in text with a mixture of scripts. We fine-tune the processed data on four downstream tasks and show that conditional transliteration based on word etymology yields the best results, surpassing fine-tuning with raw Maltese or Maltese processed with non-selective pipelines.","anthology_url":null,"authors":["Kurt Micallef","Nizar Habash","Claudia Borg","Fadhl Eryani","Houda Bouamor"],"category":"Oral","demo_url":null,"display_track":"Machine Translation","event_ids":["session-9_-machine-translation-(oral)"],"id":"157-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Giulio Zhou","Tsz Kin Lam","Alexandra Birch","Barry Haddow"],"category":"Poster","demo_url":null,"display_track":"Speech recognition, text-to-speech and spoken language understanding","event_ids":["session-10_-speech-recognition,-text-to-speech-and-spoken-language-understanding-(poster)"],"id":"158","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Prosody in Cascade and Direct Speech-to-Text Translation: a case study on Korean Wh-Phrases","tldr":"","track":"Speech recognition, text-to-speech and spoken language understanding","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ana Ezquerro","Carlos G\u00f3mez-Rodr\u00edguez","David Vilares"],"category":"Poster","demo_url":null,"display_track":"Syntax: Tagging, Chunking and Parsing","event_ids":["session-8_-syntax_-tagging,-chunking-and-parsing-(poster)"],"id":"159","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"From Partial to Strictly Incremental Constituent Parsing","tldr":"","track":"Syntax: Tagging, Chunking and Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We study incremental constituent parsers to assess their capacity to output trees based on prefix representations alone. Guided by strictly left-to-right generative language models and tree-decoding modules, we build parsers that adhere to a strong definition of incrementality across languages. This builds upon work that asserted incrementality, but that mostly only enforced it on either the encoder or the decoder. Finally, we conduct an analysis against non-incremental and partially incremental models.","anthology_url":null,"authors":["Ana Ezquerro","Carlos G\u00f3mez-Rodr\u00edguez","David Vilares"],"category":"Oral","demo_url":null,"display_track":"Discourse and Syntactic Parsing","event_ids":["session-3_-discourse-and-syntactic-parsing-(oral)"],"id":"159-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"From Partial to Strictly Incremental Constituent Parsing","tldr":"","track":"Discourse and Syntactic Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Chanjun Park","Jaehyung Seo","Seolhwa Lee","Junyoung Son","Hyeonseok Moon","Sugyeong Eo","Chanhee Lee","Heuiseok Lim"],"category":"Poster","demo_url":null,"display_track":"Speech recognition, text-to-speech and spoken language understanding","event_ids":["session-10_-speech-recognition,-text-to-speech-and-spoken-language-understanding-(poster)"],"id":"16","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"  Hyper-BTS Dataset: Scalability and Enhanced Analysis of Back TranScription (BTS) for ASR Post-Processing","tldr":"","track":"Speech recognition, text-to-speech and spoken language understanding","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Chunkit Chan","Cheng Jiayang","Weiqi Wang","Yuxin Jiang","Tianqing Fang","Xin Liu","Yangqiu Song"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"160","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Exploring the Potential of ChatGPT on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Tzuf Paz-Argaman","John Palowitch","SAYALI KULKARNI","Jason Michael Baldridge","Reut Tsarfaty"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"161","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Where Do We Go From Here? Multi-scale Allocentric Relational Inferencefrom Natural Spatial Descriptions","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Language models (LMs) are statistical models trained to assign probability to human-generated text. As such, it is reasonable to question whether they approximate linguistic variability exhibited by humans well. This form of statistical assessment is difficult to perform at the passage level, for it requires acceptability judgments (i.e., human evaluation) or a robust automated proxy (which is non-trivial). At the word level, however, given some context, samples from an LM can be assessed via exact matching against a prerecorded dataset of alternative single-word continuations of the available context. We exploit this fact and evaluate the LM\u2019s ability to reproduce variability that humans (in particular, a population of English speakers) exhibit in the \u2018next word prediction\u2019 task. This can be seen as assessing a form of calibration, which, in the context of text classification, Baan et al. (2022) termed calibration to human uncertainty. We assess GPT2, BLOOM and ChatGPT and find that they exhibit fairly low calibration to human uncertainty. We also verify the failure of expected calibration error (ECE) to reflect this, and as such, advise the community against relying on it in this setting.","anthology_url":null,"authors":["Evgenia Ilia","Wilker Aziz"],"category":"Oral","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-10_-resources-and-evaluation-(oral)"],"id":"162-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Predict the Next Word: <Humans exhibit uncertainty in this task and language models _____>","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Rose E Wang","Pawan Wirawarn","Omar Khattab","Noah Goodman","Dorottya Demszky"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"163","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Backtracing: Retrieving the Cause of the Query","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Chao-Wei Huang","Chen-An Li","Tsu-Yuan Hsu","Chen-Yu Hsu","Yun-Nung Chen"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"164","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nannan Huang","Haytham M. Fayek","Xiuzhen Zhang"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-8_-ethics-and-nlp-(poster)"],"id":"165","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Bias in Opinion Summarisation from Pre-training to Adaptation: A Case Study in Political Bias","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Opinion summarisation aims to summarise the salient information and opinions presented in documents such as product reviews, discussion forums, and social media texts into short summaries that enable users to effectively understand the opinions therein.  Generating biased summaries has the risk of potentially swaying public opinion. Previous studies focused on studying bias in opinion summarisation using extractive models, but limited research has paid attention to abstractive summarisation models. In this study, using political bias as a case study, we first establish a methodology to quantify bias in abstractive models, then trace it from the pre-trained models to the task of summarising social media opinions using different models and adaptation methods. We find that most models exhibit intrinsic bias. Using a social media text summarisation dataset and contrasting various adaptation methods, we find that tuning a smaller number of parameters is less biased compared to standard fine-tuning; however, the diversity of topics in training data used for fine-tuning is critical.","anthology_url":null,"authors":["Nannan Huang","Haytham M. Fayek","Xiuzhen Zhang"],"category":"Oral","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-9_-ethics-and-nlp-(oral)"],"id":"165-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Bias in Opinion Summarisation from Pre-training to Adaptation: A Case Study in Political Bias","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Priyanka Sukumaran","Conor Houghton","Nina Kazanina"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"166","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Investigating grammatical abstraction in language models using few-shot learning of novel noun gender","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Long documents often exhibit structure with hierarchically organized elements of different functions, such as section headers and paragraphs. Despite the omnipresence of document structure, its role in natural language processing (NLP) remains opaque. Do long-document Transformer models acquire an internal representation of document structure during pre-training? How can structural information be communicated to a model after pre-training, and how does it influence downstream performance? To answer these questions, we develop a novel suite of probing tasks to assess structure-awareness of long-document Transformers, propose general-purpose structure infusion methods, and evaluate the effects of structure infusion on QASPER and Evidence Inference, two challenging long-document NLP tasks. Results on LED and LongT5 suggest that they acquire implicit understanding of document structure during pre-training, which can be further enhanced by structure infusion, leading to improved end-task performance. To foster research on the role of document structure in NLP modeling, we make our data and code publicly available.","anthology_url":null,"authors":["Jan Buchmann","Max Eichler","Jan-Micha Bodensohn","Ilia Kuznetsov","Iryna Gurevych"],"category":"Oral","demo_url":null,"display_track":"Semantics and Applications","event_ids":["session-9_-semantics-and-applications-(oral)"],"id":"168-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Document Structure in Long Document Transformers","tldr":"","track":"Semantics and Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Neil Shah","Saiteja Kosgi","Vishal Tambrahalli","Neha S","Anil Kumar Nelakanti","Vineet Gandhi"],"category":"Poster","demo_url":null,"display_track":"Speech recognition, text-to-speech and spoken language understanding","event_ids":["session-10_-speech-recognition,-text-to-speech-and-spoken-language-understanding-(poster)"],"id":"17","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"ParrotTTS: Text-to-speech synthesis exploiting disentangled self-supervised representations","tldr":"","track":"Speech recognition, text-to-speech and spoken language understanding","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Wenyan Li","Jonas F. Lotz","Chen Qiu","Desmond Elliott"],"category":"Poster","demo_url":null,"display_track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","event_ids":["session-10_-multimodality-and-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"170","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"The Role of Data Curation in Image Captioning","tldr":"","track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Image captioning models are typically trained by treating all samples equally, neglecting to account for mismatched or otherwise difficult data points. In contrast, recent work has shown the effectiveness of training models by scheduling the data using curriculum learning strategies. This paper contributes to this direction by actively curating difficult samples in datasets without increasing the total number of samples. We explore the effect of using three data curation methods within the training process: complete removal of an sample, caption replacement, or image replacement via a text-to-image generation model. Experiments on the Flickr30K and COCO datasets with the BLIP and BEiT-3 models demonstrate that these curation methods do indeed yield improved image captioning models, underscoring their efficacy.","anthology_url":null,"authors":["Wenyan Li","Jonas F. Lotz","Chen Qiu","Desmond Elliott"],"category":"Oral","demo_url":null,"display_track":"Multimodality","event_ids":["session-3_-multimodality-(oral)"],"id":"170-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"The Role of Data Curation in Image Captioning","tldr":"","track":"Multimodality","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent evidence from cognitive science suggests that there exist two classes of cognitive representations within the spatial terms of a language, one represented geometrically (e.g., above, below) and the other functionally (e.g., on, in). It has been hypothesized that geometric terms are more constrained and are mastered relatively early in language learning, whereas functional terms are less constrained and are mastered over longer time periods (Landau, 2016). One consequence of this hypothesis is that these two classes should exhibit different cross-linguistic variability, which is supported by human elicitation studies.      In this work we present to our knowledge the first corpus-based empirical test of this hypothesis. We develop a pipeline for extracting, isolating, and aligning spatial terms in basic locative constructions from parallel text. Using Shannon entropy to measure the variability of spatial term use across eight languages, we find supporting evidence that variability in functional terms differs significantly from that of geometric terms. We also perform latent variable modeling and find support for the division of spatial terms into geometric and functional classes.","anthology_url":null,"authors":["Peter Viechnicki","Kevin Duh","Anthony Kostacos","Barbara Landau"],"category":"Oral","demo_url":null,"display_track":"Linguistic Theory and Insights","event_ids":["session-4_-linguistic-theory-and-insights-(oral)"],"id":"171-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Large-Scale Bitext Corpora Provide New Evidence for Cognitive Representations of Spatial Terms","tldr":"","track":"Linguistic Theory and Insights","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Language models (LMs) have recently shown remarkable performance on reasoning tasks by explicitly generating intermediate inferences,  e.g., chain-of-thought prompting. However, these intermediate inference steps may be inappropriate deductions from the initial context  and lead to incorrect final predictions. Here we introduce REFINER, a framework for finetuning LMs to explicitly generate intermediate reasoning steps while interacting with a critic model that provides automated feedback on the reasoning. Specifically, the critic provides structured feedback that the reasoning LM uses to iteratively improve its intermediate arguments. Empirical evaluations of REFINER on three diverse reasoning tasks show significant improvements over baseline LMs of comparable scale. Furthermore, when using GPT-3.5 or ChatGPT as the reasoner, the trained critic significantly improves reasoning without finetuning the reasoner. Finally, our critic model is trained without expensive human-in-the-loop data but can be substituted with humans at inference time.","anthology_url":null,"authors":["Debjit Paul","Mete Ismayilzada","Maxime Peyrard","Beatriz Borges","Antoine Bosselut","Robert West","Boi Faltings"],"category":"Oral","demo_url":null,"display_track":"Sentence-level Semantics","event_ids":["session-6_-sentence-level-semantics-(oral)"],"id":"174-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"REFINER: Reasoning Feedback on Intermediate Representations","tldr":"","track":"Sentence-level Semantics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"While demographic factors like age and gender change the way people talk, and in particular, the way people talk to machines, there is little investigation into how large pre-trained language models (LMs) can adapt to these changes. To remedy this gap, we consider how demographic factors in LM language skills can be measured to determine compatibility with a target demographic. We suggest clinical techniques from Speech Language Pathology, which has norms for acquisition of language skills in humans. We conduct evaluation with a domain expert (i.e., a clinically licensed speech language pathologist), and also propose automated techniques to complement clinical evaluation at scale. Empirically, we focus on age, finding LM capability varies widely depending on task: GPT-3.5 mimics the ability of humans ranging from age 6-15 at tasks requiring inference, and simultaneously, outperforms a typical 21 year old at memorization. GPT-3.5 also has trouble with social language use, exhibiting less than 50% of the tested pragmatic skills. Findings affirm the importance of considering demographic alignment and conversational goals when using LMs as public-facing tools. Code, data, and a package will be available.","anthology_url":null,"authors":["Anthony Sicilia","Jennifer C. Gates","Malihe Alikhani"],"category":"Oral","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-2_-dialogue-and-interactive-systems-(oral)"],"id":"175-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"HumBEL: A Human-in-the-Loop Approach for Evaluating Demographic Factors of Language Models in Human-Machine Conversations","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies. We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs. With a computational complexity of $\\mathcal{O}(L \\log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns. We evaluate our model on a series of long document abstractive summarization tasks. The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference. Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing.","anthology_url":null,"authors":["Florian Le Bronnec","Song Duong","Mathieu Ravaut","Alexandre Allauzen","Nancy F. Chen","Vincent Guigue","Alberto Lumbreras","Laure Soulier","patrick gallinari"],"category":"Oral","demo_url":null,"display_track":"Summarization","event_ids":["session-8_-summarization-(oral)"],"id":"176-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LOCOST: State-Space Models for Long Document Abstractive Summarization","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kai Konen","Sophie Jentzsch","Diaoul\u00e9 Diallo","Peer Sch\u00fctt","Oliver Bensch","Roxanne El Baff","Dominik Opitz","Tobias Hecking"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-3_-dialogue-and-interactive-systems-(poster)"],"id":"177","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Style Vectors for Steering Generative Large Language Models","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sahar Sadrizadeh","Ljiljana Dolamic","Pascal Frossard"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"179","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Classification-Guided Approach for Adversarial Attacks against Neural Machine Translation","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yue Zhang","Quan Guo","Parisa Kordjamshidi"],"category":"Poster","demo_url":null,"display_track":"Language Grounding to Vision, Robotics and Beyond","event_ids":["business-meeting_-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"18","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"NavHint: Vision and Language Navigation Agent with a Hint Generator","tldr":"","track":"Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Gender-neutral translation (GNT) that avoids biased and undue binary assumptions is a pivotal challenge for the creation of more inclusive translation technologies. Advancements for this task in Machine Translation (MT), however, are hindered by the lack of dedicated parallel data, which are necessary to adapt MT systems to satisfy neutral constraints. For such a scenario, large language models offer hitherto unforeseen possibilities, as they come with the distinct advantage of being versatile in various (sub)tasks when provided with explicit instructions. In this paper, we explore this potential to automate GNT by comparing MT with the popular GPT-4 model. Through extensive manual analyses, our study empirically reveals the inherent limitations of current MT systems in generating GNTs and provides valuable insights into the potential and challenges associated with prompting for neutrality.","anthology_url":null,"authors":["Beatrice Savoldi","Andrea Piergentili","Dennis Fucci","Matteo Negri","Luisa Bentivogli"],"category":"Oral","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-9_-ethics-and-nlp-(oral)"],"id":"180-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Prompt Response to the Demand for Automatic Gender-Neutral Translation","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Irina Saparina","Mirella Lapata"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"182","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving Generalization in Semantic Parsing by Increasing Natural Language Variation","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Text-to-SQL semantic parsing has made significant progress in recent years, with various models demonstrating impressive performance on the challenging Spider benchmark. However, it has also been shown that these models often struggle to generalize even when faced with small perturbations of previously (accurately) parsed expressions. This is mainly due to the linguistic form of questions in Spider which are overly specific, unnatural, and display limited variation. In this work, we use data augmentation to enhance the robustness of text-to-SQL parsers against natural language variations. Existing approaches generate question reformulations either via models trained on Spider or only introduce local changes. In contrast, we leverage the capabilities of large language models to generate more realistic and diverse questions. Using only a few prompts, we achieve a two-fold increase in the number of questions in Spider. Training on this augmented    dataset yields substantial improvements on a range of evaluation sets, including robustness benchmarks and out-of-domain data.","anthology_url":null,"authors":["Irina Saparina","Mirella Lapata"],"category":"Oral","demo_url":null,"display_track":"Discourse and Syntactic Parsing","event_ids":["session-3_-discourse-and-syntactic-parsing-(oral)"],"id":"182-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving Generalization in Semantic Parsing by Increasing Natural Language Variation","tldr":"","track":"Discourse and Syntactic Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Large pre-trained language models have recently been expanded and applied to programming language tasks with great success, often through further pre-training of a strictly-natural language model--where training sequences typically contain both natural and (linearised) programming language. Such approaches effectively map both modalities of the sequence into the same embedding space. However, programming language keywords (e.g. ``while'') often have very strictly defined semantics. As such, transfer learning from their natural language usage may not necessarily be beneficial to their code application and vise versa. Assuming an already pre-trained language model, in this work we investigate how sequence tokens can be adapted and represented differently, depending on which modality they belong to, and to the ultimate benefit of the downstream task. We experiment with separating embedding spaces between modalities during further model pre-training with modality-relative training objectives. We focus on text-to-code generation and observe consistent improvements across two backbone models and two test sets, measuring pass@$k$ and a novel incremental variation.","anthology_url":null,"authors":["Fenia Christopoulou","Guchun Zhang","Gerasimos Lampouras"],"category":"Oral","demo_url":null,"display_track":"Generation","event_ids":["session-7_-generation-(oral)"],"id":"183-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Text-to-Code Generation with Modality-relative Pre-training","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Grammatical Error Correction (GEC) enhances language proficiency and promotes effective communication, but research has primarily centered around English. We propose a simple approach to multilingual and low-resource GEC by exploring the potential of multilingual machine translation (MT) models for error correction. We show that MT models are not only capable of error correction out-of-the-box, but that they can also be fine-tuned to even better correction quality. Results show the effectiveness of this approach, with our multilingual model outperforming similar-sized mT5-based models and even competing favourably with larger models.","anthology_url":null,"authors":["Agnes Luhtaru","Elizaveta Korotkova","Mark Fishel"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 2","event_ids":["session-8_-multilinguality-and-language-diversity-2-(oral)"],"id":"184-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"No Error Left Behind: Multilingual Grammatical Error Correction with Pre-trained Translation Models","tldr":"","track":"Multilinguality and Language Diversity 2","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Joris Baan","Raquel Fern\u00e1ndez","Barbara Plank","Wilker Aziz"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"185","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Interpreting Predictive Probabilities: Model Confidence or Human Label Variation?","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yang Liu"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["business-meeting_-ethics-and-nlp-(poster)"],"id":"186","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Quantifying Stereotypes in Language","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Hossein Rajaby Faghihi","Parisa Kordjamshidi"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"187","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Consistent Joint Decision-Making with Heterogeneous Learning Models","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We present Archer, a challenging bilingual text-to-SQL dataset specific to complex reasoning, including arithmetic, commonsense and hypothetical reasoning. It contains 1,042 English questions and 1,042 Chinese questions, along with 521 unique SQL queries, covering 20 English databases across 20 domains. Notably, this dataset demonstrates a significantly higher level of complexity compared to existing publicly available datasets. Our evaluation shows that Archer challenges the capabilities of current state-of-the-art models, with a high-ranked model on the Spider leaderboard achieving only 6.73% execution accuracy on Archer test set. Thus, Archer presents a significant challenge for future research in this field.","anthology_url":null,"authors":["Danna Zheng","Mirella Lapata","Jeff Z. Pan"],"category":"Oral","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-10_-resources-and-evaluation-(oral)"],"id":"19-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Archer: A Human-Labeled Text-to-SQL Dataset with Arithmetic, Commonsense and Hypothetical Reasoning","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sarah Masud","Mohammad Aflah Khan","Vikram Goyal","Md Shad Akhtar","Tanmoy Chakraborty"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-8_-computational-social-science-and-cultural-analytics-(poster)"],"id":"190","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Probing Critical Learning Dynamics of LLMs for Hate Speech Detection","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Large Foundational Language Models are capable of performing many tasks at a high level but are difficult to deploy in many applications because of their size and proprietary ownership. Many will be motivated to distill specific capabilities of foundational models into smaller models that can be owned and controlled. In the development of a therapeutic chatbot, we wish to distill a capability known as reflective listening, in which a therapist produces reflections of client speech. These reflections either restate what a client has said, or connect what was said to a relevant observation, idea or guess that encourages and guides the client to continue contemplation. In this paper, we present a method for distilling the generation of reflections from a Foundational Language Model (GPT-4) into smaller models. We first show that GPT-4, using zero-shot prompting, can generate reflections at near 100% success rate, superior to all previous methods. Using reflections generated by GPT-4, we fine-tune different sizes of the GPT-2 family. The GPT-2-small model achieves 83% success on a hold-out test set and the GPT-2 XL achieves 90% success. We also show that GPT-4 can help in the labor-intensive task of evaluating the quality of the distilled models, using it as a zero-shot classifier. Using triple-human review as a guide, the classifier achieves a Cohen-Kappa of 0.66, a substantial inter-rater reliability figure.","anthology_url":null,"authors":["Andrew Brown","Jiading Zhu","Mohamed Abdelwahab","Alec Dong","Cindy Wang","Jonathan Rose"],"category":"Oral","demo_url":null,"display_track":"NLP Applications","event_ids":["session-6_-nlp-applications-(oral)"],"id":"191-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Generation, Distillation and Evaluation of Motivational Interviewing-Style Reflections with a Foundational Language Model","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Niv Fono","Harel Moshayof","Eldar Karol","Itai Assraf","Mark Last"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"192","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Reconstruction of Ancient Hebrew and Aramaic Texts Using Transformers","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Anton Razzhigaev","Matvey Mikhalchuk","Elizaveta Goncharova","Ivan Oseledets","Denis Dimitrov","Andrey Kuznetsov"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"194","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Frank Palma Gomez","Alla Rozovskaya"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-11_-resources-and-evaluation-(poster)"],"id":"196","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Multi-Reference Benchmarks for Russian Grammatical Error Correction","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Niloofar Mireshghallah"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["business-meeting_-ethics-and-nlp-(poster)"],"id":"197","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Smaller Language Models are Better Zero-shot Machine-Generated Text Detectors","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Training Large Language Models (LLMs) to follow user instructions has shown to supply the LLM with ample capacity to converse fluently while being aligned with humans. Yet, it is not completely clear how an LLM can lead a plan-grounded conversation in mixed-initiative settings where instructions flow in both directions of the conversation, i.e. both the LLM and the user provide instructions to one another. In this paper, we tackle a dual goal mixed-initiative conversational setting where the LLM not only grounds the conversation on an arbitrary plan but also seeks to satisfy both a procedural plan and user instructions. The LLM is then responsible for guiding the user through the plan and, at the same time, adapting to new circumstances, answering questions, and activating safety guardrails when needed. We propose a novel LLM that grounds the dialogue on a procedural plan, can take the dialogue initiative, and enforces guardrails on the system's behavior, while also improving the LLM's responses to unexpected user behavior. Experiments in controlled settings and with real users show that the best-performing model, which we call PlanLLM, achieves a 2.1x improvement over a strong baseline. Moreover, experiments also show good generalization to unseen domains.","anthology_url":null,"authors":["Diogo Gl\u00f3ria-Silva","Rafael Ferreira","Diogo Tavares","David Semedo","Joao Magalhaes"],"category":"Oral","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-2_-machine-learning-for-nlp-(oral)"],"id":"198-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Plan-Grounded Large Language Models for Dual Goal Conversational Settings","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The propagation of offensive content through social media channels has garnered attention of the research community. Multiple works have proposed various semantically related yet subtle distinct categories of offensive speech. In this work, we explore meta-learning approaches to leverage the diversity of offensive speech corpora to enhance their reliable and efficient detection. We propose a joint embedding architecture that incorporates the input's label and definition for classification via Prototypical Network. Our model achieves at least 75% of the maximal F1-score while using less than 10% of the available training data across 4 datasets. Our experimental findings also provide a case study of training strategies valuable to combat resource scarcity.","anthology_url":null,"authors":["Huy Nghiem","Umang Gupta","Fred Morstatter"],"category":"Oral","demo_url":null,"display_track":"Opinion, Sentiment and Emotion","event_ids":["session-4_-opinion,-sentiment-and-emotion-(oral)"],"id":"199-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"\u201cDefine Your Terms\u201d : Enhancing Efficient Offensive Speech Classification with Definition","tldr":"","track":"Opinion, Sentiment and Emotion","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["XIN QUAN","Marco Valentino","Louise A. Dennis","Andre Freitas"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-8_-ethics-and-nlp-(poster)"],"id":"2","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"An increasing amount of research in Natural Language Inference (NLI) focuses on the application and evaluation of Large Language Models (LLMs) and their reasoning capabilities. Despite their success, however, LLMs are still prone to factual errors and inconsistencies in their explanations, offering limited control and interpretability for inference in complex domains.   In this paper, we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques can enhance the logical validity and alignment of ethical explanations produced by LLMs. Specifically, we present an abductive-deductive framework named Logic-Explainer, which integrates LLMs with an external backward-chaining solver to refine step-wise natural language explanations and jointly verify their correctness, reduce incompleteness and minimise redundancy. An extensive empirical analysis demonstrates that Logic-Explainer can improve explanations generated via in-context learning methods and Chain-of-Thought (CoT) on challenging ethical NLI tasks, while, at the same time, producing formal proofs describing and supporting models' reasoning. As ethical NLI requires commonsense reasoning to identify underlying moral violations, our results suggest the effectiveness of neuro-symbolic methods for multi-step NLI more broadly, opening new opportunities to enhance the logical consistency, reliability, and alignment of LLMs.","anthology_url":null,"authors":["Xin Quan","Marco Valentino","Louise A. Dennis","Andre Freitas"],"category":"Oral","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-9_-ethics-and-nlp-(oral)"],"id":"2-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Thinh Phuoc Ngo","Khoa Tran Anh Dang","Son T. Luu","Kiet Van Nguyen","Ngan Luu-Thuy Nguyen"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-11_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"200","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based Machine Reading Comprehension","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"As large-scale language models become the standard for text generation, there is a greater need to tailor the generations to be more or less concise, targeted, and informative, depending on the audience/application. Existing control approaches primarily adjust the semantic (e.g., emotion, topics), structural (e.g., syntax tree, parts-of-speech), and lexical (e.g., keyword/phrase inclusion) properties of text, but are insufficient to accomplish complex objectives such as pacing which control the complexity and readability of the text. In this paper, we introduce CEV-LM - a lightweight, semi-autoregressive language model that utilizes constrained edit vectors to control three complementary metrics (speed, volume, and circuitousness) that quantify the shape of text (e.g., pacing of content). We study an extensive set of state-of-the-art CTG models and find that CEV-LM provides significantly more targeted and precise control of these three metrics while preserving semantic content, using less training data, and containing fewer parameters.","anthology_url":null,"authors":["Samraj Moorjani","ADIT KRISHNAN","Hari Sundaram"],"category":"Oral","demo_url":null,"display_track":"Generation","event_ids":["session-7_-generation-(oral)"],"id":"201-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CEV-LM: Controlled Edit Vector Language Model for Shaping Natural Language Generations","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We propose an interpretable model to score the subjective bias present in documents, based only on their textual content. Our model is trained on pairs of revisions of the same Wikipedia article, where one version is more biased than the other. Although prior approaches based on bias classification have struggled to obtain a high accuracy for the task, we are able to develop a useful model for scoring bias by learning to accurately perform pairwise comparisons. We show that we can interpret the parameters of the trained model to discover the words most indicative of bias. We also apply our model in three different settings by studying the temporal evolution of bias in Wikipedia articles, comparing news sources based on bias, and scoring bias in law amendments. In each case, we demonstrate that the outputs of the model can be explained and validated, even for the two domains that are outside the training-data domain. We also use the model to compare the general level of bias between domains, where we see that legal texts are the least biased and news media are the most biased, with Wikipedia articles in between.","anthology_url":null,"authors":["Aswin Suresh","Wu Chi hsuan","Matthias Grossglauser"],"category":"Oral","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-10_-computational-social-science-and-cultural-analytics-(oral)"],"id":"202-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"It's All Relative: Learning Interpretable Models for Scoring Subjective Bias in Documents from Pairwise Comparisons","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Hierarchical text classification (HTC) is a complex subtask under multi-label text classification, characterized by a hierarchical label taxonomy and data imbalance. The best-performing models aim to learn a static representation by combining document and hierarchical label information. However, the relevance of document sections can vary based on the hierarchy level, necessitating a dynamic document representation. To address this, we propose HiGen, a text-generation-based framework utilizing language models to encode dynamic text representations. We introduce a level-guided loss function to capture the relationship between text and label name semantics. Our approach incorporates a task-specific pretraining strategy, adapting the language model to in-domain knowledge and significantly enhancing performance for classes with limited examples. Furthermore, we present a new and valuable dataset called ENZYME, designed for HTC, which comprises articles from PubMed with the goal of predicting Enzyme Commission (EC) numbers. Through extensive experiments on the ENZYME dataset and the widely recognized WOS and NYT datasets, our methodology demonstrates superior performance, surpassing existing approaches while efficiently handling data and mitigating class imbalance. We release our code and dataset here: https://github.com/viditjain99/HiGen.","anthology_url":null,"authors":["Vidit Jain","Mukund Rungta","Yuchen Zhuang","Yue Yu","Zeyu Wang","Mu Gao","Jeffrey Skolnick","Chao Zhang"],"category":"Oral","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(oral)"],"id":"203-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"HiGen: Hierarchy-Aware Sequence Generation for Hierarchical Text Classification","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yuxia Wang","Haonan Li","Xudong Han","Preslav Nakov","Timothy Baldwin"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"205","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Do-Not-Answer: Evaluating Safeguards in LLMs","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark M4, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4","anthology_url":null,"authors":["Yuxia Wang","Jonibek Mansurov","Petar Ivanov","Jinyan Su","Artem Shelmanov","Akim Tsvigun","Chenxi Whitehouse","OSAMA MOHAMMED AFZAL","Tarek Mahmoud","Toru Sasaki","Thomas Arnold","Alham Fikri Aji","Nizar Habash","Iryna Gurevych","Preslav Nakov"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 1","event_ids":["session-7_-multilinguality-and-language-diversity-1-(oral)"],"id":"206-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection","tldr":"","track":"Multilinguality and Language Diversity 1","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the {\\em joint morpho-syntactic hypothesis}, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline.   In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.","anthology_url":null,"authors":["Danit Yshaayahu Levi","Reut Tsarfaty"],"category":"Oral","demo_url":null,"display_track":"Discourse and Syntactic Parsing","event_ids":["session-3_-discourse-and-syntactic-parsing-(oral)"],"id":"207-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Truly Joint Neural Architecture for Segmentation and Parsing","tldr":"","track":"Discourse and Syntactic Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Thanh-Nhi Nguyen","Thanh-Phong Le","Kiet Van Nguyen"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-11_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"208","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"ViLexNorm: A Lexical Normalization Corpus for Vietnamese Social Media Text","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recently, continuous diffusion models (CDM) have been introduced into non-autoregressive (NAR) text-to-text generation.   However, the discrete nature of text increases the difficulty of CDM to generate coherent and fluent texts, and also causes the incompatibility problem between CDM and advanced NLP techniques, especially the popular pre-trained language models~(PLMs).  To solve it, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM) into NAR text-to-text generation and integrates BART to improve the performance.  By revising the decoding process of BART and the typical settings of DDM, we unify the inference process of BART and the denoising process of DDM into the same NAR masked tokens recovering task.  In this way, DDM can rely on BART to perform denoising, which can benefit from both the rich pre-learned knowledge of BART and the iterative refining paradigm of DDM.  Besides, we also propose the iterative self-prompting strategy to further improve the generation quality.  Experimental results on 7 datasets show that our approach can outperform competitive NAR methods, and even surpass autoregressive methods.  Our code and data are released at \\url{https://github.com/RUCAIBox/DiffusionNAT}.","anthology_url":null,"authors":["Kun Zhou","Yifan Li","Xin Zhao","Ji-Rong Wen"],"category":"Oral","demo_url":null,"display_track":"Generation","event_ids":["session-7_-generation-(oral)"],"id":"210-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The prevalence of information manipulation online has created a need for propaganda detection systems. Such systems have typically focused on the surface words, ignoring the linguistic structure. Here we aim to bridge this gap. In particular, we present the first attempt at using discourse analysis for the task. We consider both paragraph-level and token-level classification and we propose a discourse-aware Transformer architecture. Our experiments on English and Russian demonstrate sizeable performance gains compared to a number of baselines. Moreover, our ablation study emphasizes the importance of specific types of discourse features, and our in-depth analysis reveals a strong correlation between propaganda instances and discourse spans.","anthology_url":null,"authors":["Alexander Chernyavskiy","Dmitry Ilvovsky","Preslav Nakov"],"category":"Oral","demo_url":null,"display_track":"Discourse and Syntactic Parsing","event_ids":["session-3_-discourse-and-syntactic-parsing-(oral)"],"id":"211-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Unleashing the Power of Discourse-Enhanced Transformers for Propaganda Detection","tldr":"","track":"Discourse and Syntactic Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Natural Language Processing (NLP) can advance psychotherapy research by scaling up therapy dialogue analysis as well as by allowing researchers to examine client-therapist interactions in detail. Previous studies have mainly either explored the clients' behavior or the therapists' intervention in dialogues. Yet, modelling conversations from both dialogue participants is crucial to understanding the therapeutic interaction. This study explores speaker contribution-based dialogue acts at the utterance-level; i.e, the therapist - Intervention Prediction (IP) and the client - Emotion Recognition (ER) in psychotherapy using a pan-theoretical schema. We perform experiments with fine-tuned language models and light-weight adapter solutions on a Hebrew dataset. We deploy the results from our ER model predictions in investigating the coherence between client self-reports on emotion and the utterance-level emotions. Our best adapters achieved on-par performance with fully fine-tuned models, at 0.64 and 0.66 micro F1 for IP and ER, respectively. In addition, our analysis identifies ambiguities within categorical clinical coding, which can be used to fine-tune the coding schema. Finally, our results indicate a positive correlation between client self-reports and utterance-level emotions.","anthology_url":null,"authors":["Tobias Mayer","Neha Warikoo","Amir Eliassaf","Dana Atzil-Slonim","Iryna Gurevych"],"category":"Oral","demo_url":null,"display_track":"Opinion, Sentiment and Emotion","event_ids":["session-4_-opinion,-sentiment-and-emotion-(oral)"],"id":"213-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Predicting Client Emotions and Therapist Interventions in Psychotherapy Dialogues","tldr":"","track":"Opinion, Sentiment and Emotion","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yassir Fathullah","Puria Radmard","Adian Liusie","Mark Gales"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"214","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Who Needs Decoders? Efficient Estimation of Sequence-Level Attributes with Proxies","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ayush Agrawal","Mirac Suzgun","Lester Mackey","Adam Tauman Kalai"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"215","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Do Language Models Know When They're Hallucinating References?","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yong Cao","Min Chen","Daniel Hershcovich"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-8_-computational-social-science-and-cultural-analytics-(poster)"],"id":"216","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Bridging Cultural Nuances in Dialogue Agents through Cultural Value Surveys","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yihua Zhu","Hidetoshi Shimodaira"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["session-3_-information-extraction-(poster)"],"id":"217","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The main objective of Knowledge Graph (KG) embeddings is to learn low-dimensional representations of entities and relations, enabling the prediction of missing facts. A significant challenge in achieving better KG embeddings lies in capturing relation patterns, including symmetry, antisymmetry, inversion, commutative composition, non-commutative composition, hierarchy, and multiplicity. This study introduces a novel model called 3H-TH (3D Rotation and Translation in Hyperbolic space) that captures these relation patterns simultaneously. In contrast, previous attempts have not achieved satisfactory performance across all the mentioned properties at the same time. The experimental results demonstrate that the new model outperforms existing state-of-the-art models in terms of accuracy, hierarchy property, and other relation patterns in low-dimensional space, meanwhile performing similarly in high-dimensional space.","anthology_url":null,"authors":["Yihua Zhu","Hidetoshi Shimodaira"],"category":"Oral","demo_url":null,"display_track":"Information Extraction","event_ids":["session-4_-information-extraction-(oral)"],"id":"217-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Chinese geographic re-ranking task aims to find the most relevant addresses among retrieved candidates, which is crucial for location-related services such as navigation maps. Unlike the general sentences, Chinese geographic contexts are closely intertwined with geographical concepts, from general spans (e.g., province) to specific spans (e.g., road). Given this feature, we propose an innovative framework, namely Geo-Encoder, to more effectively integrate Chinese geographical semantics into re-ranking pipelines. Our methodology begins by employing off-the-shelf tools to associate text with geographical spans, treating them as chunking units. Then, we present a multi-task learning module to simultaneously acquire an effective attention matrix that determines chunk contributions to geographic representations. Furthermore, we put forth an asynchronous update mechanism for the proposed task, aiming to guide the model to focus on specific chunks. Experiments on two Chinese benchmark datasets, show that the Geo-Encoder achieves significant improvements when compared to state-of-the-art baselines. Notably, it leads to a substantial improvement in the Hit@1 score of MGEO-BERT, increasing it by 6.22% from 62.76 to 68.98 on the GeoTES dataset.","anthology_url":null,"authors":["Yong Cao","Ruixue Ding","Boli Chen","Xianzhi Li","Min Chen","Daniel Hershcovich","Pengjun Xie","Fei Huang"],"category":"Oral","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(oral)"],"id":"218-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Geo-Encoder: A Chunk-Argument Bi-Encoder Framework for Chinese Geographic Re-Ranking","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Wei-Yao Wang","Yu-Chieh Chang","Wen-Chih Peng"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)"],"id":"219","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Style-News: Incorporating Stylized News Generation and Adversarial Verification for Neural Fake News Detection","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yining Lu","Haoping Yu","Daniel Khashabi"],"category":"Poster","demo_url":null,"display_track":"Question Answering","event_ids":["business-meeting_-question-answering-(poster)"],"id":"22","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Xianghe Ma","Michael Strube","Wei Zhao"],"category":"Poster","demo_url":null,"display_track":"Semantics: Lexical","event_ids":["session-8_-semantics_-lexical-(poster)"],"id":"220","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Graph-based Clustering for Detecting Semantic Change Across Time and Languages","tldr":"","track":"Semantics: Lexical","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Despite the predominance of contextualized embeddings in NLP, approaches to detect semantic change relying on these embeddings and clustering methods underperform simpler counterparts based on static word embeddings. This stems from the poor quality of the clustering methods to produce sense clusters---which struggle to capture word senses, especially those with low frequency. This issue hinders the next step in examining how changes in word senses in one language influence another. To address this issue, we propose a graph-based clustering approach to capture nuanced changes in both high- and low-frequency word senses across time and languages, including the acquisition and loss of these senses over time. Our experimental results show that our approach substantially surpasses previous approaches in the SemEval2020 binary classification task across four languages. Moreover, we showcase the ability of our approach as a versatile visualization tool to detect semantic changes in both intra-language and inter-language setups. We make our code and data publicly available.","anthology_url":null,"authors":["Xianghe Ma","Michael Strube","Wei Zhao"],"category":"Oral","demo_url":null,"display_track":"Multilingual Issues","event_ids":["session-6_-multilingual-issues-(oral)"],"id":"220-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Graph-based Clustering for Detecting Semantic Change Across Time and Languages","tldr":"","track":"Multilingual Issues","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Pretrained Language Models (PLMs) learn rich cross-lingual knowledge and perform well on diverse tasks such as translation and multilingual word sense disambiguation (WSD) when finetuned. However, they often struggle at disambiguating word sense in a zero-shot setting. To better understand this contrast, we present a new study investigating how well PLMs capture cross-lingual word sense with Contextual Word-Level Translation (C-WLT), an extension of word-level translation that prompts the model to translate a given word in context. We find that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. Building on C-WLT, we introduce a zero-shot prompting approach for WSD, tested on 18 languages from the XL-WSD dataset. Our method outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning. This study presents a first step towards understanding how to best leverage the cross-lingual knowledge inside PLMs for robust zero-shot reasoning in any language.","anthology_url":null,"authors":["Haoqiang Kang","Terra Blevins","Luke Zettlemoyer"],"category":"Oral","demo_url":null,"display_track":"Multilingual Issues","event_ids":["session-6_-multilingual-issues-(oral)"],"id":"221-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models","tldr":"","track":"Multilingual Issues","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Modern language models often exhibit powerful but brittle behavior, leading to the development of larger and more diverse benchmarks to reliably assess their behavior. Here, we suggest that model performance can be benchmarked and elucidated with much smaller evaluation sets. We first show that in six popular language classification benchmarks, model confidence in the correct class on many pairs of points is strongly correlated across models. We build upon this phenomenon to propose Anchor Point Selection, a technique to select small subsets of datasets that capture model behavior across the entire dataset. Anchor points reliably rank models: across 87 diverse language model-prompt pairs, evaluating models using 1-30 anchor points outperforms uniform sampling and other baselines at accurately ranking models. Moreover, just a dozen anchor points can be used to estimate model per-class predictions on all other points in a dataset with low error, sufficient for gauging where the model is likely to fail. Lastly, we present Anchor Point Maps for visualizing these insights and facilitating comparisons of the performance of different models on various regions within the dataset distribution.","anthology_url":null,"authors":["Rajan Pathe Vivek","Kawin Ethayarajh","Diyi Yang","Douwe Kiela"],"category":"Oral","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-3_-efficient-low-resource-methods-in-nlp-(oral)"],"id":"222-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Anchor Points: Benchmarking Models with Much Fewer Examples","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Eileen Wang","Caren Han","Josiah Poon"],"category":"Poster","demo_url":null,"display_track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","event_ids":["session-11_-multimodality-and-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"223","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SCO-VIST: Social Interaction Commonsense Knowledge-based Visual Storytelling","tldr":"","track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Maxwell Weinzierl","Sanda Harabagiu"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["business-meeting_-computational-social-science-and-cultural-analytics-(poster)"],"id":"224","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Discovering and Articulating Frames of Communication from Social Media Using Chain-of-Thought Reasoning","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yuxia Wang","Minghan Wang","Preslav Nakov"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"226","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Rethinking STS and NLI in Large Language Models","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Lihu Chen","Gael Varoquaux","Fabian M. Suchanek"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"227","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Learning High-Quality and General-Purpose Phrase Representations","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kaushal Kumar Maurya","Rahul Kejriwal","Maunendra Sankar Desarkar","Anoop Kunchukuttan"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-11_-machine-translation-(poster)"],"id":"228","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CharSpan: Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ruochen Zhao","Tan Wang","Yongjie Wang","Shafiq Joty"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-11_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"229","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Explaining Language Model Predictions with High-Impact Concepts","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Adian Liusie","Potsawee Manakul","Mark Gales"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"23","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Arushi Rai","Adriana Kovashka"],"category":"Poster","demo_url":null,"display_track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","event_ids":["session-10_-multimodality-and-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"233","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection","tldr":"","track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The use of large-scale vision-language datasets is limited for object detection due to the negative impact of label noise on localization. Prior methods have shown how such large-scale datasets can be used for pretraining, which can provide initial signal for localization, but is insufficient without clean bounding-box data for at least some categories. We propose a technique to \"vet\" labels extracted from noisy captions, and use them for weakly-supervised object detection (WSOD), without any bounding boxes. We analyze and annotate the types of label noise in captions in our Caption Label Noise dataset, and train a classifier that predicts if an extracted label is actually present in the image or not. Our classifier generalizes across dataset boundaries and across categories. We compare the classifier to nine baselines on five datasets, and demonstrate that it can improve WSOD without label vetting by 30\\% (31.2 to 40.5 mAP when evaluated on PASCAL VOC). See dataset at: https://github.com/arushirai1/CLaNDataset.","anthology_url":null,"authors":["Arushi Rai","Adriana Kovashka"],"category":"Oral","demo_url":null,"display_track":"Multimodality","event_ids":["session-3_-multimodality-(oral)"],"id":"233-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection","tldr":"","track":"Multimodality","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Pardis Sadat Zahraei","Ali Emami"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-11_-resources-and-evaluation-(poster)"],"id":"234","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The Winograd Schema Challenge (WSC) serves as a prominent benchmark for evaluating machine understanding. While Large Language Models (LLMs) excel at answering WSC questions, their ability to generate such questions remains less explored. In this work, we propose Tree-of-Experts (ToE), a novel prompting method which enhances the generation of WSC instances (50% valid cases vs. 10% in recent methods). Using this approach, we introduce WSC+, a novel dataset comprising 3,026 LLM-generated sentences. Notably, we extend the WSC framework by incorporating new 'ambiguous' and 'offensive' categories, providing a deeper insight into model overconfidence and bias. Our analysis reveals nuances in generation-evaluation consistency, suggesting that LLMs may not always outperform in evaluating their own generated questions when compared to those crafted by other models. On WSC+, GPT-4, the top-performing LLM, achieves an accuracy of 68.7%, significantly below the human benchmark of 95.1%.","anthology_url":null,"authors":["Pardis Sadat Zahraei","Ali Emami"],"category":"Oral","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-10_-resources-and-evaluation-(oral)"],"id":"234-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Cross-lingual transfer (XLT) driven by massively multilingual language models (mmLMs) has been shown largely ineffective for low-resource (LR) target languages with little (or no) representation in mmLM's pretraining, especially if they are linguistically distant from the high-resource (HR) source language. Much of the recent focus in XLT research has been dedicated to \\textit{LR language families}, i.e., families without any HR languages (e.g., families of African languages or indigenous languages of the Americas). In this work, in contrast, we investigate a configuration that is arguably of practical relevance for more of the world's languages: XLT to LR languages that do have a close HR relative. To explore the extent to which a HR language can facilitate transfer to its LR relatives, we (1) introduce Karde\\c{s}-NLU, an evaluation benchmark with language understanding datasets in five LR Turkic languages: Azerbaijani, Kazakh, Kyrgyz, Uzbek, and Uyghur; and (2) investigate (a) intermediate training and (b) fine-tuning strategies that leverage Turkish in XLT to these target languages. Our experimental results show that both - integrating Turkish in intermediate training and in downstream fine-tuning - yield substantial improvements in XLT to LR Turkic languages. Finally, we benchmark cutting-edge instruction-tuned large language models on Karde\\c{s}-NLU, showing that their performance is highly task- and language-dependent.","anthology_url":null,"authors":["L\u00fctfi Kerem Senel","Benedikt Ebing","Konul Baghirova","Hinrich Schuetze","Goran Glava\u0161"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 1","event_ids":["session-7_-multilinguality-and-language-diversity-1-(oral)"],"id":"236-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Karde\u015f-NLU: Transfer to Low-Resource Languages with Big Brother's Help -- A Benchmark and Evaluation for Turkic Languages","tldr":"","track":"Multilinguality and Language Diversity 1","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Oscar Chew","Hsuan-Tien Lin","Kai-Wei Chang","Kuan-Hao Huang"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"237","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Understanding and Mitigating Spurious Correlations in Text Classification with Neighborhood Analysis","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Mathieu Ravaut","Hao Zhang","Lu Xu","Aixin Sun","Yong Liu"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["business-meeting_-dialogue-and-interactive-systems-(poster)"],"id":"24","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Parameter-Efficient Conversational Recommender System as a Language Processing Task","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Accurately understanding temporal relations between events is a critical building block of diverse tasks, such as temporal reading comprehension (TRC) and relation extraction (TRE). For example in TRC, we need to understand the temporal semantic differences between the following two questions that are lexically near-identical: \u201cWhat finished right before the decision?\u201d or \u201cWhat finished right after the decision?\u201d. To discern the two questions, existing solutions have relied on answer overlaps as a proxy label to contrast similar and dissimilar questions. However, we claim that answer overlap can lead to unreliable results, due to spurious overlaps of two dissimilar questions with coincidentally identical answers. To address the issue, we propose a novel approach that elicits proper reasoning behaviors through a module for predicting time spans of events. We introduce the Timeline Reasoning Network (TRN) operating in a two-step inductive reasoning process: In the first step model initially answers each question with semantic and syntactic information. The next step chains multiple questions on the same event to predict a timeline, which is then used to ground the answers. Results on the TORQUE and TB-dense, TRC, and TRE tasks respectively, demonstrate that TRN outperforms previous methods by effectively resolving the spurious overlaps using the predicted timeline.","anthology_url":null,"authors":["Jongho Kim","Dohyeon Lee","Minsoo Kim","seung-won hwang"],"category":"Oral","demo_url":null,"display_track":"Information Extraction","event_ids":["session-4_-information-extraction-(oral)"],"id":"240-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Chaining Event Spans for Temporal Relation Grounding","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Neural machine translation (NMT) systems are vulnerable when trained on limited data. This is a common scenario in low-resource tasks in the real world. To increase robustness, a solution is to intently add realistic noise in the training phase. Noise simulation using text perturbation has been proven to be efficient in writing systems that use Latin letters. In this study, we further explore perturbation techniques on more complex abugida writing systems, for which the visual similarity of complex glyphs is considered to capture the essential nature of these writing systems. Besides the generated noise, we propose a training strategy to improve robustness. We conducted experiments on six languages: Bengali, Hindi, Myanmar, Khmer, Lao, and Thai. By overcoming the introduced noise, we obtained non-degenerate NMT systems with improved robustness for low-resource tasks for abugida glyphs.","anthology_url":null,"authors":["Hour Kaing","Chenchen Ding","Hideki Tanaka","Masao Utiyama"],"category":"Oral","demo_url":null,"display_track":"Machine Translation","event_ids":["session-9_-machine-translation-(oral)"],"id":"242-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Robust Neural Machine Translation for Abugidas by Glyph Perturbation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Luyang Lin","Lingzhi Wang","Xiaoyan Zhao","Jing Li","Kam-Fai Wong"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-8_-computational-social-science-and-cultural-analytics-(poster)"],"id":"243","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"IndiVec: An Exploration of Leveraging Large Language Models for Media Bias Detection with Fine-Grained Bias Indicators","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Rishav Hada","Varun Gumma","Adrian de Wynter","Harshita Diddee","Mohamed Ahmed","Monojit Choudhury","Kalika Bali","Sunayana Sitaram"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"245","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We study existing approaches to leverage off-the-shelf Natural Language Inference (NLI) models for the evaluation of summary faithfulness and argue that these are sub-optimal due to the granularity level considered for premises and hypotheses. That is, the smaller content unit considered as hypothesis is a sentence and premises are made up of a fixed number of document sentences. We propose a novel approach, namely INFUSE, that uses a variable premise size and simplifies summary sentences into shorter hypotheses. Departing from previous studies which focus on single short document summarisation, we analyse NLI based faithfulness evaluation for diverse summarisation tasks. We introduce DiverSumm, a new benchmark comprising long form summarisation (long documents and summaries) and diverse summarisation tasks (e.g., meeting and multi-document summarisation). In experiments, INFUSE obtains superior performance across the different summarisation tasks.","anthology_url":null,"authors":["Huajian Zhang","Yumo Xu","Laura Perez-Beltrachini"],"category":"Oral","demo_url":null,"display_track":"Summarization","event_ids":["session-8_-summarization-(oral)"],"id":"246-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Fine-Grained Natural Language Inference Based Faithfulness Evaluation for Diverse Summarisation Tasks","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Textual analogies that make comparisons between two concepts are often used for explaining complex ideas, creative writing, and scientific discovery. In this paper, we propose and study a new task, called Analogy Detection and Extraction (AnaDE), which includes three synergistic sub-tasks: 1) detecting documents containing analogies, 2) extracting text segments that make up the analogy, and 3) identifying the (source and target) concepts being compared. To facilitate the study of this new task, we create a benchmark dataset by scraping Metamia.com and investigate the performances of state-of-the-art models on all sub-tasks to establish the first-generation benchmark results for this new task. We find that the Longformer model achieves the best performance on all the three sub-tasks demonstrating its effectiveness for handling long texts. Moreover, smaller models fine-tuned on our dataset perform better than non-finetuned ChatGPT, suggesting high task difficulty. Overall, the models achieve a high performance on documents detection suggesting that it could be used to develop applications like analogy search engines. Further, there is a large room for improvement on the segment and concept extraction tasks.","anthology_url":null,"authors":["Bhavya Bhavya","Shradha Sehgal","Jinjun Xiong","ChengXiang Zhai"],"category":"Oral","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-10_-resources-and-evaluation-(oral)"],"id":"247-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"AnaDE1.0: A Novel Data Set for Benchmarking Analogy Detection and Extraction","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Christian Khairallah","Reham Marzouk","Salam Khalifa","Mayar Nassar","Nizar Habash"],"category":"Poster","demo_url":null,"display_track":"Phonology, Morphology, and Word Segmentation","event_ids":["session-8_-phonology,-morphology,-and-word-segmentation-(poster)"],"id":"249","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Computational Morphology and Lexicography Modeling of Modern Standard Arabic Nominals","tldr":"","track":"Phonology, Morphology, and Word Segmentation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Much texts describe a changing world (e.g., procedures, stories, newswires), and understanding them requires tracking how entities change. An earlier dataset, OpenPI, provided crowdsourced annotations of entity state changes in text. However, a major limitation was that those annotations were free-form and did not identify salient changes, hampering model evaluation. To overcome these limitations, we present an improved dataset, OpenPI2.0, where entities and attributes are fully canonicalized and additional entity salience annotations are added. On our fairer evaluation setting, we find that current state-of-the-art language models are far from competent. We also show that using state changes of salient entities as a chain-of-thought prompt, downstream performance is improved on tasks such as question answering and classical planning, outperforming the setting involving all related entities indiscriminately. We offer OpenPI2.0 for the continued development of models that can understand the dynamics of entities in text.","anthology_url":null,"authors":["Li Zhang","Hainiu Xu","Abhinav Kommula","Chris Callison-Burch","Niket Tandon"],"category":"Oral","demo_url":null,"display_track":"Information Extraction","event_ids":["session-4_-information-extraction-(oral)"],"id":"25-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"OpenPI2.0: An Improved Dataset for Entity Tracking in Texts","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jinghan Yang","Linjie Xu","Lequan Yu"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"251","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Relabeling Minimal Training Subset to Flip a Prediction","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Sentence representations are a critical component in NLP applications such as retrieval, question answering, and text classification. They capture the meaning of a sentence, enabling machines to understand and reason over human language. In recent years, significant progress has been made in developing methods for learning sentence representations, including unsupervised, supervised, and transfer learning approaches. However there is no literature review on sentence representations till now. In this paper, we provide an overview of the different methods for sentence representation learning, focusing mostly on deep learning models. We provide a systematic organization of the literature, highlighting the key contributions and challenges in this area. Overall, our review highlights the importance of this area in natural language processing, the progress made in sentence representation learning, and the challenges that remain. We conclude with directions for future research, suggesting potential avenues for improving the quality and efficiency of sentence representations.","anthology_url":null,"authors":["Abhinav Ramesh Kashyap","Thanh-Tung Nguyen","Viktor Schlegel","Stefan Winkler","See-Kiong Ng","Soujanya Poria"],"category":"Oral","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(oral)"],"id":"252-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Comprehensive Survey of Sentence Representations: From the BERT Epoch to the CHATGPT Era and Beyond","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Liang Wang","Nan Yang","Furu Wei"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["business-meeting_-information-retrieval-and-text-mining-(poster)"],"id":"253","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Learning to Retrieve In-Context Examples for Large Language Models","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sachin Pawar","Nitin Ramrakhiyani","Anubhav sinha","Manoj Apte","Girish Keshav Palshikar"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"254","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Why Generate When You Can Discriminate? A Novel Technique for Text Classification using Language Models","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Frank Martin Mtumbuka","Steven Schockaert"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["business-meeting_-information-extraction-(poster)"],"id":"256","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"EnCore: Fine-Grained Entity Typing by Pre-Training Entity Encoders on Coreference Chains","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"With the ever-growing use of social media to express opinions on the national and international stage, unsupervised methods of stance detection are increasingly important to handle the task without costly annotation of data. The current unsupervised state-of-the-art models are designed for specific network types, either homophilic or heterophilic, and they fail to generalize to both. In this paper, we first analyze the generalization ability of recent baselines to these two very different network types. Then, we conduct extensive experiments with a baseline model based on text embeddings propagated with a graph neural network that generalizes well to heterophilic and homophilic networks. We show that it outperforms, on average, other state-of-the-art methods across the two network types. Additionally, we show that combining textual and network information outperforms using text only, and that the language model size has only a limited impact on the model performance.","anthology_url":null,"authors":["Maia Sutter","Antoine Gourru","Amine Trabelsi","Christine Largeron"],"category":"Oral","demo_url":null,"display_track":"Opinion, Sentiment and Emotion","event_ids":["session-4_-opinion,-sentiment-and-emotion-(oral)"],"id":"257-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Unsupervised stance detection for social media discussions: A generic baseline","tldr":"","track":"Opinion, Sentiment and Emotion","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nadine Probol","Margot Mieskes"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"258","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Autism Detection in Speech \u2013 A Survey","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Current text classification approaches usually focus on the content to be classified. Contextual aspects (both linguistic and extra-linguistic) are usually neglected, even in tasks based on online discussions. Still in many cases the multi-party and multi-turn nature of the context from which these elements are selected can be fruitfully exploited. In this work, we propose a series of experiments on a large dataset for stance detection in English, in which we evaluate the contribution of different types of contextual information, i.e. linguistic, structural and temporal, by feeding them as natural language input into a transformer-based model. We also experiment with different amounts of training data and analyse the topology of local discussion networks in a privacy-compliant way. Results show that structural information can be highly beneficial to text classification but only under certain circumstances (e.g. depending on the amount of training data and on discussion chain complexity). Indeed, we show that contextual information on smaller datasets from other classification tasks does not yield significant improvements. Our framework, based on local discussion networks, allows the integration of structural information while minimising user profiling, thus preserving their privacy.","anthology_url":null,"authors":["Nicol\u00f2 Penzo","Antonio Longa","Bruno Lepri","Sara Tonelli","Marco Guerini"],"category":"Oral","demo_url":null,"display_track":"Opinion, Sentiment and Emotion","event_ids":["session-4_-opinion,-sentiment-and-emotion-(oral)"],"id":"259-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Putting Context in Context: the Impact of Discussion Structure on Text Classification","tldr":"","track":"Opinion, Sentiment and Emotion","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recently, empathetic dialogue systems have received significant attention.  While some researchers have noted limitations, e.g., that these systems tend to generate generic utterances, no study has systematically verified these issues. We survey 21 systems, asking what progress has been made on the task. We observe multiple limitations of current evaluation procedures. Most critically, studies tend to rely on a single non-reproducible empathy score, which inadequately reflects the multidimensional nature of empathy. To better understand the differences between systems, we comprehensively analyze each system with automated methods that are grounded in a variety of aspects of empathy. We find that recent systems lack three important aspects of empathy: specificity, reflection levels, and diversity. Based on our results, we discuss problematic behaviors that may have gone undetected in prior evaluations, and offer guidance for developing future systems.\\footnote{Our experiments can be found at [Anonymous URL]}","anthology_url":null,"authors":["Andrew Lee","Jonathan K. Kummerfeld","Larry Ann","Rada Mihalcea"],"category":"Oral","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-2_-dialogue-and-interactive-systems-(oral)"],"id":"26-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Comparative Multidimensional Analysis of Empathetic Systems","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Leonardo Ranaldi","Andre Freitas"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"260","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Aligning Large and Small Language Models via Chain-of-Thought Reasoning","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Chain-of-Thought (CoT) prompting empowers  the reasoning abilities of Large Language Models (LLMs), eliciting them to solve complex  reasoning tasks in a step-wise manner. However, these capabilities appear only in models with billions of parameters, which represent an entry barrier for many users who are constrained to operate on a smaller model scale, i.e., Small Language Models (SLMs). Although many companies are releasing LLMs of the same family with fewer parameters, these models tend not to preserve all the reasoning capabilities of the original models, including CoT reasoning.      In this paper, we propose a method for aligning and transferring reasoning abilities between larger to smaller Language Models. By using an Instruction-tuning-CoT method, that is, an Instruction-tuning designed around CoT-Demonstrations, we enable the SLMs to generate multi-step controlled reasoned answers when they are elicited with the CoT mechanism. Hence, we instruct a smaller Language Model using outputs generated by more robust models belonging to the same family or not, evaluating the impact across different types of models. Results obtained on question-answering and mathematical reasoning benchmarks show that LMs instructed via the Instruction-tuning CoT method produced by LLMs outperform baselines within both in-domain and out-domain scenarios.","anthology_url":null,"authors":["Leonardo Ranaldi","Andre Freitas"],"category":"Oral","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-3_-efficient-low-resource-methods-in-nlp-(oral)"],"id":"260-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Aligning Large and Small Language Models via Chain-of-Thought Reasoning","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Multilingual Machine Translation (MMT) benefits from knowledge transfer across different language pairs. However, improvements in one-to-many translation compared to many-to-one translation are only marginal and sometimes even negligible. This performance discrepancy raises the question of to what extent positive transfer plays a role on the target-side for one-to-many MT. In this paper, we conduct a large-scale study that varies the auxiliary target-side languages along two dimensions, i.e., linguistic similarity and corpus size, to show the dynamic impact of knowledge transfer on the main language pairs. We show that linguistically similar auxiliary target languages exhibit strong ability to transfer positive knowledge. With an increasing size of similar target languages, the positive transfer is further enhanced to benefit the main language pairs. Meanwhile, we find distant auxiliary target languages can also unexpectedly benefit main language pairs, even with minimal positive transfer ability. Apart from transfer, we show distant auxiliary target languages can act as a regularizer to benefit translation performance by enhancing the generalization and model inference calibration.","anthology_url":null,"authors":["Yan Meng","Christof Monz"],"category":"Oral","demo_url":null,"display_track":"Machine Translation","event_ids":["session-9_-machine-translation-(oral)"],"id":"262-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Disentangling the Roles of Target-side Transfer and Regularization in Multilingual Machine Translation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Hari Shrawgi","Prasanjit Rath","Tushar Singhal","Sandipan Dandapat"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-8_-ethics-and-nlp-(poster)"],"id":"263","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Uncovering Stereotypes in Large Language Models: A Task Complexity-based Approach","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent Large Language Models (LLMs) have unlocked unprecedented applications of AI. As these models continue to transform human life, there are growing socio-ethical concerns around their inherent stereotypes that can lead to bias in their applications. There is an urgent need for holistic bias evaluation of these LLMs. Few such benchmarks exist today and evaluation techniques that do exist are either non-holistic or may provide a false sense of security as LLMs become better at hiding their biases on simpler tasks. We address these issues with an extensible benchmark - LLM Stereotype Index (LSI). LSI is grounded on Social Progress Index, a holistic social benchmark. We also test the breadth and depth of bias protection provided by LLMs via a variety of tasks with varying complexities. Our findings show that both ChatGPT and GPT-4 have strong inherent prejudice with respect to nationality, gender, race, and religion. The exhibition of such issues becomes increasingly apparent as we increase task complexity. Furthermore, GPT-4 is better at hiding the biases, but when displayed it is more significant. Our findings highlight the harms and divide that these LLMs can bring to society if we do not take very diligent care in their use.","anthology_url":null,"authors":["Hari Shrawgi","Prasanjit Rath","Tushar Singhal","Sandipan Dandapat"],"category":"Oral","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-9_-ethics-and-nlp-(oral)"],"id":"263-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Uncovering Stereotypes in Large Language Models: A Task Complexity-based Approach","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Carolin Holtermann","Markus Frohmann","Navid Rekabsaz","Anne Lauscher"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"264","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Pulkit Agarwal","Settaluri Lakshmi Sravanthi","Pushpak Bhattacharyya"],"category":"Poster","demo_url":null,"display_track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","event_ids":["session-11_-multimodality-and-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"265","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"IndiFoodVQA: A Knowledge-Aware Reasoning-Based Visual Question Answering Dataset for Indian Food Dishes","tldr":"","track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Marie Bexte","Andrea Horbach","Torsten Zesch"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"267","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Rainbow - A Benchmark for Systematic Testing of How Sensitive Visio-Linguistic Models are to Color Naming","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of smaller language models (SLMs) with automatically generated counterfactual (CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain (OOD) performance of SLMs in the extractive question answering (QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise explanations.","anthology_url":null,"authors":["Rachneet Singh Sachdeva","Martin Tutek","Iryna Gurevych"],"category":"Oral","demo_url":null,"display_track":"Question Answering","event_ids":["session-7_-question-answering-(oral)"],"id":"269-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"This paper explores the task of language-agnostic speaker replication, a novel endeavor that seeks to replicate a speaker's voice irrespective of the language they are speaking. Towards this end, we introduce a multi-level attention aggregation approach that systematically probes and amplifies various speaker-specific attributes in a hierarchical manner. Through rigorous evaluations across a wide range of scenarios including seen and unseen speakers conversing in seen and unseen lingua, we establish that our proposed model is able to achieve substantial speaker similarity, and is able to generalize to out-of-domain (OOD) cases.","anthology_url":null,"authors":["Yejin Jeon","Gary Lee"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 2","event_ids":["session-8_-multilinguality-and-language-diversity-2-(oral)"],"id":"27-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Multi-Level Attention Aggregation for Language-Agnostic Speaker Replication","tldr":"","track":"Multilinguality and Language Diversity 2","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Xia Zeng","Arkaitz Zubiaga"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"270","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["David Duki\u0107","Kiril Gashteovski","Goran Glava\u0161","Jan Snajder"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["session-3_-information-extraction-(poster)"],"id":"271","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leveraging Open Information Extraction for More Robust Domain Transfer of Event Trigger Detection","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Wenyue Hua","Yingqiang Ge","Shuyuan Xu","jianchao ji","Zelong Li","Yongfeng Zhang"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)"],"id":"273","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"UP5: Unbiased Foundation Model for Fairness-aware Recommendation","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Prakamya Mishra","Lincy Pattanaik","Arunima Sundar","Nishant Yadav","Mayank Kulkarni"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"274","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Clustering-based Sampling for Few-Shot Cross-Domain Keyphrase Extraction","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zeliang Zhang"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-11_-machine-learning-for-nlp-(poster)"],"id":"276","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Random Smooth-based Certified Defense against Text Adversarial Attack","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Katarzyna Pru\u015b","Mark Steedman","Adam Lopez"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"278","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Human Temporal Inferences Go Beyond Aspectual Class","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Hossein A. Rahmani","Xi Wang","Mohammad Aliannejadi","Mohammadmehdi Naghiaei","Emine Yilmaz"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"279","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Clarifying the Path to User Satisfaction: An Investigation into Clarification Usefulness","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Few-shot learning for open domain multi-hop question answering typically relies on the in-context learning capability of large language models (LLMs). While powerful, these LLMs usually contain tens or hundreds of billions of parameters, making them rather inefficient at inference time. To improve performance of smaller language models, we propose a data synthesis framework for multi-hop question answering that requires less than 10 human-annotated question answer pairs. Our framework depends only on rich, naturally-occurring relationships among documents and is built upon the data generation functions parameterized by LLMs and prompts. We synthesize millions of multi-hop questions and claims to finetune language models, evaluated on popular benchmarks for multi-hop question answering and fact verification. Empirically, our approach improves model performance significantly, allowing the finetuned models to be competitive with GPT-3.5 based approaches while being almost one-third the size in parameter count.","anthology_url":null,"authors":["Mingda Chen","Xilun Chen","Wen-tau Yih"],"category":"Oral","demo_url":null,"display_track":"Question Answering","event_ids":["session-7_-question-answering-(oral)"],"id":"28-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Few-Shot Data Synthesis for Open Domain Multi-Hop Question Answering","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"NLI tasks necessitate a substantial degree of logical reasoning; as such, the remarkable performance of SoTA transformers on these tasks may lead us to believe that those models have learned to reason logically. The results presented in this paper demonstrate that (i) models fine-tuned on NLI datasets learn to treat external negation as a distractor, effectively ignoring its presence in hypothesis sentences; (ii) several near-SoTA encoder and encoder-decoder transformer models fail to inductively learn the law of the excluded middle for a single external negation prefix with respect to NLI tasks, despite extensive fine-tuning; (iii) those models which are are able to learn the law of the excluded middle for a single prefix are unable to generalize this pattern to similar prefixes. Given the critical role of negation in logical reasoning, we may conclude from these findings that transformers do not learn to reason logically when fine-tuned for NLI tasks. Furthermore, these results suggest that transformers may not be able to inductively learn the role of negation with respect to NLI tasks, calling into question their capacity to fully acquire logical reasoning abilities.","anthology_url":null,"authors":["Michael Sullivan"],"category":"Oral","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-10_-interpretability-and-model-analysis-in-nlp-(oral)"],"id":"280-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"It is not True that Transformers are Inductive Learners: Probing NLI Models with External Negation","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["John Pavlopoulos","Aristidis Likas"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"281","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Polarized Opinion Detection Improves the Detection of Toxic Language","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Acoustic word embeddings (AWEs) are vector representations of spoken words. An effective method for obtaining AWEs is the Correspondence Auto-Encoder (CAE). In the past, the CAE method has been associated with traditional MFCC features. Representations obtained from self-supervised learning (SSL)-based speech models such as HuBERT, Wav2vec2, etc., are outperforming MFCC in many downstream tasks. However, they have not been well studied in the context of learning AWEs. This work explores the effectiveness of CAE with SSL-based speech representations to obtain improved AWEs. Additionally, the capabilities of SSL-based speech models are explored in cross-lingual scenarios for obtaining AWEs. Experiments are conducted on five languages: Polish, Portuguese, Spanish, French, and English. HuBERT-based CAE model achieves the best results for word discrimination in all languages, despite HuBERT being pre-trained on English only. Also, the HuBERT-based CAE model works well in cross-lingual settings. It outperforms MFCC-based CAE models trained on the target languages when trained on one source language and tested on target languages.","anthology_url":null,"authors":["Amit Meghanani","Thomas Hain"],"category":"Oral","demo_url":null,"display_track":"Multimodality","event_ids":["session-3_-multimodality-(oral)"],"id":"282-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving Acoustic Word Embeddings through Correspondence Training of Self-supervised Speech Representations","tldr":"","track":"Multimodality","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Lifu Tu","Jin Qu","Semih Yavuz","Shafiq Joty","Wenhao Liu","Caiming Xiong","Yingbo Zhou"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"283","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nikhil Mehta","Milagro Teruel","Xin Deng","Sergio Patricio Figueroa Sanz","Ahmed Hassan Awadallah","Julia Kiseleva"],"category":"Poster","demo_url":null,"display_track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","event_ids":["session-10_-multimodality-and-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"285","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback","tldr":"","track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ashish Sharma","Sudha Rao","Chris Brockett","Akanksha Malhotra","Nebojsa Jojic","Bill Dolan"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["business-meeting_-dialogue-and-interactive-systems-(poster)"],"id":"286","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Investigating Agency of LLMs in Human-AI Collaboration Tasks","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jennifer Hsia","Danish Pruthi","Aarti Singh","Zachary Chase Lipton"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"288","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Goodhart\u2019s Law Applies to NLP\u2019s Explanation Benchmarks","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zhe Zhang","Karol Lasocki","Yi Yu","Atsuhiro Takasu"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)"],"id":"289","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Syllable-level lyrics generation from melody exploiting character-level language model","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In-context learning with Large Language Models (LLMs) has emerged as a promising avenue of research in Dialog State Tracking (DST). However, the best-performing in-context learning methods involve retrieving and adding similar examples to the prompt, requiring access to labeled training data. Procuring such training data for a wide range of domains and applications is time-consuming, expensive, and, at times, infeasible. While zero-shot learning requires no training data, it significantly lags behind the few-shot setup. Thus, `\\textit{Can we efficiently generate synthetic data for any dialogue schema to enable few-shot prompting?}' Addressing this question, we propose \\method, a data generation framework tailored for DST, utilizing LLMs. Our approach only requires the dialogue schema and a few hand-crafted dialogue templates to synthesize natural, coherent, and free-flowing dialogues with DST annotations. Few-shot learning using data from {\\method} results in $4-5\\%$ improvement in Joint Goal Accuracy over the zero-shot baseline on MultiWOZ 2.1 and 2.4. Remarkably, our few-shot learning approach recovers nearly $98\\%$ of the performance compared to the few-shot setup using human-annotated training data\\footnote{Our synthetic data and code can be accessed at \\\\ \\url{ https://github.com/apple/ml-synthdst}.}.","anthology_url":null,"authors":["Atharva Kulkarni","Bo-Hsiang Tseng","Joel Ruben Antony Moniz","Dhivya Piraviperumal","Hong Yu","Shruti Bhargava"],"category":"Oral","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-2_-dialogue-and-interactive-systems-(oral)"],"id":"290-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State Tracking","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Pinzhen Chen","Shaoxiong Ji","Nikolay Bogoychev","Andrey Kutuzov","Barry Haddow","Kenneth Heafield"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"291","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ashish Sunil Agrawal","Barah Fazili","Preethi Jyothi"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"292","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Translation Errors Significantly Impact Low-Resource Languages in Cross-Lingual Learning","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Popular benchmarks (e.g., XNLI) used to evaluate cross-lingual language understanding consist of parallel versions of English evaluation sets in multiple target languages created with the help of professional translators. When creating such parallel data, it is critical to ensure high-quality translations for all target languages for an accurate characterization of cross-lingual transfer. In this work, we find that translation inconsistencies \\emph{do exist} and interestingly they \\emph{disproportionally impact low-resource languages} in XNLI. To identify such inconsistencies, we propose measuring the gap in performance between zero-shot evaluations on the human-translated and machine-translated target text across multiple target languages; relatively large gaps are indicative of translation errors. We also corroborate that translation errors exist for two target languages, namely Hindi and Urdu, by doing a manual reannotation of human-translated test instances in these two languages and finding poor agreement with the original English labels these instances were supposed to inherit.","anthology_url":null,"authors":["Ashish Sunil Agrawal","Barah Fazili","Preethi Jyothi"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 1","event_ids":["session-7_-multilinguality-and-language-diversity-1-(oral)"],"id":"292-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Translation Errors Significantly Impact Low-Resource Languages in Cross-Lingual Learning","tldr":"","track":"Multilinguality and Language Diversity 1","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Tsung-Hsuan Pan","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"294","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Enhancing Society-Undermining Disinformation Detection through Fine-Grained Sentiment Analysis Pre-Finetuning","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Chen Zhang","Yang Yang","Qifan Wang","Jiahao Liu","Jingang Wang","Wei Wu","Dawei Song"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["business-meeting_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"296","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Minimal Distillation Schedule for Extreme Language Model Compression","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Masayuki Kawarada","Tsutomu Hirao","Wataru Uchida","Masaaki Nagata"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"299","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Argument Mining as a Text-to-Text Generation Task","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Marco Valentino","Danilo Carvalho","Andre Freitas"],"category":"Poster","demo_url":null,"display_track":"Semantics: Lexical","event_ids":["session-8_-semantics_-lexical-(poster)"],"id":"3","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Multi-Relational Hyperbolic Word Embeddings from Natural Language Definitions","tldr":"","track":"Semantics: Lexical","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zonglin Yang","Li Dong","Xinya Du","Hao Cheng","Erik Cambria","Xiaodong Liu","Jianfeng Gao","Furu Wei"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["business-meeting_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"30","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Language Models as Inductive Reasoners","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zuoquan Lin"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-3_-dialogue-and-interactive-systems-(poster)"],"id":"301","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Local and Global Contexts for Conversation","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Marius B\u00fcttner","Ivan Habernal"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"302","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Answering legal questions from laymen in German civil law system","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yunshu Wu","Hayate Iso","Pouya Pezeshkpour","Nikita Bhutani","Estevam Hruschka"],"category":"Poster","demo_url":null,"display_track":"Summarization","event_ids":["session-3_-summarization-(poster)"],"id":"303","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Less is More for Long Document Summary Evaluation by LLMs","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Large Language Models (LLMs) have shown promising performance in summary evaluation tasks, yet they face challenges such as high computational costs and the \\textit{Lost-in-the-Middle} problem where important information in the middle of long documents is often overlooked. To address these issues, this paper introduces a novel approach, Extract-then-Evaluate, which involves extracting key sentences from a long source document and then evaluating the summary by prompting LLMs. The results reveal that the proposed method not only significantly reduces evaluation costs but also exhibits a higher correlation with human evaluations. Furthermore, we provide practical recommendations for optimal document length and sentence extraction methods, contributing to the development of cost-effective yet more accurate methods for LLM-based text generation evaluation.","anthology_url":null,"authors":["Yunshu Wu","Hayate Iso","Pouya Pezeshkpour","Nikita Bhutani","Estevam Hruschka"],"category":"Oral","demo_url":null,"display_track":"Summarization","event_ids":["session-8_-summarization-(oral)"],"id":"303-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Less is More for Long Document Summary Evaluation by LLMs","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["ZHAOYUE SUN","Gabriele Pergola","Byron C Wallace","Yulan He"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"308","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical Study","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"With the advent of large language models (LLMs), there has been growing interest in exploring their potential for medical applications. This research aims to investigate the ability of LLMs, specifically ChatGPT, in the context of pharmacovigilance event extraction, of which the main goal is to identify and extract adverse events or potential therapeutic events from textual medical sources. We conduct extensive experiments to assess the performance of ChatGPT in the pharmacovigilance event extraction task, employing various prompts and demonstration selection strategies. The findings demonstrate that while ChatGPT demonstrates reasonable performance with appropriate demonstration selection strategies, it still falls short compared to fully fine-tuned small models. Additionally, we explore the potential of leveraging ChatGPT for data augmentation. However, our investigation reveals that the inclusion of synthesized data into fine-tuning may lead to a decrease in performance, possibly attributed to noise in the ChatGPT-generated labels. To mitigate this, we explore different filtering strategies and find that, with the proper approach, more stable performance can be achieved, although constant improvement remains elusive.","anthology_url":null,"authors":["Zhaoyue Sun","Gabriele Pergola","Byron C Wallace","Yulan He"],"category":"Oral","demo_url":null,"display_track":"NLP Applications","event_ids":["session-6_-nlp-applications-(oral)"],"id":"308-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical Study","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Michiel van der Meer","Piek Vossen","Catholijn M Jonker","Pradeep Kumar Murukannaiah"],"category":"Poster","demo_url":null,"display_track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","event_ids":["session-3_-sentiment-analysis,-stylistic-analysis-and-argument-mining-(poster)"],"id":"309","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"An Empirical Analysis of Diversity in Argument Summarization","tldr":"","track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Presenting high-level arguments is a crucial task for fostering participation in online societal discussions. Current argument summarization approaches miss an important facet of this task---capturing \\emph{diversity}---which is important for accommodating multiple perspectives. We introduce three aspects of diversity: those of opinions, annotators, and sources.   We evaluate approaches to a popular argument summarization task called Key Point Analysis, which shows how these approaches struggle to (1) represent arguments shared by few people, (2) deal with data from various sources, and (3) align with subjectivity in human-provided annotations. We find that both general-purpose LLMs and dedicated KPA models exhibit this behavior, but have complementary strengths. Further, we observe that diversification of training data may ameliorate generalization in zero-shot cases. Addressing diversity in argument summarization requires a mix of strategies to deal with subjectivity.","anthology_url":null,"authors":["Michiel van der Meer","Piek Vossen","Catholijn M Jonker","Pradeep Kumar Murukannaiah"],"category":"Oral","demo_url":null,"display_track":"Summarization","event_ids":["session-8_-summarization-(oral)"],"id":"309-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"An Empirical Analysis of Diversity in Argument Summarization","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Despite the progress in building multilingual language models, evaluation is often limited to a few languages with available datasets which excludes a large number of low-resource languages.   In this paper, we create SIB-200---a large-scale open-sourced benchmark dataset for topic classification in 205 languages and dialects to address the lack of evaluation dataset for Natural Language Understanding (NLU). For many of the languages covered in SIB-200, this is the first publicly available evaluation dataset for NLU. The dataset is based on Flores-200 machine translation corpus. We annotated the English portion of the dataset and extended the sentence-level annotation to the remaining 204 languages covered in the corpus. Despite the simplicity of this task, our evaluation in full-supervised setting, cross-lingual transfer setting and prompting of large language model setting show that there is still a large gap between the performance of high-resource and low-resource languages when multilingual evaluation is scaled to numerous world languages. We found that languages unseen during the pre-training of multilingual language models, languages from under-represented families (like Nilotic and Altantic-Congo), and languages from the regions of Africa, Americas, Oceania and South East Asia, often have the lowest performance on our topic classification dataset. We hope our dataset %will   encourages a more inclusive evaluation of multilingual language models on a more diverse set of languages.","anthology_url":null,"authors":["David Ifeoluwa Adelani","Hannah Liu","Xiaoyu Shen","Nikita Vassilyev","Jesujoba Oluwadara Alabi","Yanke Mao","Haonan Gao","En-Shiun Annie Lee"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 1","event_ids":["session-7_-multilinguality-and-language-diversity-1-(oral)"],"id":"31-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects","tldr":"","track":"Multilinguality and Language Diversity 1","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Verifying biomedical claims fails if no evidence can be discovered. In these cases, the fact-checking verdict remains unknown and the claim is unverifiable. To improve this situation, we have to understand if there are any claim properties that impact its verifiability. In this work we assume that entities and relations define the core variables in a biomedical claim's anatomy and analyze if their properties help us to differentiate verifiable from unverifiable claims. In a study with trained annotation experts we prompt them to find evidence for biomedical claims, and observe how they refine search queries for their evidence search. This leads to the first corpus for scientific fact verification annotated with subject--relation--object triplets, evidence documents, and fact-checking verdicts (the BEAR-FACT corpus). We find (1) that discovering evidence for negated claims (e.g., X--does-not-cause--Y) is particularly challenging. Further, we see that annotators process queries mostly by adding constraints to the search and by normalizing entities to canonical names. (2) We compare our in-house annotations with a small crowdsourcing setting where we employ both medical experts and laypeople. We find that domain expertise does not have a substantial effect on the reliability of annotations. Finally, (3), we demonstrate that it is possible to reliably estimate the success of evidence retrieval purely from the claim text (.82F$_1$), whereas identifying unverifiable claims proves more challenging (.27F$_1$)","anthology_url":null,"authors":["Amelie Wuehrl","Yarik Menchaca Resendiz","Lara Grimminger","Roman Klinger"],"category":"Oral","demo_url":null,"display_track":"Factual Content in NLP","event_ids":["session-2_-factual-content-in-nlp-(oral)"],"id":"310-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"What Makes Medical Claims (Un)Verifiable? Analyzing Entity and Relation Properties for Fact Verification","tldr":"","track":"Factual Content in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Lucas Moeller","Dmitry Nikolaev","Sebastian Pad\u00f3"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"311","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Approximate Attributions for Off-the-Shelf Siamese Transformers","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Generating natural language text from graph-structured data is essential for conversational information seeking. Semantic triples derived from knowledge graphs can serve as a valuable source for grounding responses from conversational agents by providing a factual basis for the information they communicate. This is especially relevant in the context of large language models, which offer great potential for conversational interaction but are prone to hallucinating, omitting, or producing conflicting information. In this study, we conduct an empirical analysis of conversational large language models in generating natural language text from semantic triples. We compare four large language models of varying sizes with different prompting techniques. Through a series of benchmark experiments on the WebNLG dataset, we analyze the models' performance and identify the most common issues in the generated predictions. Our findings show that the capabilities of large language models in triple verbalization can be significantly improved through few-shot prompting, post-processing, and efficient fine-tuning techniques, particularly for smaller models that exhibit lower zero-shot performance.","anthology_url":null,"authors":["Phillip Schneider","Manuel Klettner","Elena Simperl","Florian Matthes"],"category":"Oral","demo_url":null,"display_track":"Generation","event_ids":["session-7_-generation-(oral)"],"id":"312-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ece Takmaz","Sandro Pezzelle","Raquel Fern\u00e1ndez"],"category":"Poster","demo_url":null,"display_track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics","event_ids":["session-8_-linguistic-theories,-cognitive-modeling-and-psycholinguistics-(poster)"],"id":"313","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Describing Images $\\textit{Fast and Slow}$: Quantifying and Predicting the Variation in Human Signals during Visuo-Linguistic Processes","tldr":"","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Acquiring factual knowledge for language models (LMs) in low-resource languages poses a serious challenge, thus resorting to cross-lingual transfer in multilingual LMs (ML-LMs). In this study, we ask how ML-LMs acquire and represent factual knowledge. Using the multilingual factual knowledge probing dataset, mLAMA, we first conducted a neuron investigation of ML-LMs (specifically, multilingual BERT). We then traced the roots of facts back to the knowledge source (Wikipedia) to identify the ways in which ML-LMs acquire specific facts. We finally identified three patterns of acquiring and representing facts in ML-LMs: language-independent, cross-lingual shared and transferred, and devised methods for differentiating them. Our findings highlight the challenge of maintaining consistent factual knowledge across languages, underscoring the need for better fact representation learning in ML-LMs.","anthology_url":null,"authors":["Xin Zhao","Naoki Yoshinaga","Daisuke Oba"],"category":"Oral","demo_url":null,"display_track":"Factual Content in NLP","event_ids":["session-2_-factual-content-in-nlp-(oral)"],"id":"314-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge","tldr":"","track":"Factual Content in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Although fine-tuning a pre-trained model with a conventional approach has shown to be effective in various downstream tasks, previous work has used only backpropagation to fine-tune the model, which causes a massive amount of computational resources and time. We propose Extreme Fine-Tuning (EFT), a novel approach for fine-tuning a pre-trained model effectively and efficiently. EFT uses backpropagation for a brief fine-tuning and an iterative extreme learning machine for training a classifier. We applied EFT to four text classification datasets, MELD, IEMOCAP, IMDb, and AG News, and compared its performance with state-of-the-art (SOTA) approaches. The results indicate that EFT noticeably outperformed the other approaches in training-time measurement with comparable model performance. We will release our code at https://github.com/up-33/extreme-fine-tuning.","anthology_url":null,"authors":["Boonnithi Jiaramaneepinit","Thodsaporn Chay-intr","Kotaro Funakoshi","Manabu Okumura"],"category":"Oral","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-2_-machine-learning-for-nlp-(oral)"],"id":"317-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Extreme Fine-tuning: A Novel and Fast Fine-tuning Approach for Text Classification","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Juraj Vladika","Florian Matthes"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"318","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Comparing Knowledge Sources for Open-Domain Scientific Claim Verification","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Julius Cheng","Andreas Vlachos"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"319","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Measuring Uncertainty in Neural Machine Translation with Similarity-Sensitive Entropy","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zhilu Zhang","Procheta Sen","Zimu Wang","Ruoyu Sun","Zhengyong Jiang","Jionglong Su"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)"],"id":"32","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"FinBPM: A Framework for Portfolio Management-based Financial Investor Behavior Perception Model","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Dor Bernsohn","Gil Semo","Yaron Vazana","Gila Hayat","Ben Hagag","Joel Niklaus","Rohit Saha","Kyryl Truskovskyi"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"320","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In this study, we focus on two main tasks, the first for detecting legal violations within unstructured textual data, and the second for associating these violations with potentially affected individuals. We constructed two datasets using Large Language Models (LLMs) which were subsequently validated by domain expert annotators. Both tasks were designed specifically for the context of class-action cases. The experimental design incorporated fine-tuning models from the BERT family and open-source LLMs, and conducting few-shot experiments using closed-source LLMs. Our results, with an F1-score of 62.69% (violation identification) and 81.02% (associating victims), show that our datasets and setups can be used for both tasks. Finally, we publicly release the datasets and the code used for the experiments in order to advance further research in the area of legal natural language processing (NLP).","anthology_url":null,"authors":["Dor Bernsohn","Gil Semo","Yaron Vazana","Gila Hayat","Ben Hagag","Joel Niklaus","Rohit Saha","Kyryl Truskovskyi"],"category":"Oral","demo_url":null,"display_track":"NLP Applications","event_ids":["session-6_-nlp-applications-(oral)"],"id":"320-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Fantine Huot","Joshua Maynez","Chris Alberti","Reinald Kim Amplayo","Priyanka Agrawal","Constanza Fierro","Shashi Narayan","Mirella Lapata"],"category":"Poster","demo_url":null,"display_track":"Summarization","event_ids":["session-3_-summarization-(poster)"],"id":"321","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"$\\mu$PLAN: Summarizing using a Content Plan as Cross-Lingual Bridge","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Neural networks are notoriously data-hungry. This represents an issue in cases where data are scarce such as in low-resource languages. Data augmentation is a technique commonly used in computer vision to provide neural networks with more data and increase their generalization power. When dealing with data augmentation for natural language, however, simple data augmentation techniques similar to the ones used in computer vision such as rotation and cropping cannot be employed because they would generate ungrammatical texts.   Thus, data augmentation needs a specific design in the case of neural logic-to-text systems, especially for a structurally rich input format such as the ones used for meaning representation. This is the case of the neural natural language generation for Discourse Representation Structures (DRS-to-Text), where the logical nature of DRS needs a specific design of data augmentation. In this paper, we adopt a novel approach in DRS-to-Text to selectively augment a training set with new data by adding and varying two specific lexical categories, i.e. proper and common nouns. In particular, we propose using WordNet supersenses to produce new training sentences using both in-and-out-of-context nouns. We present a number of experiments for evaluating the role played by augmented lexical information. The experimental results prove the effectiveness of our approach for data augmentation in DRS-to-Text generation.","anthology_url":null,"authors":["Muhammad Saad Amin","Luca Anselma","Alessandro Mazzei"],"category":"Oral","demo_url":null,"display_track":"Generation","event_ids":["session-7_-generation-(oral)"],"id":"322-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Exploring Data Augmentation in Neural DRS-to-Text Generation","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"While the Large Language Models (LLMs) dominate a majority of language understanding tasks, previous work shows that some of these results are supported by modelling spurious correlations of training datasets. Authors commonly assess model robustness by evaluating their models on out-of-distribution (OOD) datasets of the same task, but these datasets might share the bias of the training dataset. We propose a simple method for measuring a scale of models' reliance on any identified spurious feature and assess the robustness towards a large set of known and newly found prediction biases for various pre-trained models and debiasing methods in Question Answering (QA). We find that the reported OOD gains of debiasing methods can not be explained by mitigated reliance on biased features, suggesting that biases are shared among different QA datasets. We further evidence this by measuring that performance of OOD models depends on bias features comparably to the ID model. Our findings motivate future work to refine the reports of LLMs' robustness to a level of known spurious features.","anthology_url":null,"authors":["Luk\u00e1\u0161 Mikula","Michal \u0160tef\u00e1nik","Marek Petrovi\u010d","Petr Sojka"],"category":"Oral","demo_url":null,"display_track":"Question Answering","event_ids":["session-7_-question-answering-(oral)"],"id":"323-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Michela Lorandi","Anya Belz"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["session-3_-generation-(poster)"],"id":"324","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Emotion recognition in conversation (ERC) has attracted much attention due to its wide applications. While consistent improvement is being made in this area, inevitable challenge comes from the dataset. The ERC dataset exhibits significantly imbalanced emotion distribution. While the utterances with neutral emotion predominate the data, this emotion label is always treated the same as other emotion labels in current approaches. To address the problem caused by the dataset, we propose a supervised contrastive learning specifically oriented for ERC task. We employ a novel data augmentation method emulating the emotion dynamics in a conversation and formulate supervised contrastive learning method tailored for ERC addressing the predominance and the ambiguity of neutral emotion. Experimental results on four benchmark datasets demonstrate the effectiveness of our approach.","anthology_url":null,"authors":["Yujin Kang","Yoon-Sik Cho"],"category":"Oral","demo_url":null,"display_track":"Opinion, Sentiment and Emotion","event_ids":["session-4_-opinion,-sentiment-and-emotion-(oral)"],"id":"325-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving Contrastive Learning in Emotion Recognition in Conversation via Data Augmentation and Decoupled Neutral Emotion","tldr":"","track":"Opinion, Sentiment and Emotion","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Francesco Maria Molfese","Andrei Stefan Bejgu","Simone Tedeschi","Simone Conia","Roberto Navigli"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"326","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Neuralign: A Context-Aware, Cross-Lingual and Fully-Neural Sentence Alignment System for Long Texts","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Sentence alignment -- establishing links between corresponding sentences in two related documents -- is an important NLP task with several downstream applications, such as machine translation (MT).  Despite the fact that existing sentence alignment systems have achieved promising results, their effectiveness is based on auxiliary information such as document metadata or machine-generated translations, as well as hyperparameter-sensitive techniques. Moreover, these systems often overlook the crucial role that context plays in the alignment process.  In this paper, we address the aforementioned issues and propose Neuralign: the first context-aware, end-to-end and fully-neural architecture for sentence alignment. Our system maps source and target sentences in long documents by contextualizing their sentence embeddings with respect to the other sentences in the document. We extensively evaluate Neuralign on a multilingual dataset consisting of 20 language pairs derived from the Opus project, and demonstrate that our model achieves state-of-the-art performance. To ensure reproducibility, we release our code and model checkpoints at https://github.com/Babelscape/Neuralign.","anthology_url":null,"authors":["Francesco Maria Molfese","Andrei Stefan Bejgu","Simone Tedeschi","Simone Conia","Roberto Navigli"],"category":"Oral","demo_url":null,"display_track":"Sentence-level Semantics","event_ids":["session-6_-sentence-level-semantics-(oral)"],"id":"326-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Neuralign: A Context-Aware, Cross-Lingual and Fully-Neural Sentence Alignment System for Long Texts","tldr":"","track":"Sentence-level Semantics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Eliana Pastor","Alkis Koudounas","Giuseppe Attanasio","Dirk Hovy","Elena Baralis"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"327","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Predictive models make mistakes and have biases. To combat both, we need to understand their predictions.  Explainable AI (XAI) provides insights into models for vision, language, and tabular data. However, only a few approaches exist for speech classification models. Previous works focus on a selection of spoken language understanding (SLU) tasks, and most users find their explanations challenging to interpret.  We propose a novel approach to explain speech classification models. It provides two types of insights. (i) Word-level. We measure the impact of each audio segment aligned with a word on the outcome. (ii) Paralinguistic. We evaluate how non-linguistic features (e.g., prosody and background noise) affect the outcome if perturbed.  We validate our approach by explaining two state-of-the-art SLU models on two tasks in English and Italian. We test their plausibility with human subject ratings. Our results show that the explanations correctly represent the model's inner workings and are plausible to humans.","anthology_url":null,"authors":["Eliana Pastor","Alkis Koudounas","Giuseppe Attanasio","Dirk Hovy","Elena Baralis"],"category":"Oral","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-10_-interpretability-and-model-analysis-in-nlp-(oral)"],"id":"327-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Hallucinations and off-target translation remain unsolved problems in MT, especially for low-resource languages and massively multilingual models. In this paper, we introduce two related methods to mitigate these failure cases with a modified decoding objective, without either requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. Experiments on the massively multilingual models M2M-100 (418M) and SMaLL-100 show that these methods suppress hallucinations and off-target translations, reducing the number of translations with segment-level chrF2 below 10 by 67-83% on average across 57 tested translation directions. In a proof of concept on out-of-English translation, we also show that we can suppress off-target translations with large language models. We release code upon acceptance.","anthology_url":null,"authors":["Rico Sennrich","Jannis Vamvas","Alireza Mohammadshahi"],"category":"Oral","demo_url":null,"display_track":"Machine Translation","event_ids":["session-9_-machine-translation-(oral)"],"id":"33-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jianfeng He","Julian Salazar","Kaisheng Yao","Haoqi Li","Jason Cai"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-11_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"331","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Zero-Shot End-to-End Spoken Language Understanding via Cross-Modal Selective Self-Training","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Muhammad Asif Ali","Yan HU","Jianbin Qin","Di Wang"],"category":"Poster","demo_url":null,"display_track":"Semantics: Lexical","event_ids":["session-11_-semantics_-lexical-(poster)"],"id":"332","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Antonym vs Synonym Distinction using InterlaCed Encoder NETworks (ICE-NET)","tldr":"","track":"Semantics: Lexical","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Vincent Tao Hu","Di Wu","Yuki M Asano","Pascal Mettes","Basura Fernando","Bj\u00f6rn Ommer","Cees G. M. Snoek"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["session-3_-generation-(poster)"],"id":"333","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Flow Matching for Conditional Text Generation in a Few Sampling Steps","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Eric Khiu","Hasti Toossi","Jinyu Liu","Jiaxu Li","David Anugraha","Juan Armando Parra Flores","Leandro Arcos Roman","A. Seza Do\u011fru\u00f6z","En-Shiun Annie Lee"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"334","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Predicting Machine Translation Performance on Low-Resource Languages: The Role of Domain Similarity","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine \"intelligence.\" Recently, many anecdotal examples were used to suggest that newer Large Language Models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation of 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.","anthology_url":null,"authors":["Natalie Shapira","Mosh Levy","Seyed Hossein Alavi","Xuhui Zhou","Yejin Choi","Yoav Goldberg","Maarten Sap","Vered Shwartz"],"category":"Oral","demo_url":null,"display_track":"Linguistic Theory and Insights","event_ids":["session-4_-linguistic-theory-and-insights-(oral)"],"id":"335-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models","tldr":"","track":"Linguistic Theory and Insights","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Martha Lewis","Nihal V. Nayak","Peilin Yu","Jack Merullo","Qinan Yu","Stephen Bach","Ellie Pavlick"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["business-meeting_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"336","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Does CLIP Bind Concepts? Probing Compositionality in Large Image Models","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Daniel Weisberg Mitelman","Nachum Dershowitz","Kfir Bar"],"category":"Poster","demo_url":null,"display_track":"shows virtual","event_ids":["session-10_-shows-virtual-(poster)"],"id":"337","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Code-Switching and Back-Transliteration Using a Bilingual Model","tldr":"","track":"shows virtual","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yibin Lei","Yu Cao","Tianyi Zhou","Tao Shen","Andrew Yates"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"339","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Corpus-Steered Query Expansion with Large Language Models","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty---an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction.","anthology_url":null,"authors":["Alberto Testoni","Raquel Fern\u00e1ndez"],"category":"Oral","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-2_-dialogue-and-interactive-systems-(oral)"],"id":"34-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zihao He","Ashwin Rao","Siyi Guo","Negar Mokhberian","Kristina Lerman"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["business-meeting_-computational-social-science-and-cultural-analytics-(poster)"],"id":"340","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Reading Between the Tweets: Deciphering Ideological Stances of Interconnected Mixed-Ideology Communities","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Orion Weller","Dawn Lawrie","Benjamin Van Durme"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(poster)"],"id":"342","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"NevIR: Negation in Neural Information Retrieval","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Negation is a common everyday phenomena and has been a consistent area of weakness for language models (LMs). Although the Information Retrieval (IR) community has adopted LMs as the backbone of modern IR architectures, there has been little to no research in understanding how negation impacts neural IR. We therefore construct a straightforward benchmark on this theme: asking IR models to rank two documents that differ only by negation. We show that the results vary widely according to the type of IR architecture: cross-encoders perform best, followed by late-interaction models, and in last place are bi-encoder and sparse neural architectures. We find that most current information retrieval models do not consider negation, performing similarly or worse than randomly ranking. We show that although the obvious approach of continued fine-tuning on a dataset of contrastive documents containing negations increases performance (as does model size), there is still a large gap between machine and human performance.","anthology_url":null,"authors":["Orion Weller","Dawn Lawrie","Benjamin Van Durme"],"category":"Oral","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(oral)"],"id":"342-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"NevIR: Negation in Neural Information Retrieval","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent work in open-domain question answering (ODQA) has shown that adversarial poisoning of the search collection can cause large drops in accuracy for production systems. However, little to no work has proposed methods to defend against these attacks. To do so, we rely on the intuition that redundant information often exists in large corpora. To find it, we introduce a method that uses query augmentation to search for a diverse set of passages that could answer the original question but are less likely to have been poisoned. We integrate these new passages into the model through the design of a novel confidence method, comparing the predicted answer to its appearance in the retrieved contexts (what we call Confidence from Answer Redundancy, i.e. CAR). Together these methods allow for a simple but effective way to defend against poisoning attacks that provides gains of nearly 20% exact match across varying levels of data poisoning/knowledge conflicts.","anthology_url":null,"authors":["Orion Weller","Aleem Khan","Nathaniel Weir","Dawn Lawrie","Benjamin Van Durme"],"category":"Oral","demo_url":null,"display_track":"Question Answering","event_ids":["session-7_-question-answering-(oral)"],"id":"343-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Defending Against Disinformation Attacks in Open-Domain Question Answering","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Orion Weller","Marc Marone","Nathaniel Weir","Dawn Lawrie","Daniel Khashabi","Benjamin Van Durme"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"344","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"\u201cAccording to . . . \u201d: Prompting Language Models Improves Quoting from Pre-Training Data","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches. This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work. We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently. The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms. Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance. Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification.","anthology_url":null,"authors":["Goncalo Emanuel Cavaco Gomes","Isabel Pereira Coutinho","Bruno Martins"],"category":"Oral","demo_url":null,"display_track":"NLP Applications","event_ids":["session-6_-nlp-applications-(oral)"],"id":"345-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Accurate and Well-Calibrated ICD Code Assignment Through Attention Over Diverse Label Embeddings","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kushal Chawla","Hannah Rashkin","Gaurav Singh Tomar","David Reitter"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["business-meeting_-dialogue-and-interactive-systems-(poster)"],"id":"347","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Investigating Content Planning for Navigating Trade-offs in Knowledge-Grounded Dialogue","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Xiang Gao","Jiaxin Zhang","Lalla Mouatadid","Kamalika Das"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"348","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Luke Bates","Iryna Gurevych"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"35","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Like a Good Nearest Neighbor: Practical Content Moderation and Text Classification","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent progress in sentence embedding, which represents a sentence's meaning as a point in a vector space, has achieved high performance on several tasks such as the semantic textual similarity (STS) task.  However, a sentence representation cannot adequately express the diverse information that sentences contain: for example, such representations cannot naturally handle asymmetric relationships between sentences.  This paper proposes GaussCSE, a Gaussian-distribution-based contrastive learning framework for sentence embedding that can handle asymmetric inter-sentential relations, as well as a similarity measure for identifying entailment relations.  Our experiments show that GaussCSE achieves performance comparable to that of previous methods on natural language inference (NLI) tasks, and that it can estimate the direction of entailment relations, which is difficult with point representations.","anthology_url":null,"authors":["Shohei Yoda","Hayato Tsukagoshi","Ryohei Sasano","Koichi Takeda"],"category":"Oral","demo_url":null,"display_track":"Sentence-level Semantics","event_ids":["session-6_-sentence-level-semantics-(oral)"],"id":"350-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Sentence Representations via Gaussian Embedding","tldr":"","track":"Sentence-level Semantics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Diffusion models have emerged as a powerful paradigm for generation, obtaining strong performance in various continuous domains.   However, applying continuous diffusion models to natural language remains challenging due to its discrete nature and the need for a large number of diffusion steps to generate text, making diffusion-based generation expensive.  In this work, we propose Text-to-text Self-conditioned Simplex Diffusion (TESS), a text diffusion model that is fully non-autoregressive, employs a new form of self-conditioning, and applies the diffusion process on the logit simplex space rather than the learned embedding space.  Through extensive experiments on natural language understanding and generation tasks including summarization, text simplification, paraphrase generation, and question generation, we demonstrate that TESS outperforms state-of-the-art non-autoregressive models, requires fewer diffusion steps with minimal drop in performance, and is competitive with pretrained autoregressive sequence-to-sequence models.","anthology_url":null,"authors":["Rabeeh Karimi mahabadi","Hamish Ivison","Jaesung Tae","James Henderson","Iz Beltagy","Matthew E Peters","Arman Cohan"],"category":"Oral","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-2_-machine-learning-for-nlp-(oral)"],"id":"351-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"TESS: Text-to-Text Self-Conditioned Simplex Diffusion","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yunzhe Li","Qian Chen","Weixiang Yan","Wen Wang","Qinglin Zhang","Hari Sundaram"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["business-meeting_-generation-(poster)"],"id":"352","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Advancing Precise Outline-Conditioned Text Generation with Task Duality and Explicit Outline Control","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zhuowan Li","Cihang Xie","Benjamin Van Durme","Alan Yuille"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["session-11_-generation-(poster)"],"id":"353","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Localization vs. Semantics: Visual Representations in Unimodal and Multimodal Models","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kaige Xie","Mark Riedl"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["business-meeting_-dialogue-and-interactive-systems-(poster)"],"id":"354","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Creating Suspenseful Stories: Iterative Planning with Large Language Models","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kaige Xie","Tong Yu","Haoliang Wang","Junda Wu","Handong Zhao","Ruiyi Zhang","Kanak Mahadik","Ani Nenkova","Mark Riedl"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["business-meeting_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"355","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer in Prompt Tuning","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Raha Moraffah","huan liu"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-11_-machine-learning-for-nlp-(poster)"],"id":"358","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Exploiting Class Probabilities for Black-box Sentence-level Attacks","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Dongyub Lee","Eunhwan Park","Hodong Lee","Heuiseok Lim"],"category":"Poster","demo_url":null,"display_track":"Question Answering","event_ids":["business-meeting_-question-answering-(poster)"],"id":"359","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Ask, Assess, and Refine: Rectifying Factual Consistency and Hallucination in LLMs with Metric-Guided Feedback Learning","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Fajri Koto","Tilman Beck","Zeerak Talat","Iryna Gurevych","Timothy Baldwin"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-11_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"36","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Zero-shot Sentiment Analysis in Low-Resource Languages Using a Multilingual Sentiment Lexicon","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ruixue Lian","William A. Sethares","Junjie Hu"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-11_-machine-learning-for-nlp-(poster)"],"id":"360","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Learning Label Hierarchy with Supervised Contrastive Learning","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We present a new Hindi text-to-speech (TTS) dataset and demonstrate its utility for the expressive synthesis of children's audio stories. The dataset comprises narration by a single female speaker who modifies her voice to produce different story characters. Annotation for dialogue identification, character labelling, and character attribution are provided, all of which are expected to facilitate the learning of character voice and speaking styles. Experiments are conducted using different versions of the annotated dataset that enable training a multi-speaker TTS model on the single-speaker data. Subjective tests show that the multi-speaker model improves expressiveness and character voice consistency compared to the baseline single-speaker TTS. With the multi-speaker model, objective evaluations show comparable word error rates, better speaker voice consistency, and higher correlations with ground-truth emotion attributes. We release a new 16.8 hours storytelling speech dataset in Hindi and propose effective solutions for expressive TTS with narrator voice modulation and character voice consistency.","anthology_url":null,"authors":["Pavan Kalyan Tankala","Preethi Jyothi","Preeti Rao","Pushpak Bhattacharyya"],"category":"Oral","demo_url":null,"display_track":"Multimodality","event_ids":["session-3_-multimodality-(oral)"],"id":"362-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"STORiCo: Storytelling TTS for Hindi with Character Voice Modulation","tldr":"","track":"Multimodality","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We explore loss functions for fact verification in the FEVER shared task. While the cross-entropy loss is a standard objective for training verdict predictors, it fails to capture the heterogeneity among the FEVER verdict classes. In this paper, we develop two task-specific objectives tailored to FEVER. Experimental results confirm that the proposed objective functions outperform the standard cross-entropy. Performance is further improved when these objectives are combined with simple class weighting, which effectively overcomes the imbalance in the training data. The source code is available (https://github.com/yuta-mukobara/RLF-KGAT).","anthology_url":null,"authors":["Yuta Mukobara","Yutaro Shigeto","Masashi Shimbo"],"category":"Oral","demo_url":null,"display_track":"Factual Content in NLP","event_ids":["session-2_-factual-content-in-nlp-(oral)"],"id":"364-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Rethinking Loss Functions for Fact Verification","tldr":"","track":"Factual Content in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Michael Toker","Oren Mishali","Ophir M\u00fcnz-Manor","Benny Kimelfeld","Yonatan Belinkov"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"369","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Dataset for Metaphor Detection in Early Medieval Hebrew Poetry","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Zihao Meng","Tao Liu","Heng Zhang","Kai Feng","Peng Zhao"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["business-meeting_-information-extraction-(poster)"],"id":"37","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CEAN: Contrastive Event Aggregation Network with LLM-based Augmentation for Event Extraction","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Wafaa Mohammed","Vlad Niculae"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"371","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"On Measuring Context Utilization in Document-Level MT Systems","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Shahed Masoudian","Cornelia Volaucnik","Markus Schedl","Navid Rekabsaz"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-8_-ethics-and-nlp-(poster)"],"id":"373","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Micha\u0142 Pietruszka","Micha\u0142 Turski","\u0141ukasz Borchmann","Tomasz Dwojak","Gabriela Nowakowska","Karolina Szyndler","Dawid Jurkiewicz","\u0141ukasz Garncarek"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["session-3_-information-extraction-(poster)"],"id":"374","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"STable: Table Generation Framework for Encoder-Decoder Models","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Heejin Do","Yunsu Kim","Gary Lee"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"376","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Autoregressive Score Generation for Multi-trait Essay Scoring","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["LIN TIAN","Xiuzhen Zhang","Jey Han Lau"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"378","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CMA-R: Causal Mediation Analysis for Explaining Rumour Detection","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ander Corral","Xabier Saralegi"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"379","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Morphology Aware Source Term Masking for Terminology-Constrained NMT","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Asahi Ushio","Jose Camacho-Collados","Steven Schockaert"],"category":"Poster","demo_url":null,"display_track":"Semantics: Lexical","event_ids":["business-meeting_-semantics_-lexical-(poster)"],"id":"380","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A RelEntLess Benchmark for Modelling Graded Relations between Named Entities","tldr":"","track":"Semantics: Lexical","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yo-Han Park","Wencke Liermann","Yong-Seok Choi","Kong Joo Lee"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-3_-dialogue-and-interactive-systems-(poster)"],"id":"381","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Improving Backchannel Prediction Leveraging Sequential and Attentive Context Awareness","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["C\u00e9dric BOSCHER","Christine Largeron","V\u00e9ronique Eglin","El\u00f6d Egyed-Zsigmond"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["session-3_-information-extraction-(poster)"],"id":"382","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SENSE-LM : A Synergy between a Language Model and Sensorimotor Representations for Auditory and Olfactory Information Extraction","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jie Chi","Peter Bell"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"384","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Analyzing the Role of Part-of-Speech in Code-Switching: A Corpus-Based Study","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Shawly Ahsan","Eftekhar Hossain","Omar Sharif","Avishek Das","Mohammed Moshiul Hoque","M. Ali Akber Dewan"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-11_-resources-and-evaluation-(poster)"],"id":"386","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Multimodal Framework to Detect Target Aware Aggression in Memes","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller. 2) semantic coverage is the key indicator for downstream QA performance. Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model. In contrast, the higher semantic coverage provided by our method is critical for QA performance.","anthology_url":null,"authors":["Hai X. Pham","Isma Hadji","Xinnuo Xu","Ziedune Degutyte","Jay Rainey","Evangelos Kazakos","Afsaneh Fazly","Georgios Tzimiropoulos","Brais Martinez"],"category":"Oral","demo_url":null,"display_track":"Question Answering","event_ids":["session-7_-question-answering-(oral)"],"id":"388-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Graph Guided Question Answer Generation for Procedural Question-Answering","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In Neural Machine Translation (NMT), models will sometimes generate repetitive or fluent output that is not grounded in the source sentence. This phenomenon is known as hallucination and is a problem even in large-scale multilingual translation models. We propose to use Contrastive Decoding, an algorithm developed to improve generation from unconditional language models, to mitigate hallucinations in NMT. Specifically, we maximise the log-likelihood difference between a model and the same model with reduced contribution from the encoder outputs. Additionally, we propose an alternative implementation of Contrastive Decoding that dynamically weights the difference based on the maximum probability in the output distribution to reduce the effect of CD when the model is confident of its prediction. We evaluate our methods using the Small (418M) and Medium (1.2B) M2M models across 21 low and medium-resource language pairs. Our results show a 14.6 \u00b1 0.5 and 11.0 \u00b1 0.6 maximal increase in the mean COMET scores for the Small and Medium models on those sentences for which the M2M models initially generate a hallucination., respectively.","anthology_url":null,"authors":["Jonas Waldendorf","Barry Haddow","Alexandra Birch"],"category":"Oral","demo_url":null,"display_track":"Machine Translation","event_ids":["session-9_-machine-translation-(oral)"],"id":"389-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Contrastive Decoding Reduces Hallucinations in Large Multilingual Machine Translation Models","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Rob van der Goot"],"category":"Poster","demo_url":null,"display_track":"Phonology, Morphology, and Word Segmentation","event_ids":["session-8_-phonology,-morphology,-and-word-segmentation-(poster)"],"id":"39","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Where are we Still Split on Tokenization?","tldr":"","track":"Phonology, Morphology, and Word Segmentation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Daisuke Oba","Masahiro Kaneko","Danushka Bollegala"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-8_-ethics-and-nlp-(poster)"],"id":"390","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"In-Contextual Gender Bias Suppression for Large Language Models","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Misinformation and disinformation phenomena existed long before the advent of digital technologies. The exponential use of social media platforms, whose information feeds have created the conditions for many to many communication and instant amplification of the news has accelerated the diffusion of inaccurate and misleading information. As a result, the identification of claims have emerged as a pivotal technology for combating the influence of misinformation and disinformation within news media. Most existing work has concentrated on claim analysis at the sentence level, neglecting the crucial exploration of supplementary attributes such as the claimer and the claim object of the claim or confining it by limiting its scope to a predefined list of topics. Furthermore, previous research has been mostly centered around political debates, Wikipedia articles, and COVID-19 related content. By leveraging the advanced capabilities of Large Language Models (LLMs) in Natural Language Understanding (NLU) and text generation, we propose a novel architecture utilizing LLMs finetuned with LoRA to transform the claim, claimer and claim object detection task into a Question Answering (QA) setting. We evaluate our approach in a dataset of 867 scientific news articles of 3 domains (Health, Climate Change, Nutrition) (HCN), which are human annotated with the major claim, the claimer and the object of the major claim. We also evaluate our proposed model in the benchmark dataset of NEWSCLAIMS. Experimental and qualitative results showcase the effectiveness of the proposed approach. We make our dataset publicly available to encourage further research.","anthology_url":null,"authors":["Sotiris Kotitsas","Panagiotis Kounoudis","Eleni Koutli","Haris Papageorgiou"],"category":"Oral","demo_url":null,"display_track":"Factual Content in NLP","event_ids":["session-2_-factual-content-in-nlp-(oral)"],"id":"391-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leveraging fine-tuned Large Language Models with LoRA for Effective Claim, Claimer, and Claim Object Detection","tldr":"","track":"Factual Content in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nefeli Gkouti","Prodromos Malakasiotis","Stavros Toumpis","Ion Androutsopoulos"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"393","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Should I try multiple optimizers when fine-tuning a pre-trained Transformer for NLP tasks? Should I tune their hyperparameters?","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jessica Lin","Amir Zeldes"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-8_-computational-social-science-and-cultural-analytics-(poster)"],"id":"399","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"GUMsley: Evaluating Entity Salience in Summarization for 12 English Genres","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nathan Godey","\u00c9ric Villemonte de la Clergerie","Beno\u00eet Sagot"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"4","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Anisotropy Is Inherent to Self-Attention in Transformers","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Danni Liu","Jan Niehues"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"40","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Customizing machine translation models to comply with desired attributes (e.g., formality or grammatical gender) is a well-studied topic. However, most current approaches rely on (semi-)supervised data with attribute annotations. This data scarcity bottlenecks democratizing such customization possibilities to a wider range of languages, particularly lower-resource ones. This gap is out of sync with recent progress in pretrained massively multilingual translation models. In response, we transfer the attribute controlling capabilities to languages without attribute-annotated data with an NLLB-200 model as a foundation. Inspired by techniques from controllable generation, we employ a gradient-based inference-time controller to steer the pretrained model. The controller transfers well to zero-shot conditions, as it is operates on pretrained multilingual representations and is attribute- rather than language-specific. With a comprehensive comparison to finetuning-based control, we demonstrate that, despite finetuning\u2019s clear dominance in supervised settings, the gap to inference-time control closes when moving to zero-shot conditions, especially with new and distant target languages. The latter also shows stronger domain robustness. We further show that our inference-time control complements finetuning. Moreover, a human evaluation on a real low-resource language, Bengali, confirms our findings. Our code is in the supplementary material.","anthology_url":null,"authors":["Danni Liu","Jan Niehues"],"category":"Oral","demo_url":null,"display_track":"Machine Translation","event_ids":["session-9_-machine-translation-(oral)"],"id":"40-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as toxic language detection.   Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique \u2014 it remains unclear for which tasks and scenarios it can help, and the role of the individual factors in sociodemographic prompting is still unexplored. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. We use it to analyze its influence on model sensitivity, performance and robustness across seven datasets and six instruction-tuned model families. We show that sociodemographic information affects model predictions and can be beneficial for improving zero-shot learning in subjective NLP tasks.  However, its outcomes largely vary for different model types, sizes, and datasets, and are subject to large variance with regards to prompt formulations. Most importantly, our results show that sociodemographic prompting should be used with care when used for data annotation or studying LLM alignment.","anthology_url":null,"authors":["Tilman Beck","Hendrik Schuff","Anne Lauscher","Iryna Gurevych"],"category":"Oral","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-10_-interpretability-and-model-analysis-in-nlp-(oral)"],"id":"400-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Max Ploner","Alan Akbik"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"401","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Parameter-Efficient Fine-Tuning: Is There An Optimal Subset of Parameters to Tune?","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Chanwoo Bae","Guanhong Tao","ZHUO ZHANG","Xiangyu Zhang"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-11_-nlp-applications-(poster)"],"id":"402","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Threat Behavior Textual Search by Attention Graph Isomorphism","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"As one of the oldest forms of human communication, narratives appear across a variety of genres and media. Computational methods have been applied to study narrativity in novels, social media, and patient records, leading to new approaches and insights. However, other types of media are growing in popularity, like podcasts. Podcasts contain a multitude of spoken narratives that can provide a meaningful glimpse into how people share stories with one another.  In this paper, we outline and apply methods to process English-language podcast transcripts and extract narrative content from conversations within each episode. We provide an initial analysis of the types of narrative content that exists within a wide range of podcasts, and compare our results to other established narrative analysis tools.  Our annotations for narrativity and pretrained models can help to enable future research into narrativity within a large corpus of approximately 100,000 podcast episodes.","anthology_url":null,"authors":["Yosra Abdessamed","Shadi Rezapour","Steven R. Wilson"],"category":"Oral","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-10_-computational-social-science-and-cultural-analytics-(oral)"],"id":"404-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Identifying Narrative Content in Podcast Transcripts","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent studies have shown that as Transformer-based language models become larger and are trained on very large amounts of data, the fit of their surprisal estimates to naturalistic human reading times degrades. The current work presents a series of analyses showing that word frequency is a key explanatory factor underlying these two trends. First, residual errors from four language model families on four corpora show that the inverse correlation between model size and fit to reading times is the strongest on the subset of least frequent words, which is driven by excessively accurate predictions of larger model variants. Additionally, training dynamics reveal that during later training steps, all model variants learn to predict rare words and that larger model variants do so more accurately, which explains the detrimental effect of both training data amount and model size on fit to reading times. Finally, a feature attribution analysis demonstrates that larger model variants are able to accurately predict rare words based on both an effectively longer context window size as well as stronger local associations compared to smaller model variants. Taken together, these results indicate that Transformer-based language models' surprisal estimates diverge from human-like expectations due to the superhumanly complex associations they learn for predicting rare words.","anthology_url":null,"authors":["Byung-Doh Oh","Shisen Yue","William Schuler"],"category":"Oral","demo_url":null,"display_track":"Linguistic Theory and Insights","event_ids":["session-4_-linguistic-theory-and-insights-(oral)"],"id":"405-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Frequency Explains the Inverse Correlation of Large Language Models' Size, Training Data Amount, and Surprisal's Fit to Reading Times","tldr":"","track":"Linguistic Theory and Insights","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nikita Martynov","Mark Baushenko","Anastasia Kozlova","Katerina Kolomeytseva","Aleksandr Abramov","Alena Fenogenova"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["session-3_-generation-(poster)"],"id":"41","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Scientific papers and slides are two different representations of the same underlying information, but both require substantial work to prepare. While there had been prior efforts on automating document-to-slides generation, there is still a pressing need of customizing the presentation of content aligning with the persona of target audience or duration of presentation. This paper first introduces the concept of end-user specification-aware document to slides conversion that incorporates end-user specifications into the conversion process. For this, we initially introduce a new dataset reuse the existing SciDuet dataset consisting of pairs of papers and corresponding slides decks from recent years\u2019 *ACL conferences to create four persona-aware configurations. Secondly, we present Persona-Aware-D2S, a novel approach by finetuning LLMs using target audience feedback to create persona-aware slides from scientific documents. Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of target audience.","anthology_url":null,"authors":["Ishani Mondal","Shwetha S","Anandhavelu Natarajan","Aparna Garimella","Sambaran Bandyopadhyay","Jordan Lee Boyd-Graber"],"category":"Oral","demo_url":null,"display_track":"NLP Applications","event_ids":["session-6_-nlp-applications-(oral)"],"id":"411-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Presentations by the Humans and For the Humans: Harnessing LLMs for Generating Persona-Aware Slides from Documents","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Md Mahfuz Ibn Alam","Sina Ahmadi","Antonios Anastasopoulos"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"412","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CODET: A Benchmark for Contrastive Dialectal Evaluation of Machine Translation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Bolei Ma","Ercong Nie","Shuzhou Yuan","Helmut Schmid","Michael F\u00e4rber","Frauke Kreuter","Hinrich Schuetze"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"413","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Prompt-based methods have been successfully applied to multilingual pretrained language models for zero-shot cross-lingual understanding. However, most previous studies primarily focused on sentence-level classification tasks, and only a few considered token-level labeling tasks such as Named Entity Recognition (NER) and Part-of-Speech (POS) tagging. In this paper, we propose Token-Level Prompt Decomposition (ToPro), which facilitates the prompt-based method for token-level sequence labeling tasks. The ToPro method decomposes an input sentence into single tokens and applies one prompt template to each token. Our experiments on multilingual NER and POS tagging datasets demonstrate that ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuning in zero-shot cross-lingual transfer, especially for languages that are typologically different from the source language English. Our method also attains state-of-the-art performance when employed with the mT5 model. Besides, our exploratory study in multilingual large language models shows that ToPro performs much better than the current in-context learning method. Overall, the performance improvements show that ToPro could potentially serve as a novel and simple benchmarking method for sequence labeling tasks.","anthology_url":null,"authors":["Bolei Ma","Ercong Nie","Shuzhou Yuan","Helmut Schmid","Michael F\u00e4rber","Frauke Kreuter","Hinrich Schuetze"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 2","event_ids":["session-8_-multilinguality-and-language-diversity-2-(oral)"],"id":"413-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks","tldr":"","track":"Multilinguality and Language Diversity 2","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Giorgos Vernikos","Arthur Brazinskas","Jakub Adamek","Jonathan Mallinson","Aliaksei Severyn","Eric Malmi"],"category":"Poster","demo_url":null,"display_track":"Generation","event_ids":["session-3_-generation-(poster)"],"id":"417","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Small Language Models Improve Giants by Rewriting Their Outputs","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Despite the impressive performance of large language models (LLMs), they  often lag behind specialized models in various tasks. LLMs only use a fraction  of the existing training data for in-context learning, while task-specific  models harness the full dataset for fine-tuning. In this work, we tackle the  problem of leveraging training data to improve the performance of LLMs without  fine-tuning. Our approach directly targets LLM predictions without requiring  access to their weights. We create a pool of candidates from the LLM through  few-shot prompting and we employ a compact model, the LM-corrector (LMCor),  specifically trained to merge these candidates to produce an enhanced output.  Our experiments on four natural language generation tasks demonstrate that even  a small LMCor model (250M) substantially improves the few-shot performance of  LLMs (62B), matching and even outperforming standard fine-tuning. Furthermore,  we illustrate the robustness of LMCor against different prompts, thereby  minimizing the need for extensive prompt engineering. Finally, we show that  LMCor can be seamlessly integrated with different LLMs at inference, serving as  a plug-and-play module to improve their performance.","anthology_url":null,"authors":["Giorgos Vernikos","Arthur Brazinskas","Jakub Adamek","Jonathan Mallinson","Aliaksei Severyn","Eric Malmi"],"category":"Oral","demo_url":null,"display_track":"Generation","event_ids":["session-7_-generation-(oral)"],"id":"417-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Small Language Models Improve Giants by Rewriting Their Outputs","tldr":"","track":"Generation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"While static word embeddings are blind to context, for lexical semantics tasks context is rather too present in contextual word embeddings, vectors of same-meaning occurrences being too different (Ethayarajh, 2019). Fine-tuning pre-trained language models (PLMs) using contrastive learning was proposed, leveraging automatically self-augmented examples (Liu et al., 2021b). In this paper, we investigate how to inject a lexicon as an alternative source of supervision, using the English Wiktionary. We also test how dimensionality reduction impacts the resulting contextual word embeddings. We evaluate our approach on the Word-In-Context (WiC) task, in the unsupervised setting (not using the training set). We achieve new SoTA result on the original WiC test set. We also propose two new WiC test sets for which we show that our fine-tuning method achieves substantial improvements. We also observe improvements, although modest, for the semantic frame induction task. Although we experimented on English to allow comparison with related work, our method is adaptable to the many languages for which large Wiktionaries exist.","anthology_url":null,"authors":["Anna Mosolova","Marie Candito","Carlos Ramisch"],"category":"Oral","demo_url":null,"display_track":"Multilingual Issues","event_ids":["session-6_-multilingual-issues-(oral)"],"id":"42-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Injecting Wiktionary to improve token-level contextual representations using contrastive learning","tldr":"","track":"Multilingual Issues","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Pawe\u0142 Maka","Yusuf Can Semerci","Jan Scholtes","Gerasimos Spanakis"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"420","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Sequence Shortening for Context-Aware Machine Translation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Social science NLP tasks, such as emotion or humor detection, are required to capture the semantics along with the implicit pragmatics from text, often with limited amounts of training data. Instruction tuning has been shown to improve the many capabilities of large language models (LLMs) such as commonsense reasoning, reading comprehension, and computer programming. However, little is known about the effectiveness of instruction tuning on the social domain where implicit pragmatic cues are often needed to be captured. We explore the use of instruction tuning for social science NLP tasks and introduce Socialite-Llama &mdash; an open-source, instruction-tuned Llama. On a suite of 20 social science tasks, Socialite-Llama improves upon the performance of Llama as well as matches or improves upon the performance of a state-of-the-art, multi-task finetuned model on a majority of them. Further, Socialite-Llama also leads to improvement on 5 out of 6 related social tasks as compared to Llama, suggesting instruction tuning can lead to generalized social understanding. All resources including our code, model and dataset can be found through [bit.ly/socialitellama](https://bit.ly/socialitellama/).","anthology_url":null,"authors":["Gourab Dey","Adithya V Ganesan","Yash Kumar Lal","Manal Shah","Shreyashee Sinha","Matthew Matero","Salvatore Giorgi","Vivek Kulkarni","H. Schwartz"],"category":"Oral","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-10_-computational-social-science-and-cultural-analytics-(oral)"],"id":"422-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Dennis Thomas Ulmer","Chrysoula Zerva","Andre Martins"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"424","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Non-Exchangeable Conformal Language Generation with Nearest Neighbors","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Online sexism has become a concerning issue in recent years, especially conveyed through memes. Although this alarming phenomenon has triggered many studies from computational linguistic and natural language processing points of view, less effort has been spent analyzing if those misogyny detection models are affected by an unintended bias. Such biases can lead models to incorrectly label non-misogynous memes misogynous due to specific identity terms, perpetuating harmful stereotypes and reinforcing negative attitudes.   This paper presents the first and most comprehensive approach to measure and mitigate unintentional bias in the misogynous memes detection model, aiming to develop effective strategies to counter their harmful impact. Our proposed model, the \\textbf{C}on\\textbf{t}e\\textbf{x}tualized \\textbf{S}cene \\textbf{G}raph-based \\textbf{M}ultimodal \\textbf{Net}work (CTXSGMNet), is an integrated architecture that combines VisualBERT, a CLIP-LSTM-based memory network, and an unbiased scene graph module with supervised contrastive loss, achieves state-of-the-art performance in mitigating unintentional bias in misogynous memes.  Empirical evaluation, including both qualitative and quantitative analysis, demonstrates the effectiveness of our CTXSGMNet framework on the SemEval-2022 Task 5 (\\textbf{MAMI} task) dataset, showcasing its promising performance in terms of Equity of Odds and F1 score. Additionally, we assess the generalizability of the proposed model by evaluating their performance on a few benchmark meme datasets, providing a comprehensive understanding of our approach's efficacy across diverse datasets.","anthology_url":null,"authors":["Gitanjali Kumari","Anubhav Sinha","Asif Ekbal"],"category":"Oral","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["session-10_-computational-social-science-and-cultural-analytics-(oral)"],"id":"425-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Unintended Bias Detection and Mitigation in Misogynous Memes","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yongho Song","Dahyun Lee","Myungha Jang","seung-won hwang","Kyungjae Lee","Dongha Lee","Jinyoung Yeo"],"category":"Poster","demo_url":null,"display_track":"Question Answering","event_ids":["session-11_-question-answering-(poster)"],"id":"426","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Towards Evidentiality-Aware Retrieval for Abstractive Tasks: Overcoming Abstractiveness in Open-Domain Question Answering","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We explore how weak supervision on abundant unlabeled data can be leveraged to improve few-shot performance in aspect-based sentiment analysis (ABSA) tasks. We propose a pipeline approach to construct a noisy ABSA dataset, and we use it to adapt a pre-trained sequence-to-sequence model to the ABSA tasks. We test the resulting model on three widely used ABSA datasets, before and after fine-tuning. Our proposed method preserves the full fine-tuning performance while showing significant improvements (15.84 absolute F1) in the few-shot learning scenario for the harder tasks. In zero-shot (i.e., without fine-tuning), our method outperforms the previous state of the art on the aspect extraction sentiment classification (AESC) task and is, additionally, capable of performing the harder aspect sentiment triplet extraction (ASTE) task.","anthology_url":null,"authors":["Robert Vacareanu","Siddharth Varia","Kishaloy Halder","Shuai Wang","Giovanni Paolini","Neha Anna John","Miguel Ballesteros","Smaranda Muresan"],"category":"Oral","demo_url":null,"display_track":"Opinion, Sentiment and Emotion","event_ids":["session-4_-opinion,-sentiment-and-emotion-(oral)"],"id":"427-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Weak Supervision Approach for Few-Shot Aspect Based Sentiment Analysis","tldr":"","track":"Opinion, Sentiment and Emotion","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Knowledge graph embeddings (KGEs) were originally developed to infer true but missing facts in incomplete knowledge repositories.  In this paper, we link knowledge graph completion and counterfactual reasoning via our new task CFKGR. We model the original world state as a knowledge graph, hypothetical scenarios as edges added to the graph, and plausible changes to the graph as inferences from logical rules. We create corresponding benchmark datasets, which contain diverse hypothetical scenarios with plausible changes to the original knowledge graph and facts that should be retained. We develop COULDD, a general method for adapting existing knowledge graph embeddings given a hypothetical premise, and evaluate it on our benchmark. Our results indicate that KGEs learn patterns in the graph without explicit training. We further observe that KGEs adapted with COULDD solidly detect plausible counterfactual changes to the graph that follow these patterns. An evaluation on human-annotated data reveals that KGEs adapted with COULDD are mostly unable to recognize changes to the graph that do not follow learned inference rules. In contrast, ChatGPT mostly outperforms KGEs in detecting plausible changes to the graph but has poor knowledge retention. In summary, CFKGR connects two previously distinct areas, namely KG completion and counterfactual reasoning.","anthology_url":null,"authors":["Lena Zellinger","Andreas Stephan","Benjamin Roth"],"category":"Oral","demo_url":null,"display_track":"Factual Content in NLP","event_ids":["session-2_-factual-content-in-nlp-(oral)"],"id":"428-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Counterfactual Reasoning with Knowledge Graph Embeddings","tldr":"","track":"Factual Content in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Weizhe Yuan","Kyunghyun Cho","Jason E Weston"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["business-meeting_-dialogue-and-interactive-systems-(poster)"],"id":"429","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"System-Level Natural Language Feedback","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We introduce MultiMUC, the first multilingual parallel corpus for template filling, comprising translations of the classic MUC-4 template filling benchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. We obtain automatic translations from a strong multilingual machine translation system and manually project the original English annotations into each target language. For all languages, we also provide human translations for key portions of the dev and test splits. Finally, we present baselines on MultiMUC both with state-of-the-art template filling models for MUC-4 and with ChatGPT. We release MUC-4 and the supervised baselines to facilitate further work on document-level information extraction in multilingual settings.","anthology_url":null,"authors":["William Gantt","Shabnam Behzad","Hannah YoungEun An","Yunmo Chen","Aaron Steven White","Benjamin Van Durme","Mahsa Yarmohammadi"],"category":"Oral","demo_url":null,"display_track":"Information Extraction","event_ids":["session-4_-information-extraction-(oral)"],"id":"43-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"MultiMUC: Multilingual Template Filling on MUC-4","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"One interesting approach to Question Answering (QA) is to search for semantically similar questions, which have been answered before. This task is different from answer retrieval as it focuses on questions rather than only on the answers, therefore it requires different model training on different data.  In this work, we introduce a novel unsupervised pre-training method specialized for retrieving and ranking questions. This leverages (i) knowledge distillation from a basic question retrieval model, and (ii) new pre-training task and objective for learning to rank questions in terms of their relevance with the query. Our experiments show that (i) the proposed technique achieves state-of-the-art performance on QRC and Quora-match datasets, and (ii) the benefit of combining re-ranking and retrieval models.","anthology_url":null,"authors":["Stefano Campese","Ivano Lauriola","Alessandro Moschitti"],"category":"Oral","demo_url":null,"display_track":"Question Answering","event_ids":["session-7_-question-answering-(oral)"],"id":"432-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Pre-Training Methods for Question Reranking","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Over 15 years ago, Ward & Birner (2006) suggested that non-canonical constructions in English can serve both to mark information status and to structure the information flow of discourse. One such construction is preposing, where a phrasal constituent appears to the left of its canonical position, typically sentence-initially. But computational work on discourse has, to date, ignored non-canonical syntax. We take account of non-canonical syntax by providing quantitative evidence relating NP/PP preposing to discourse relations. The evidence comes from an LLM mask-filling task that compares the predictions when a mask is inserted between the arguments of an implicit inter-sentential discourse relation --- first, when the right-hand argument (Arg2) starts with a preposed constituent, and again, when that constituent is in canonical (post-verbal) position. Results show that (1) the top-ranked mask-fillers in the preposed case agree more often with \"gold\" annotations in the Penn Discourse TreeBank than they do in the latter case, and (2) preposing in Arg2 can affect the distribution of discourse-relational senses.","anthology_url":null,"authors":["Yunfang Dong","Xixian Liao","Bonnie L. Webber"],"category":"Oral","demo_url":null,"display_track":"Linguistic Theory and Insights","event_ids":["session-4_-linguistic-theory-and-insights-(oral)"],"id":"433-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Syntactic Preposing and Discourse Relations","tldr":"","track":"Linguistic Theory and Insights","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Haochen Liu"],"category":"Poster","demo_url":null,"display_track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","event_ids":["business-meeting_-sentiment-analysis,-stylistic-analysis-and-argument-mining-(poster)"],"id":"434","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Self-training Strategies for Sentiment Analysis: An Empirical Study","tldr":"","track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recently, decoder-only pre-trained large language models (LLMs), with several tens of billion parameters, have significantly impacted a wide range of natural language processing (NLP) tasks. While encoder-only or encoder-decoder pre-trained language models have already proved to be effective in discourse parsing, the extent to which LLMs can perform this task remains an open research question. Therefore, this paper explores how beneficial such LLMs are for Rhetorical Structure Theory (RST) discourse parsing. Here, the parsing process for both fundamental top-down and bottom-up strategies is converted into prompts, which LLMs can work with. We employ Llama 2 and fine-tune it with QLoRA, which has fewer parameters that can be tuned. Experimental results on three benchmark datasets, RST-DT, Instr-DT, and the GUM corpus, demonstrate that Llama 2 with 70 billion parameters in the bottom-up strategy obtained state-of-the-art (SOTA) results with significant differences. Furthermore, our parsers demonstrated generalizability when evaluated on RST-DT, showing that, in spite of being trained with the GUM corpus, it obtained similar performances to those of existing parsers trained with RST-DT.","anthology_url":null,"authors":["Aru Maekawa","Tsutomu Hirao","Hidetaka Kamigaito","Manabu Okumura"],"category":"Oral","demo_url":null,"display_track":"Discourse and Syntactic Parsing","event_ids":["session-3_-discourse-and-syntactic-parsing-(oral)"],"id":"438-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Can we obtain significant success in RST discourse parsing by using Large Language Models?","tldr":"","track":"Discourse and Syntactic Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Florian Ludwig","Klara Dolos","Ana Alves-Pinto","Torsten Zesch"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"439","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Unraveling the Dynamics of Semi-Supervised Hate Speech Detection: The Impact of Unlabeled Data Characteristics and Pseudo-Labeling Strategies","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Emi Baylor","Esther Ploeger","Johannes Bjerva"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"44","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Multilingual Gradient Word-Order Typology from Universal Dependencies","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"While information from the field of linguistic typology has the potential to improve performance on NLP tasks, reliable typological data is a prerequisite. Existing typological databases, including WALS and Grambank, suffer from inconsistencies primarily caused by their categorical format. Furthermore, typological categorisations by definition differ significantly from the continuous nature of phenomena, as found in natural language corpora. In this paper, we introduce a new seed dataset made up of continuous-valued data, rather than categorical data, that can better reflect the variability of language. While this initial dataset focuses on word-order typology, we also present the methodology used to create the dataset, which can be easily adapted to generate data for a broader set of features and languages.","anthology_url":null,"authors":["Emi Baylor","Esther Ploeger","Johannes Bjerva"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 1","event_ids":["session-7_-multilinguality-and-language-diversity-1-(oral)"],"id":"44-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Multilingual Gradient Word-Order Typology from Universal Dependencies","tldr":"","track":"Multilinguality and Language Diversity 1","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We propose attribute-aware multimodal entity linking, where the input consists of a mention described with a text paragraph and images, and the goal is to predict the corresponding target entity from a multimodal knowledge base (KB) where each entity is also accompanied by a text description, visual images, and a collection of attributes that present the meta-information of the entity in a structured format.   To facilitate this research endeavor, we construct Ameli, encompassing a new multimodal entity linking benchmark dataset that contains 16,735 mentions described in text and associated with 30,472 images, and a multimodal knowledge base that covers 34,690 entities along with 177,873 entity images and 798,216 attributes. To establish baseline performance on Ameli, we experiment with several state-of-the-art architectures for multimodal entity linking and further propose a new approach that incorporates attributes of entities into disambiguation. Experimental results and extensive qualitative analysis demonstrate that extracting and understanding the attributes of mentions from their text descriptions and visual images play a vital role in multimodal entity linking. To the best of our knowledge, we are the first to integrate attributes in the multimodal entity linking task. The programs, model checkpoints, and the dataset are publicly available at https://github.com/VT-NLP/Ameli.","anthology_url":null,"authors":["Barry Menglong Yao","Sijia Wang","Yu Chen","Qifan Wang","Minqian Liu","Zhiyang Xu","Licheng Yu","Lifu Huang"],"category":"Oral","demo_url":null,"display_track":"Information Extraction","event_ids":["session-4_-information-extraction-(oral)"],"id":"440-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Ameli: Enhancing Multimodal Entity Linking with Fine-Grained Attributes","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Orion Weller","Kyle Lo","David Wadden","Dawn Lawrie","Benjamin Van Durme","Arman Cohan","Luca Soldaini"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"441","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yilun Zhu","Joel Ruben Antony Moniz","Shruti Bhargava","Jiarui Lu","Dhivya Piraviperumal","Site Li","Yuan Zhang","Hong Yu","Bo-Hsiang Tseng"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"442","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Can Large Language Models Understand Context?","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Haolan Zhan","Yufei Wang","Zhuang Li","Tao Feng","YUNCHENG HUA","Suraj Sharma","Lizhen Qu","Zhaleh Semnani Azad","Ingrid Zukerman","Reza Haf"],"category":"Poster","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-3_-dialogue-and-interactive-systems-(poster)"],"id":"443","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Let's Negotiate! A Survey of Negotiation Dialogue Systems","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Generative Retrieval (GR), autoregressively decoding relevant document identifiers given a query, has been shown to perform well under the setting of small-scale corpora. By memorizing the document corpus with model parameters, GR implicitly achieves deep interaction between query and document. However, such a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for fine-grained features of documents; (2) Memory confusion gets worse as the corpus size increases; (3) Huge memory update costs for new documents. To alleviate these problems, we propose the Generative Dense Retrieval (GDR) paradigm. Specifically, GDR first uses the limited memory volume to achieve inter-cluster matching from query to relevant document clusters. Memorizing-free matching mechanism from Dense Retrieval (DR) is then introduced to conduct fine-grained intra-cluster matching from clusters to relevant documents. The coarse-to-fine process maximizes the advantages of GR's deep interaction and DR's scalability. Besides, we design a cluster identifier constructing strategy to facilitate corpus memory and a cluster-adaptive negative sampling strategy to enhance the intra-cluster mapping ability. Empirical results show that GDR obtains an average of 3.0 R@100 improvement on NQ dataset under multiple settings and has better scalability.","anthology_url":null,"authors":["Peiwen Yuan","Xinglin Wang","Shaoxiong Feng","Boyuan Pan","Yiwei Li","Heda Wang","Xupeng Miao","Kan Li"],"category":"Oral","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(oral)"],"id":"444-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Generative Dense Retrieval: Memory Can Be a Burden","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Most works on transformers trained with the Masked Language Modeling (MLM) objective use the original BERT model's fixed masking rate of 15%. We propose to instead dynamically schedule the masking rate throughout training. We find that linearly decreasing the masking rate over the course of pretraining improves average GLUE accuracy by up to 0.46% and 0.25% in BERT-base and BERT-large, respectively, compared to fixed rate baselines. These gains come from exposure to both high and low masking rate regimes, providing benefits from both settings. Our results demonstrate that masking rate scheduling is a simple way to improve the quality of masked language models, achieving up to a 1.89x speedup in pretraining for BERT-base as well as a Pareto improvement for BERT-large.","anthology_url":null,"authors":["Zachary Ankner","Naomi Saphra","Davis Blalock","Jonathan Frankle","Matthew L Leavitt"],"category":"Oral","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-2_-machine-learning-for-nlp-(oral)"],"id":"446-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Dynamic Masking Rate Schedules for MLM Pretraining","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["David Bayani"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"448","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Testing the Depth of ChatGPT's Comprehension via Cross-Modal Tasks Based on ASCII-Art: GPT3.5's Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Francesco Cazzaro","Davide Locatelli","Ariadna Quattoni"],"category":"Poster","demo_url":null,"display_track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","event_ids":["session-8_-semantics_-sentence-level-semantics,-textual-inference-and-other-areas-(poster)"],"id":"45","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Align and Augment: Generative Data Augmentation for Compositional Generalization","tldr":"","track":"Semantics: Sentence-level Semantics, Textual Inference and other areas","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent work on semantic parsing has shown that seq2seq models find compositional generalization challenging. Several strategies have been proposed to mitigate this challenge. One such strategy is to improve compositional generalization via data augmentation techniques. In this paper we follow this line of work and propose Archer, a data-augmentation strategy that exploits alignment annotations between sentences and their corresponding meaning representations. More precisely, we use alignments to train a two step generative model that combines monotonic lexical generation with reordering. Our experiments show that Archer leads to significant improvements in compositional generalization performance.","anthology_url":null,"authors":["Francesco Cazzaro","Davide Locatelli","Ariadna Quattoni"],"category":"Oral","demo_url":null,"display_track":"Semantics and Applications","event_ids":["session-9_-semantics-and-applications-(oral)"],"id":"45-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Align and Augment: Generative Data Augmentation for Compositional Generalization","tldr":"","track":"Semantics and Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Himanshu Beniwal","Kowsik Nandagopan D","Mayank Singh"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"451","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Cross-lingual Editing in Multilingual Language Models","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Raphael Schumann","Elman Mansimov","Yi-An Lai","Nikolaos Pappas","Xibin Gao","Yi Zhang"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"453","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Backward Compatibility During Data Updates by Weight Interpolation","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Parsa Kavehzadeh"],"category":"Poster","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-4_-efficient-low-resource-methods-in-nlp-(poster)"],"id":"454","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large Language Models for Dynamic Inference","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Abraham Toluwase Owodunni","Aditya Yadavalli","Chris Chinenye Emezue","Tobi Olatunji","Clinton C Mbataku"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"456","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"AccentFold: A Journey through African Accents for Zero-Shot ASR Adaptation to Target Accents","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nevan Wichers","Carson Denison","Ahmad Beirami"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"458","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Gradient-Based Language Model Red Teaming","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Red teaming is a common strategy for identifying weaknesses in generative language models (LMs) by producing adversarial prompts that trigger models to generate unsafe responses. Red teaming is instrumental for both model alignment and evaluation, but is labor-intensive and difficult to scale when done by humans. In this paper, we present Gradient-Based Red Teaming (GBRT), a novel red teaming method for automatically generating diverse prompts that are likely to cause an LM to output unsafe responses. GBRT is a form of prompt learning, trained by scoring an LM response with a safety classifier and then backpropagating through the frozen safety classifier and LM to update the prompt. To improve the coherence of input prompts, we introduce two variants that add a realism loss and fine-tune a pretrained model to generate the prompts instead of learning the prompts directly. Our experiments show that GBRT is more effective at finding prompts that trigger an LM to generate unsafe responses than a strong reinforcement learning-based red teaming approach and works even when the LM has been fine-tuned to produce safer outputs.","anthology_url":null,"authors":["Nevan Wichers","Carson Denison","Ahmad Beirami"],"category":"Oral","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-2_-machine-learning-for-nlp-(oral)"],"id":"458-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Gradient-Based Language Model Red Teaming","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Hyeonseok Moon","Jaewook Lee","Sugyeong Eo","Chanjun Park","Jaehyung Seo","Heuiseok Lim"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"460","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Generative Interpretation: Toward Human-Like Evaluation for Educational Question-Answer Pair Generation","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Andreas Waldis","Yufang Hou","Iryna Gurevych"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"461","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Dive into the Chasm: Probing the Gap between In- and Cross-Topic Generalization","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"This paper explores the moral judgment and moral reasoning abilities exhibited by Large Language Models (LLMs) across languages through the Defining Issues Test. It is a well known fact that moral judgment depends on the language in which the question is asked. We extend the work of beyond English, to 5 new languages (Chinese, Hindi, Russian, Spanish and Swahili), and probe three LLMs -- ChatGPT, GPT-4 and Llama2Chat-70B -- that shows substantial multilingual text processing and generation abilities. Our study shows that the moral reasoning ability for all models, as indicated by the post-conventional score, is substantially inferior for Hindi and Swahili, compared to Spanish, Russian, Chinese and English, while there is no clear trend for the performance of the latter four languages. The moral judgments too vary considerably by the language.","anthology_url":null,"authors":["Aditi Khandelwal","Utkarsh Agarwal","Kumar Tanmay","Monojit Choudhury"],"category":"Oral","demo_url":null,"display_track":"Multilingual Issues","event_ids":["session-6_-multilingual-issues-(oral)"],"id":"462-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test","tldr":"","track":"Multilingual Issues","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Md Rakibul Hasan"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["business-meeting_-computational-social-science-and-cultural-analytics-(poster)"],"id":"464","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LLM-GEm: Large Language Model-Guided Prediction of People's Empathy Levels towards Newspaper Article","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Siun Kim","Jung-Hyun Won","David Lee","Renqian Luo","Lijun Wu","Tao Qin","Howard Lee"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"466","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CReSE: Benchmark Data and Automatic Evaluation Framework for Recommending Eligibility Criteria from Clinical Trial Information","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Christoph Leiter","Hoa Nguyen","Steffen Eger"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-11_-resources-and-evaluation-(poster)"],"id":"467","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"BMX: Boosting Natural Language Generation Metrics with Explainability","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sara Rajaee","Christof Monz"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"468","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in Multilingual Language Models","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent advances in training multilingual language models on large datasets seem to have shown promising results in knowledge transfer across languages and achieve high performance on downstream tasks. However, we question to what extent the current evaluation benchmarks and setups accurately measure zero-shot cross-lingual knowledge transfer. In this work, we challenge the assumption that high zero-shot performance on target tasks reflects high cross-lingual ability by introducing more challenging setups involving instances with multiple languages. Through extensive experiments and analysis, we show that the observed high performance of multilingual models can be largely attributed to factors not requiring the transfer of actual linguistic knowledge, such as task- and surface-level knowledge. More specifically, we observe what has been transferred across languages is mostly data artifacts and biases, especially for low-resource languages. Our findings highlight the overlooked drawbacks of existing cross-lingual test data and evaluation setups, calling for a more nuanced understanding of the cross-lingual capabilities of multilingual models.","anthology_url":null,"authors":["Sara Rajaee","Christof Monz"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 2","event_ids":["session-8_-multilinguality-and-language-diversity-2-(oral)"],"id":"468-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in Multilingual Language Models","tldr":"","track":"Multilinguality and Language Diversity 2","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Wei Fang","Yung-Sung Chuang","James R. Glass"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"469","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Joint Inference of Retrieval and Generation for Passage Re-ranking","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"In this paper, we introduce UNSEE, which stands for Unsupervised Non-Contrastive Sentence Embeddings. UNSEE demonstrates better performance compared to SimCSE in the Massive Text Embedding (MTEB) benchmark. We begin by highlighting the issue of representation collapse that occurs with the replacement of contrastive objectives with non-contrastive objectives in SimCSE. Subsequently, we introduce a straightforward solution called the target network to mitigate this problem. This approach enables us to harness non-contrastive objectives while ensuring training stability and achieving performance improvements similar to those seen with contrastive objectives. We have reached peak performance in non-contrastive sentence embeddings through extensive fine-tuning and optimization. These efforts have resulted in superior sentence representation models, emphasizing the importance of careful tuning and optimization for non-contrastive objectives.","anthology_url":null,"authors":["\u00d6mer Veysel \u00c7a\u011fatan"],"category":"Oral","demo_url":null,"display_track":"Sentence-level Semantics","event_ids":["session-6_-sentence-level-semantics-(oral)"],"id":"47-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"UNSEE: Unsupervised Non-contrastive Sentence Embeddings","tldr":"","track":"Sentence-level Semantics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples. One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.'' In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types. In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type. In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning. To this end, we leverage an entity linking benchmark to create a dataset with orders of magnitude of more distinct entity types and descriptions as currently used datasets. We find that this increased signal yields strong results in zero- and few-shot NER in in-domain, cross-domain, and even cross-lingual settings. Our findings indicate significant potential for improving few-shot NER through heuristical data-based optimization.","anthology_url":null,"authors":["Jonas Golde","Felix Hamborg","Alan Akbik"],"category":"Oral","demo_url":null,"display_track":"Information Extraction","event_ids":["session-4_-information-extraction-(oral)"],"id":"470-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Rodrigo Wilkens","Patrick Watrin","R\u00e9mi Cardon","Alice Pintard","Isabelle Gribomont","Thomas Fran\u00e7ois"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"472","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Exploring hybrid approaches to readability: experiments on the complementarity between linguistic features and transformers","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The field of machine learning (ML) has gained widespread adoption, leading to significant demand for adapting ML to specific scenarios, which is yet expensive and non-trivial. The predominant approaches towards the automation of solving ML tasks (e.g., AutoML) are often time-consuming and hard to understand for human developers. In contrast, though human engineers have the incredible ability to understand tasks and reason about solutions, their experience and knowledge are often sparse and difficult to utilize by quantitative approaches. In this paper, we aim to bridge the gap between machine intelligence and human knowledge by introducing a novel framework MLCopilot, which leverages the state-of-the-art large language models to develop ML solutions for novel tasks. We showcase the possibility of extending the capability of LLMs to comprehend structured inputs and perform thorough reasoning for solving novel ML tasks. And we find that, after some dedicated design, the LLM can (i) observe from the existing experiences of ML tasks and (ii) reason effectively to deliver promising results for new tasks. The solution generated can be used directly to achieve high levels of competitiveness.","anthology_url":null,"authors":["lei Zhang","Yuge Zhang","Kan Ren","Dongsheng Li","Yuqing Yang"],"category":"Oral","demo_url":null,"display_track":"Semantics and Applications","event_ids":["session-9_-semantics-and-applications-(oral)"],"id":"473-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks","tldr":"","track":"Semantics and Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Maxime Fily","Guillaume Wisniewski","Severine Guillaume","Gilles Adda","Alexis Michaud"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"474","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Establishing degrees of closeness between audio recordings along different dimensions using large-scale cross-lingual models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Paul Youssef","J\u00f6rg Schl\u00f6tterer","Christin Seifert"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"475","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"The Queen of England is not England\u2019s Queen: On the Lack of Factual Coherency in PLMs","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Image clustering divides a collection of images into meaningful groups, typically interpreted post-hoc via human-given annotations. Those are usually in the form of text, begging the question of using text as an abstraction for image clustering. Current image clustering methods, however, neglect the use of generated textual descriptions. We, therefore, propose \\textit{Text-Guided Image Clustering}, i.e., generating text using image captioning and visual question-answering (VQA) models and subsequently clustering the generated text. Further, we introduce a novel approach to inject task- or domain knowledge for clustering by prompting VQA models. Across eight diverse image clustering datasets, our results show that the obtained text representations often outperform image features. Additionally, we propose a counting-based cluster explainability method. Our evaluations show that the derived keyword-based explanations describe clusters better than the respective cluster accuracy suggests. Overall, this research challenges traditional approaches and paves the way for a paradigm shift in image clustering, using generated text.","anthology_url":null,"authors":["Andreas Stephan","Lukas Miklautz","Kevin Sidak","Jan Philip Wahle","Bela Gipp","Claudia Plant","Benjamin Roth"],"category":"Oral","demo_url":null,"display_track":"Multimodality","event_ids":["session-3_-multimodality-(oral)"],"id":"476-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Text-Guided Image Clustering","tldr":"","track":"Multimodality","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Kinjal Basu","Keerthiram Murugesan","Subhajit Chaudhury","Murray Campbell","Kartik Talamadupula","Tim Klinger"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"48","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"EXPLORER: Exploration-guided Reasoning for Textual Reinforcement Learning","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Vincent Jung","Lonneke van der Plas"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"480","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Understanding the effects of language-specific class imbalance in multilingual fine-tuning","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yang Li","Canran Xu","Guodong Long","Tao Shen","Chongyang Tao","Jing Jiang"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["business-meeting_-information-extraction-(poster)"],"id":"481","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"CCPrefix: Counterfactual Contrastive Prefix-Tuning for Many-Class Classification","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Text segmentation is a fundamental task in natural language processing, where documents are split into contiguous sections. However, prior research in this area has been constrained by limited datasets, which are either small in scale, synthesized, or only contain well-structured documents. In this paper, we address these limitations by introducing a novel benchmark YTSeg focusing on spoken content that is inherently more unstructured and both topically and structurally diverse. As part of this work, we introduce an efficient hierarchical segmentation model MiniSeg, that outperforms state-of-the-art baselines. Lastly, we expand the notion of text segmentation to a more practical \"smart chaptering\" task that involves the segmentation of unstructured content, the generation of meaningful segment titles, and a potential real-time application of the models.","anthology_url":null,"authors":["Fabian Retkowski","Alexander Waibel"],"category":"Oral","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-10_-resources-and-evaluation-(oral)"],"id":"49-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"From Text Segmentation to Smart Chaptering: A Novel Benchmark for Structuring Video Transcriptions","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["MSVPJ Sathvik","Abhilash Dowpati","Revanth kumar Narra"],"category":"Poster","demo_url":null,"display_track":"Computational Social Science and Cultural Analytics","event_ids":["business-meeting_-computational-social-science-and-cultural-analytics-(poster)"],"id":"5","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"French GossipPrompts: Dataset For Prevention of Generating French Gossip Stories By LLMs","tldr":"","track":"Computational Social Science and Cultural Analytics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Negar Arabzadeh","Charles L. A. Clarke"],"category":"Poster","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-3_-information-retrieval-and-text-mining-(poster)"],"id":"50","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"r\u00e9chet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The rapid advancement of natural language processing, information retrieval (IR), computer vision, and other technologies has presented significant challenges in evaluating the performance of these systems. One of the main challenges is the scarcity of human-labeled data, which hinders the fair and accurate assessment of these systems. In this work, we specifically focus on evaluating IR systems with sparse labels, borrowing from recent research on evaluating computer vision tasks.  taking inspiration from the success of using Fr\u00e9chet Inception Distance (FID) in assessing text-to-image generation systems. We propose leveraging the Fr\u00e9chet Distance to measure the distance between the distributions of relevant judged items and retrieved results. Our experimental results on MS MARCO V1 dataset and TREC Deep Learning Tracks query sets demonstrate the effectiveness of the Fr\u00e9chet Distance as a metric for evaluating IR systems,   particularly in settings where a few labels are available.  This approach contributes to the advancement of evaluation methodologies in real-world scenarios such as the assessment of generative IR systems.","anthology_url":null,"authors":["Negar Arabzadeh","Charles L. A. Clarke"],"category":"Oral","demo_url":null,"display_track":"Information Retrieval and Text Mining","event_ids":["session-8_-information-retrieval-and-text-mining-(oral)"],"id":"50-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Fr\u00e9chet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels","tldr":"","track":"Information Retrieval and Text Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Recent studies of the emergent capabilities of transformer-based Natural Language Understanding (NLU) models have indicated that they have an understanding of lexical and compositional semantics. We provide evidence that suggests these claims should be taken with a grain of salt: we find that state-of-the-art Natural Language Inference (NLI) models are sensitive towards minor semantics preserving surface-form variations, which lead to sizable inconsistent model decisions during inference. Notably, this behaviour differs from valid and in-depth comprehension of compositional semantics, however does neither emerge when evaluating model accuracy on standard benchmarks nor when probing for syntactic, monotonic, and logically robust reasoning. We propose a novel framework to measure the extent of semantic sensitivity. To this end, we evaluate NLI models on adversarially generated examples containing minor semantics-preserving surface-form input noise. This is achieved using conditional text generation, with the explicit condition that the NLI model predicts the relationship between the original and adversarial inputs as a symmetric equivalence entailment. We systematically study the effects of the phenomenon across NLI models for $\\text{\\emph{in-}}$ and $\\text{\\emph{out-of-}}$ domain settings. Our experiments show that semantic sensitivity causes performance degradations of $12.92\\%$ and $23.71\\%$ average over $\\text{\\emph{in-}}$ and $\\text{\\emph{out-of-}}$ domain settings, respectively. We further perform ablation studies, analysing this phenomenon across models, datasets, and variations in inference and show that semantic sensitivity can lead to major inconsistency within model predictions.","anthology_url":null,"authors":["Erik Arakelyan","Zhaoqi Liu","Isabelle Augenstein"],"category":"Oral","demo_url":null,"display_track":"Linguistic Theory and Insights","event_ids":["session-4_-linguistic-theory-and-insights-(oral)"],"id":"51-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models","tldr":"","track":"Linguistic Theory and Insights","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ekaterina Artemova","Verena Blaschke","Barbara Plank"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"52","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Exploring the Robustness of Task-oriented Dialogue Systems for Colloquial German Varieties","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sanjana Ramprasad","Kundan Krishna","Zachary Chase Lipton","Byron C Wallace"],"category":"Poster","demo_url":null,"display_track":"Summarization","event_ids":["business-meeting_-summarization-(poster)"],"id":"53","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Simeng Sun","Yang Liu","Shuohang Wang","Dan Iter","Chenguang Zhu","Mohit Iyyer"],"category":"Poster","demo_url":null,"display_track":"Question Answering","event_ids":["business-meeting_-question-answering-(poster)"],"id":"54","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents","tldr":"","track":"Question Answering","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.","anthology_url":null,"authors":["Richard Yuanzhe Pang","Stephen Roller","Kyunghyun Cho","He He","Jason E Weston"],"category":"Oral","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-2_-dialogue-and-interactive-systems-(oral)"],"id":"56-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Leveraging Implicit Feedback from Deployment Data in Dialogue","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"There has recently been a growing interest in using Large Language Models (LLMs) to evaluate NLP tasks automatically. Considerable research effort has been put into improving such systems towards achieving high correlations with human judgement. However, it is still unclear what level of correlation is good enough for practical applications of LLM-based automatic evaluation systems. This paper characterizes these LLM evaluators' confidence in ranking candidate NLP models and develops a configurable Monte Carlo simulation method. We show that even automatic metrics with low correlation with human judgement can reach high-confidence rankings of candidate models with reasonable evaluation set sizes (100s of examples). Further, we describe tradeoff curves between the LLM evaluator performance (i.e., correlation with humans) and evaluation set size; loss in correlation can be compensated with modest increases in the evaluation set size. We validate our results on RoSE, a text summarization dataset, and find our estimates of confidence align with empirical observations.    Code available at https://github.com/rickardstureborg/llm-eval-confidence","anthology_url":null,"authors":["Rickard Stureborg","Dimitris Alikaniotis","Yoshi Suhara"],"category":"Oral","demo_url":null,"display_track":"Summarization","event_ids":["session-8_-summarization-(oral)"],"id":"57-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Characterizing the Confidence of Large Language Model-Based Automatic Evaluation Metrics","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Samuel Joseph Amouyal","Aya Meltzer-Asscher","Jonathan Berant"],"category":"Poster","demo_url":null,"display_track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics","event_ids":["session-8_-linguistic-theories,-cognitive-modeling-and-psycholinguistics-(poster)"],"id":"58","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Large Language Models for Psycholinguistic Plausibility Pretesting","tldr":"","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Heng Yang","Ke Li"],"category":"Poster","demo_url":null,"display_track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","event_ids":["session-11_-sentiment-analysis,-stylistic-analysis-and-argument-mining-(poster)"],"id":"59","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Modeling Aspect Sentiment Coherency via Local Sentiment Aggregation","tldr":"","track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Saba Ahmadi","Aishwarya Agrawal"],"category":"Poster","demo_url":null,"display_track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","event_ids":["session-10_-multimodality-and-language-grounding-to-vision,-robotics-and-beyond-(poster)"],"id":"60","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"An Examination of the Robustness of Reference-Free Image Captioning Evaluation Metrics","tldr":"","track":"Multimodality and Language Grounding to Vision, Robotics and Beyond","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Shira Wein","Te I","Colin Cherry","Juraj Juraska","Dirk Padfield","Wolfgang Macherey"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-4_-resources-and-evaluation-(poster)"],"id":"61","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Barriers to Effective Evaluation of Simultaneous Interpretation","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ahmed Abdelali","Hamdy Mubarak","Shammur Absar Chowdhury","Maram Hasanain","Basel Mousi","Sabri Boughorbel","Samir Abdaljalil","Yassine El Kheir","Daniel Izham","Fahim Dalvi","Majd Hawasly","Nizi Nazar","Youssef Ibrahim Elshahawy","Ahmed Ali","Nadir Durrani","Natasa Milic-Frayling","Firoj Alam"],"category":"Poster","demo_url":null,"display_track":"Resources and Evaluation","event_ids":["session-8_-resources-and-evaluation-(poster)"],"id":"65","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"LAraBench: Benchmarking Arabic AI with Large Language Models","tldr":"","track":"Resources and Evaluation","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"A subtle difference in context results in totally different nuances even for lexically identical words. On the other hand, two words can convey similar meanings given a homogeneous context. As a result, considering only word spelling information is not sufficient to obtain quality text representation. We propose SentenceLDA, a sentence-level topic model. We combine modern SentenceBERT and classical LDA to extend the semantic unit from word to sentence. By extending the semantic unit, we verify that SentenceLDA returns more discriminative document representation than other topic models, while maintaining LDA's elegant probabilistic interpretability. We also verify the robustness of SentenceLDA by comparing the inference results on original and paraphrased texts. Additionally, we implement one possible application of SentenceLDA on corpus-level key opinion mining by applying SentenceLDA on an argumentative corpus, DebateSum.","anthology_url":null,"authors":["Taehun Cha","Donghun Lee"],"category":"Oral","demo_url":null,"display_track":"Semantics and Applications","event_ids":["session-9_-semantics-and-applications-(oral)"],"id":"66-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"SentenceLDA: Discriminative and Robust Document Representation with Sentence Level Topic Model","tldr":"","track":"Semantics and Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Adrian Theuma","Ehsan Shareghi"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"67","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Qingyun Wang","Zixuan Zhang","Hongxiang Li","Xuan Liu","Jiawei Han","Huimin Zhao","Heng Ji"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["session-3_-information-extraction-(poster)"],"id":"7","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Jiachen Lian","Gopala Anumanchipalli"],"category":"Poster","demo_url":null,"display_track":"Speech recognition, text-to-speech and spoken language understanding","event_ids":["session-10_-speech-recognition,-text-to-speech-and-spoken-language-understanding-(poster)"],"id":"70","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Towards Hierarchical Spoken Language Disfluency Modeling","tldr":"","track":"Speech recognition, text-to-speech and spoken language understanding","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Speech dysfluency modeling is the bottleneck for both speech therapy and language learning. However, there is no AI solution to systematically tackle this problem. We first propose to define the concept of dysfluent speech and dysfluent speech modeling. We then present Hierarchical Unconstrained Dysfluency Modeling (H-UDM) approach that addresses both dysfluency transcription and detection to eliminate the need for extensive manual annotation. Furthermore, we introduce a simulated dysfluent dataset called VCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our experimental results demonstrate the effectiveness and robustness of our proposed methods in both transcription and detection tasks.","anthology_url":null,"authors":["Jiachen Lian","Gopala Anumanchipalli"],"category":"Oral","demo_url":null,"display_track":"Multimodality","event_ids":["session-3_-multimodality-(oral)"],"id":"70-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Towards Hierarchical Spoken Language Disfluency Modeling","tldr":"","track":"Multimodality","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Adversarial attacks against Language models (LMs) are a significant concern. In particular, adversarial samples exploit the model's sensitivity to small input changes. While these changes appear insignificant on the semantics of the input sample, they result in significant decay in model performance. In this paper, we propose Targeted Paraphrasing via RL (TPRL), an approach to automatically learn a policy to generate challenging samples that improve the model\u2019s performance. TPRL leverages FLAN-T5, a language model, as a generator and employs a self-learned policy using a proximal policy optimization to generate the adversarial examples automatically. TPRL's reward is based on the confusion induced in the classifier, preserving the original text meaning through a Mutual Implication score. We demonstrate \\& evaluate TPRL's effectiveness in discovering natural adversarial attacks and improving model performance through extensive experiments on four diverse NLP classification tasks via Automatic \\& Human evaluation. TPRL outperforms strong baselines, exhibits generalizability across classifiers and datasets, and combines the strengths of language modeling and reinforcement learning to generate diverse and influential adversarial examples.","anthology_url":null,"authors":["Aly M. Kassem","Sherif Saad"],"category":"Oral","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-3_-efficient-low-resource-methods-in-nlp-(oral)"],"id":"71-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Availability of large annotated data can be a critical bottleneck in training machine learning algorithms successfully, especially when applied to diverse domains. Weak supervision offers a promising alternative by accelerating the creation of labeled training data using domain-specific rules. However, it requires users to write a diverse set of high-quality rules to assign labels to the unlabeled data (eg., Snorkel~\\cite{bach2019snorkel}). Automatic Rule Induction (ARI) approaches such as Snuba \\cite{snuba} circumvent this problem by automatically creating rules from features on a small labeled set and filtering a final set of rules from them. In the ARI approach, the crucial step is to filter out a set of a high-quality useful subset of rules from the large set of automatically created rules. In this paper, we propose an algorithm FAIR (Filtering of Automatically Induced Rules) to filter rules from a large number of automatically induced rules using submodular objective functions that account for the collective precision, coverage, and conflicts of the rule set. We experiment with three ARI approaches and five text classification datasets to validate the superior performance of our algorithm with respect to several semi-supervised label aggregation approaches. We show that our approach achieves statistically significant results in comparison to existing rule-filtering approaches. The anonymized source code is available at \\url{https://anonymous.4open.science/r/FAIR-LF-Induction-9B60}.","anthology_url":null,"authors":["Divya Jyoti Bajpai","Ayush Maheshwari","Manjesh Kumar Hanawal","Ganesh Ramakrishnan"],"category":"Oral","demo_url":null,"display_track":"Efficient Low-resource methods in NLP","event_ids":["session-3_-efficient-low-resource-methods-in-nlp-(oral)"],"id":"73-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"FAIR: Filtering of Automatically Induced Rules","tldr":"","track":"Efficient Low-resource methods in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Memorizing and utilizing speakers' personas is a common practice for response generation in long-term conversations. Yet, human-authored datasets often provide uninformative persona sentences that hinder response quality. This paper presents a novel framework that leverages commonsense-based persona expansion to address such issues in long-term conversation.  While prior work focuses on not producing personas that contradict others, we focus on transforming contradictory personas into sentences that contain rich speaker information, by refining them based on their contextual backgrounds with designed strategies. As the pioneer of persona expansion in multi-session settings, our framework facilitates better response generation via human-like persona refinement. The supplementary video of our work is available at https://caffeine-15bbf.web.app/.","anthology_url":null,"authors":["Hana Kim","Kai Tzu-iunn Ong","Seoyeon Kim","Dongha Lee","Jinyoung Yeo"],"category":"Oral","demo_url":null,"display_track":"Dialogue and Interactive Systems","event_ids":["session-2_-dialogue-and-interactive-systems-(oral)"],"id":"74-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement","tldr":"","track":"Dialogue and Interactive Systems","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Marinela Parovi\u0107","Ivan Vuli\u0107","Anna Korhonen"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"77","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Investigating the Potential of Task Arithmetic for Cross-Lingual Transfer","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Nadav Benedek","Lior Wolf"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-9_-machine-learning-for-nlp-(poster)"],"id":"79","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Mike Zhang","Rob van der Goot","Min-Yen Kan","Barbara Plank"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"80","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"NNOSE: Nearest Neighbor Occupational Skill Extraction","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"The labor market is changing rapidly, prompting increased interest in the automatic extraction of occupational skills from text. With the advent of English benchmark job description datasets, there is a need for systems that handle their diversity well. We tackle the complexity in occupational skill datasets tasks---combining and leveraging multiple datasets for skill extraction, to identify rarely observed skills within a dataset, and overcoming the scarcity of skills across datasets. In particular, we investigate the retrieval-augmentation of language models, employing an external datastore for retrieving similar skills in a dataset-unifying manner. Our proposed method, \\textbf{N}earest \\textbf{N}eighbor \\textbf{O}ccupational \\textbf{S}kill \\textbf{E}xtraction (NNOSE) effectively leverages multiple datasets by retrieving neighboring skills from other datasets in the datastore. This improves skill extraction \\emph{without} additional fine-tuning. Crucially, we observe a performance gain in predicting infrequent patterns, with substantial gains of up to 30\\% span-F1 in cross-dataset settings.","anthology_url":null,"authors":["Mike Zhang","Rob van der Goot","Min-Yen Kan","Barbara Plank"],"category":"Oral","demo_url":null,"display_track":"NLP Applications","event_ids":["session-6_-nlp-applications-(oral)"],"id":"80-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"NNOSE: Nearest Neighbor Occupational Skill Extraction","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Text summarization and simplification are among the most widely used applications of AI. However, such models are often prone to hallucination, which can result from training models on unaligned data. One efficient approach to address this issue is Loss Truncation (Kang and Hashimoto, 2020), an approach to modify the standard log loss to adaptively remove noisy examples during training. However, we find that LT alone yields a considerable number of hallucinated entities on various datasets. We study the behavior of the underlying losses between factual and non-factual examples, to understand and refine the performance of LT. We demonstrate that LT's performance is limited when the underlying assumption that noisy targets have higher NLL loss is not satisfied, and find that word-level NLL among entities provides better signal for distinguishing factuality. We then leverage this to propose a fine-grained NLL loss and fine-grained data cleaning strategies, and observe improvements in hallucination reduction across some datasets. Our work is available at https://github.com/yale-nlp/Simplification-Projects.","anthology_url":null,"authors":["Lorenzo Jaime Yu Flores","Arman Cohan"],"category":"Oral","demo_url":null,"display_track":"Summarization","event_ids":["session-8_-summarization-(oral)"],"id":"82-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization","tldr":"","track":"Summarization","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Yingqiang Gao","Nianlong Gu","Jessica Lam","James Henderson","Richard Hahnloser"],"category":"Poster","demo_url":null,"display_track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","event_ids":["session-3_-sentiment-analysis,-stylistic-analysis-and-argument-mining-(poster)"],"id":"83","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Evaluating Unsupervised Argument Aligners via Generation of Conclusions of Structured Scientific Abstracts","tldr":"","track":"Sentiment Analysis, Stylistic Analysis and Argument Mining","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Naganand Yadati"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-11_-machine-learning-for-nlp-(poster)"],"id":"84","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"GAINER: Graph Machine Learning with Node-specific Radius for Classification of Short Texts and Documents","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Peiqin Lin","Chengzhi Hu","Zheyu Zhang","Andre Martins","Hinrich Schuetze"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"86","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"  mPLM-Sim: Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Prachi Jain","Ashutosh Sathe","Varun Gumma","Kabir Ahuja","Sunayana Sitaram"],"category":"Poster","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-8_-ethics-and-nlp-(poster)"],"id":"87","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"MAFIA: Multi-Adapter Fused Inclusive Language Models","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Pretrained Language Models (PLMs) are widely used in NLP for various tasks. Recent studies have identified various biases that such models exhibit and have proposed methods to correct these biases. However, most of the works address a limited set of bias dimensions independently such as gender, race, or religion. Moreover, the methods typically involve finetuning the full model in order to maintain the performance on the downstream task. In this work, we aim to modularly debias a pre-trained language model across multiple dimensions. Previous works extensively explored debiasing PLMs by using limited US-centric counterfactual data augmentation (CDA). We use structured knowledge and a large generative model to build a diverse CDA across multiple bias dimensions in a semi-automated way. We highlight how existing debiasing methods do not consider interactions between multiple societal biases and propose a debiasing model that exploits the synergy amongst various societal biases and enables multi-bias debiasing simultaneously. An extensive evaluation on multiple tasks and languages demonstrates the efficacy of the approach.","anthology_url":null,"authors":["Prachi Jain","Ashutosh Sathe","Varun Gumma","Kabir Ahuja","Sunayana Sitaram"],"category":"Oral","demo_url":null,"display_track":"Ethics and NLP","event_ids":["session-9_-ethics-and-nlp-(oral)"],"id":"87-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"MAFIA: Multi-Adapter Fused Inclusive Language Models","tldr":"","track":"Ethics and NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Cheng-Han Chiang","Hung-yi Lee"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"88","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Over-Reasoning and Redundant Calculation of Large Language Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Large language models (LLMs) can solve problems step-by-step.  While this chain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if LLMs know when to use CoT and whether those CoT are always necessary to answer the question.   This paper shows that LLMs tend to generate redundant calculations and reasoning on a manually constructed math QA dataset, GSM8K-Zero.  GSM8K-Zero is constructed such that the questions can be answered without any calculations, but LLMs, including Llama-2 models and Claude-2, tend to generate lengthy and unnecessary calculations to answer the questions.  We also conduct experiments to explain why LLMs generate redundant calculations and reasonings.","anthology_url":null,"authors":["Cheng-Han Chiang","Hung-yi Lee"],"category":"Oral","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-10_-interpretability-and-model-analysis-in-nlp-(oral)"],"id":"88-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Over-Reasoning and Redundant Calculation of Large Language Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Juhwan Choi","Eunju Lee","Kyohoon Jin","YoungBin Kim"],"category":"Poster","demo_url":null,"display_track":"Multilinguality and Language Diversity","event_ids":["session-10_-multilinguality-and-language-diversity-(poster)"],"id":"9","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"GPTs Are Multilingual Annotators for Sequence Generation Tasks","tldr":"","track":"Multilinguality and Language Diversity","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["CHEN BOWEN","Rune S\u00e6tre","Yusuke Miyao"],"category":"Poster","demo_url":null,"display_track":"Interpretability and Model Analysis in NLP","event_ids":["session-4_-interpretability-and-model-analysis-in-nlp-(poster)"],"id":"93","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"A Comprehensive Evaluation of Inductive Reasoning Capabilities and Problem Solving in Large Language Models","tldr":"","track":"Interpretability and Model Analysis in NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"Code switching (CS) is a very common phenomenon in written and spoken communication, but is handled poorly by many NLP applications. Looking to the application of building CS corpora, we explore CS language identification for corpus building. We make the task more realistic by scaling it to more languages and considering models with simpler architectures for faster inference. We also reformulate the task as a sentence-level multi-label tagging problem to make it more tractable. Having defined the task, we investigate three reasonable architectures for this task and define metrics which better reflect desired performance. We present empirical evidence that no current approach is adequate, and finally provide recommendations for future work in this area.","anthology_url":null,"authors":["Laurie Burchell","Alexandra Birch","Robert Peter Thompson","Kenneth Heafield"],"category":"Oral","demo_url":null,"display_track":"Multilinguality and Language Diversity 2","event_ids":["session-8_-multilinguality-and-language-diversity-2-(oral)"],"id":"94-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Code-Switched Language Identification is Harder Than You Think","tldr":"","track":"Multilinguality and Language Diversity 2","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Ruohong Zhang","Yau-Shian Wang","Yiming Yang"],"category":"Poster","demo_url":null,"display_track":"Machine Learning for NLP","event_ids":["session-11_-machine-learning-for-nlp-(poster)"],"id":"95","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-following LLM","tldr":"","track":"Machine Learning for NLP","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Luis Lugo","Valentin Vielzeuf"],"category":"Poster","demo_url":null,"display_track":"Speech recognition, text-to-speech and spoken language understanding","event_ids":["session-10_-speech-recognition,-text-to-speech-and-spoken-language-understanding-(poster)"],"id":"96","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Towards efficient self-supervised representation learning in speech processing","tldr":"","track":"Speech recognition, text-to-speech and spoken language understanding","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Tu Nguyen","Nedim \u0160rndi\u0107","Alexander Neth"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["business-meeting_-information-extraction-(poster)"],"id":"98","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Mahsa Shamsabadi","Jennifer D'Souza","S\u00f6ren Auer"],"category":"Poster","demo_url":null,"display_track":"Information Extraction","event_ids":["session-3_-information-extraction-(poster)"],"id":"99","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Large Language Models for Scientific Information Extraction: An Empirical Study for Virology","tldr":"","track":"Information Extraction","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"nan","anthology_url":null,"authors":["Johanna Bj\u00f6rklund","Frank Drewes","Anna Jonsson"],"category":"Oral","demo_url":null,"display_track":"Discourse and Syntactic Parsing","event_ids":["session-3_-discourse-and-syntactic-parsing-(oral)"],"id":"Journal-paper-CL1-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Generation and Polynomial Parsing of Graph Languages with Non-Structural Reentrancies","tldr":"","track":"Discourse and Syntactic Parsing","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"nan","anthology_url":null,"authors":["Raphael Schumann","Michael Staniek","Maike Z\u00fcfle","Stefan Riezler"],"category":"Oral","demo_url":null,"display_track":"Sentence-level Semantics","event_ids":["session-6_-sentence-level-semantics-(oral)"],"id":"Journal-paper-TACL1-Oral","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Oral","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap","tldr":"","track":"Sentence-level Semantics","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Sweta Agrawal","Carpuat Marine"],"category":"Poster","demo_url":null,"display_track":"NLP Applications","event_ids":["session-9_-nlp-applications-(poster)"],"id":"TACL2","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Do Text Simplification Systems Convey Correct Information? A Human Evaluation via Reading Comprehension","tldr":"","track":"NLP Applications","underline_id":null,"underline_url":null,"video_url":null},{"abstract":"","anthology_url":null,"authors":["Lukas Edman","Gabriele Sarti","Antonio Toral","Gertjan van Noord","Arianna Bisazza"],"category":"Poster","demo_url":null,"display_track":"Machine Translation","event_ids":["session-10_-machine-translation-(poster)"],"id":"TACL3","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":null,"paper_type":"Poster","poster_pdf":null,"preview_image":null,"program":"Main","similar_paper_ids":[],"slides_pdf":null,"title":"Are Character-level Translations Worth the Wait? Comparing Pretrained Character- and Subword-level Models for Machine Translation","tldr":"","track":"Machine Translation","underline_id":null,"underline_url":null,"video_url":null}]
